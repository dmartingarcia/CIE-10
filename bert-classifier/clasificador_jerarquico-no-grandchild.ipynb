{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /home/david/.pyenv/versions/3.12.8/lib/python3.12/site-packages (1.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%pip install joblib\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from tqdm.auto import tqdm\n",
    "import joblib\n",
    "\n",
    "# ====================\n",
    "#  CONFIGURACIÓN\n",
    "# ====================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "class Config:\n",
    "    USE_FP16 = False\n",
    "    STRIDE = 128  # Overlap between windows\n",
    "    MODEL_NAME = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "    #MODEL_NAME = 'PlanTL-GOB-ES/bsc-bio-ehr-es'\n",
    "    #MODEL_NAME = 'IIC/bsc-bio-ehr-es-caresA'\n",
    "    #MODEL_NAME = 'PlanTL-GOB-ES/roberta-base-biomedical-clinical-es'\n",
    "    #MODEL_NAME = 'IIC/bert-base-spanish-wwm-cased-ctebmsp'\n",
    "    #MODEL_NAME = 'IIC/xlm-roberta-large-ehealth_kd'\n",
    "    THRESHOLD_TUNING_INTERVAL = 3  # Cada cuántas épocas ajustar umbrales\n",
    "    USE_FEATURE_PYRAMID = True # Usar Feature Pyramid Network\n",
    "    FEATURE_LAYER_WEIGHTS = [0.1, 0.3, 0.6]  # Pesos para las últimas 3 capas\n",
    "    CLASS_WEIGHT_SMOOTHING = 0.1  # Suavizado para pesos de clases\n",
    "    EARLY_STOP_PATIENCE = 50  # Número de épocas sin mejora para parar\n",
    "    IMPROVEMENT_MARGIN = 0.0005\n",
    "    MAX_LENGTH = 512 # Máxima longitud de secuencia, definida en el BERT pre-entrenado\n",
    "    TRAIN_BATCH_SIZE = 4\n",
    "    VAL_BATCH_SIZE = 16\n",
    "    TEST_BATCH_SIZE = 32\n",
    "    EPOCHS = 1000\n",
    "    GRADIENT_ACCUMULATION_STEPS = 1\n",
    "    WARMUP_EPOCHS = 2\n",
    "    HIERARCHICAL_WEIGHTS = {'parent': 1.5, 'child': 1.0}\n",
    "    LEARNING_RATE = 3e-5 # 2e-2\n",
    "    DATA_PATHS = {\n",
    "        'train': 'codiesp_csvs/codiesp_D_source_train.csv',\n",
    "        'test': 'codiesp_csvs/codiesp_D_source_test.csv',\n",
    "        'val': 'codiesp_csvs/codiesp_D_source_validation.csv'\n",
    "    }\n",
    "    SAVE_TOKENIZER_PATH = 'snapshots/cie10_tokenizer'\n",
    "    SAVE_PATH = 'snapshots/best_hierarchical_model'\n",
    "    SAVE_STATE_PATH = 'snapshots/best_hierarchical_model_state.bin'\n",
    "    SAVE_MLB_PARENT_PATH = 'snapshots/best_hierarchical_model_mlb_parent'\n",
    "    SAVE_MLB_CHILD_PATH = 'snapshots/best_hierarchical_model_mlb_child'\n",
    "    THRESHOLDS = {'parent': 0.041, 'child': 0.12}\n",
    "    PRETRAIN_EPOCHS = 10\n",
    "    PRETRAIN_BATCH_SIZE = 8\n",
    "    PRETRAIN_DATA_PATH = '../csv_import_scripts/cie10-es-diagnoses-expanded.csv'\n",
    "    FORCE_NEW_MODEL = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PREPROCESAMIENTO\n",
    "# ====================\n",
    "def parse_code(code):\n",
    "    \"\"\"Divide el código en niveles jerárquicos\"\"\"\n",
    "    parts = code.split('.')\n",
    "    hierarchy = []\n",
    "    if len(parts) >= 1:\n",
    "        parent = parts[0]  # Primera categoría (ej: S62)\n",
    "        hierarchy.append(parent)\n",
    "\n",
    "        if len(parts) >= 2:\n",
    "            child_part = parts[1]\n",
    "            child = f\"{parent}.{child_part}\"  # Segunda categoría (ej: S62.14S)\n",
    "            hierarchy.append(child)\n",
    "\n",
    "    return hierarchy\n",
    "\n",
    "def calculate_mlb_classes():\n",
    "    df = pd.read_csv(Config.PRETRAIN_DATA_PATH)\n",
    "    # Try to load saved MLBs first\n",
    "    try:\n",
    "        mlb_parent = joblib.load(Config.SAVE_MLB_PARENT_PATH)\n",
    "        mlb_child = joblib.load(Config.SAVE_MLB_CHILD_PATH)\n",
    "        print(\"Loaded saved MLBs\")\n",
    "        return mlb_parent, mlb_child\n",
    "    except:\n",
    "        print(\"Creating new MLBs\")\n",
    "\n",
    "        # Construir jerarquía de códigos\n",
    "        all_parents = set()\n",
    "        all_children = set()\n",
    "\n",
    "        for code in df['code']:\n",
    "            levels = parse_code(code.strip())\n",
    "            if len(levels) >= 1: all_parents.add(levels[0])\n",
    "            if len(levels) >= 2: all_children.add(levels[1])\n",
    "\n",
    "        # Inicializar MLB\n",
    "        mlb_parent = MultiLabelBinarizer().fit([all_parents])\n",
    "        mlb_child = MultiLabelBinarizer().fit([all_children])\n",
    "\n",
    "        # Save MLBs\n",
    "        joblib.dump(mlb_parent, Config.SAVE_MLB_PARENT_PATH)\n",
    "        joblib.dump(mlb_child, Config.SAVE_MLB_CHILD_PATH)\n",
    "\n",
    "    print(f\"Padres: {len(mlb_parent.classes_)} - Hijos: {len(mlb_child.classes_)}\")\n",
    "    return mlb_parent, mlb_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PLT DE MÉTRICAS\n",
    "# ====================\n",
    "\n",
    "def plot_metrics():\n",
    "    # Load metrics\n",
    "    metrics_history = pd.read_csv('training_metrics.csv')\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(metrics_history['epoch'], metrics_history['loss'], label='Loss')\n",
    "    plt.plot(metrics_history['epoch'], metrics_history['f1_micro'], label='F1 Micro')\n",
    "    plt.plot(metrics_history['epoch'], metrics_history['f1_macro'], label='F1 Macro')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Training Metrics Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_metrics.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MODELO JERÁRQUICO\n",
    "# ====================\n",
    "\n",
    "class HierarchicalBERT(torch.nn.Module):\n",
    "    def __init__(self, num_parents, num_children):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            self.bert = AutoModel.from_pretrained(Config.SAVE_PATH)\n",
    "            print(\"Loaded saved BERT model\")\n",
    "        except:\n",
    "            self.bert = AutoModel.from_pretrained(Config.MODEL_NAME)\n",
    "            print(\"Using default BERT model\")\n",
    "\n",
    "        hidden_size = self.bert.config.hidden_size  # This will be 768 for base models\n",
    "\n",
    "        self.parent_classifier = torch.nn.Linear(hidden_size, num_parents)\n",
    "        self.child_classifier = torch.nn.Linear(hidden_size + num_parents, num_children)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        # Clasificación padre\n",
    "        parent_logits = self.parent_classifier(pooled)\n",
    "\n",
    "        # Clasificación hijo con contexto de padres\n",
    "        parent_probs = torch.sigmoid(parent_logits)\n",
    "        child_input = torch.cat([pooled, parent_probs], dim=1)\n",
    "        child_logits = self.child_classifier(child_input)\n",
    "\n",
    "        return parent_logits, child_logits, pooled\n",
    "\n",
    "# ====================\n",
    "# Función de pérdida\n",
    "# ====================\n",
    "def hierarchical_loss(parent_logits, child_logits,\n",
    "                      parent_labels, child_labels):\n",
    "\n",
    "    loss_parent = torch.nn.BCEWithLogitsLoss()(parent_logits, parent_labels)\n",
    "    loss_child = torch.nn.BCEWithLogitsLoss()(child_logits, child_labels)\n",
    "\n",
    "    return (Config.HIERARCHICAL_WEIGHTS['parent'] * loss_parent +\n",
    "            Config.HIERARCHICAL_WEIGHTS['child'] * loss_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved MLBs\n",
      "Loaded saved tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 603/603 [01:17<00:00,  7.76it/s, loss=4.13, lr=1.5e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 3.4021 | LR: 1.50E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['A00', 'A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A15', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27', 'A28', 'A30', 'A31', 'A32', 'A33', 'A34', 'A35', 'A36', 'A37', 'A38', 'A39', 'A40', 'A41', 'A42', 'A43', 'A44', 'A46', 'A48', 'A49', 'A50', 'A51', 'A52', 'A53', 'A54', 'A55', 'A56', 'A57', 'A58', 'A59', 'A60', 'A63', 'A64', 'A65', 'A66', 'A67', 'A68', 'A69', 'A70', 'A71', 'A74', 'A75', 'A77', 'A78', 'A79', 'A80', 'A81', 'A82', 'A83', 'A84', 'A85', 'A86', 'A87', 'A88', 'A89', 'A90', 'A91', 'A92', 'A93', 'A94', 'A95', 'A96', 'A98', 'A99', 'B00', 'B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B09', 'B10', 'B15', 'B16', 'B17', 'B18', 'B19', 'B20', 'B25', 'B26', 'B27', 'B30', 'B33', 'B34', 'B35', 'B36', 'B37', 'B38', 'B39', 'B40', 'B41', 'B42', 'B43', 'B44', 'B45', 'B46', 'B47', 'B48', 'B49', 'B50', 'B51', 'B52', 'B53', 'B54', 'B55', 'B56', 'B57', 'B58', 'B59', 'B60', 'B64', 'B65', 'B66', 'B67', 'B68', 'B69', 'B70', 'B71', 'B72', 'B73', 'B74', 'B75', 'B76', 'B77', 'B78', 'B79', 'B80', 'B81', 'B82', 'B83', 'B85', 'B86', 'B87', 'B88', 'B89', 'B90', 'B91', 'B92', 'B94', 'B95', 'B96', 'B97', 'B99', 'C00', 'C01', 'C02', 'C03', 'C04', 'C05', 'C06', 'C07', 'C08', 'C09', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C30', 'C31', 'C32', 'C33', 'C34', 'C37', 'C38', 'C39', 'C40', 'C41', 'C43', 'C44', 'C45', 'C46', 'C47', 'C48', 'C49', 'C4A', 'C50', 'C51', 'C52', 'C53', 'C54', 'C55', 'C56', 'C57', 'C58', 'C60', 'C61', 'C62', 'C63', 'C64', 'C65', 'C66', 'C67', 'C68', 'C69', 'C70', 'C71', 'C72', 'C73', 'C74', 'C75', 'C76', 'C77', 'C78', 'C79', 'C7A', 'C7B', 'C80', 'C81', 'C82', 'C83', 'C84', 'C85', 'C86', 'C88', 'C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'D00', 'D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D09', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'D16', 'D17', 'D18', 'D19', 'D20', 'D21', 'D22', 'D23', 'D24', 'D25', 'D26', 'D27', 'D28', 'D29', 'D30', 'D31', 'D32', 'D33', 'D34', 'D35', 'D36', 'D37', 'D38', 'D39', 'D3A', 'D40', 'D41', 'D42', 'D43', 'D44', 'D45', 'D46', 'D47', 'D48', 'D49', 'D50', 'D51', 'D52', 'D53', 'D55', 'D56', 'D57', 'D58', 'D59', 'D60', 'D61', 'D62', 'D63', 'D64', 'D65', 'D66', 'D67', 'D68', 'D69', 'D70', 'D71', 'D72', 'D73', 'D74', 'D75', 'D76', 'D77', 'D78', 'D80', 'D81', 'D82', 'D83', 'D84', 'D86', 'D89', 'E00', 'E01', 'E02', 'E03', 'E04', 'E05', 'E06', 'E07', 'E08', 'E09', 'E10', 'E11', 'E13', 'E15', 'E16', 'E20', 'E21', 'E22', 'E23', 'E24', 'E25', 'E26', 'E27', 'E28', 'E29', 'E30', 'E31', 'E32', 'E34', 'E35', 'E36', 'E40', 'E41', 'E42', 'E43', 'E44', 'E45', 'E46', 'E50', 'E51', 'E52', 'E53', 'E54', 'E55', 'E56', 'E58', 'E59', 'E60', 'E61', 'E63', 'E64', 'E65', 'E66', 'E67', 'E68', 'E70', 'E71', 'E72', 'E73', 'E74', 'E75', 'E76', 'E77', 'E78', 'E79', 'E80', 'E83', 'E84', 'E85', 'E86', 'E87', 'E88', 'E89', 'F01', 'F02', 'F03', 'F04', 'F05', 'F06', 'F07', 'F09', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21', 'F22', 'F23', 'F24', 'F25', 'F28', 'F29', 'F30', 'F31', 'F32', 'F33', 'F34', 'F39', 'F40', 'F41', 'F42', 'F43', 'F44', 'F45', 'F48', 'F50', 'F51', 'F52', 'F53', 'F54', 'F55', 'F59', 'F60', 'F63', 'F64', 'F65', 'F66', 'F68', 'F69', 'F70', 'F71', 'F72', 'F73', 'F78', 'F79', 'F80', 'F81', 'F82', 'F84', 'F88', 'F89', 'F90', 'F91', 'F93', 'F94', 'F95', 'F98', 'F99', 'G00', 'G01', 'G02', 'G03', 'G04', 'G05', 'G06', 'G07', 'G08', 'G09', 'G10', 'G11', 'G12', 'G13', 'G14', 'G20', 'G21', 'G23', 'G24', 'G25', 'G26', 'G30', 'G31', 'G32', 'G35', 'G36', 'G37', 'G40', 'G43', 'G44', 'G45', 'G46', 'G47', 'G50', 'G51', 'G52', 'G53', 'G54', 'G55', 'G56', 'G57', 'G58', 'G59', 'G60', 'G61', 'G62', 'G63', 'G64', 'G65', 'G70', 'G71', 'G72', 'G73', 'G80', 'G81', 'G82', 'G83', 'G89', 'G90', 'G91', 'G92', 'G93', 'G94', 'G95', 'G96', 'G97', 'G98', 'G99', 'H00', 'H01', 'H02', 'H04', 'H05', 'H10', 'H11', 'H15', 'H16', 'H17', 'H18', 'H20', 'H21', 'H22', 'H25', 'H26', 'H27', 'H28', 'H30', 'H31', 'H32', 'H33', 'H34', 'H35', 'H36', 'H40', 'H42', 'H43', 'H44', 'H46', 'H47', 'H49', 'H50', 'H51', 'H52', 'H53', 'H54', 'H55', 'H57', 'H59', 'H60', 'H61', 'H62', 'H65', 'H66', 'H67', 'H68', 'H69', 'H70', 'H71', 'H72', 'H73', 'H74', 'H75', 'H80', 'H81', 'H82', 'H83', 'H90', 'H91', 'H92', 'H93', 'H94', 'H95', 'I00', 'I01', 'I02', 'I05', 'I06', 'I07', 'I08', 'I09', 'I10', 'I11', 'I12', 'I13', 'I15', 'I16', 'I20', 'I21', 'I22', 'I23', 'I24', 'I25', 'I26', 'I27', 'I28', 'I30', 'I31', 'I32', 'I33', 'I34', 'I35', 'I36', 'I37', 'I38', 'I39', 'I40', 'I41', 'I42', 'I43', 'I44', 'I45', 'I46', 'I47', 'I48', 'I49', 'I50', 'I51', 'I52', 'I5A', 'I60', 'I61', 'I62', 'I63', 'I65', 'I66', 'I67', 'I68', 'I69', 'I70', 'I71', 'I72', 'I73', 'I74', 'I75', 'I76', 'I77', 'I78', 'I79', 'I80', 'I81', 'I82', 'I83', 'I85', 'I86', 'I87', 'I88', 'I89', 'I95', 'I96', 'I97', 'I99', 'J00', 'J01', 'J02', 'J03', 'J04', 'J05', 'J06', 'J09', 'J10', 'J11', 'J12', 'J13', 'J14', 'J15', 'J16', 'J17', 'J18', 'J20', 'J21', 'J22', 'J30', 'J31', 'J32', 'J33', 'J34', 'J35', 'J36', 'J37', 'J38', 'J39', 'J40', 'J41', 'J42', 'J43', 'J44', 'J45', 'J47', 'J60', 'J61', 'J62', 'J63', 'J64', 'J65', 'J66', 'J67', 'J68', 'J69', 'J70', 'J80', 'J81', 'J82', 'J84', 'J85', 'J86', 'J90', 'J91', 'J92', 'J93', 'J94', 'J95', 'J96', 'J98', 'J99', 'K00', 'K01', 'K02', 'K03', 'K04', 'K05', 'K06', 'K08', 'K09', 'K11', 'K12', 'K13', 'K14', 'K20', 'K21', 'K22', 'K23', 'K25', 'K26', 'K27', 'K28', 'K29', 'K30', 'K31', 'K35', 'K36', 'K37', 'K38', 'K40', 'K41', 'K42', 'K43', 'K44', 'K45', 'K46', 'K50', 'K51', 'K52', 'K55', 'K56', 'K57', 'K58', 'K59', 'K60', 'K61', 'K62', 'K63', 'K64', 'K65', 'K66', 'K67', 'K68', 'K70', 'K71', 'K72', 'K73', 'K74', 'K75', 'K76', 'K77', 'K80', 'K81', 'K82', 'K83', 'K85', 'K86', 'K87', 'K90', 'K91', 'K92', 'K94', 'K95', 'L00', 'L01', 'L02', 'L03', 'L04', 'L05', 'L08', 'L10', 'L11', 'L12', 'L13', 'L14', 'L20', 'L21', 'L22', 'L23', 'L24', 'L25', 'L26', 'L27', 'L28', 'L29', 'L30', 'L40', 'L41', 'L42', 'L43', 'L44', 'L45', 'L49', 'L50', 'L51', 'L52', 'L53', 'L54', 'L55', 'L56', 'L57', 'L58', 'L59', 'L60', 'L62', 'L63', 'L64', 'L65', 'L66', 'L67', 'L68', 'L70', 'L71', 'L72', 'L73', 'L74', 'L75', 'L76', 'L80', 'L81', 'L82', 'L83', 'L84', 'L85', 'L86', 'L87', 'L88', 'L89', 'L90', 'L91', 'L92', 'L93', 'L94', 'L95', 'L97', 'L98', 'L99', 'M00', 'M01', 'M02', 'M04', 'M05', 'M06', 'M07', 'M08', 'M10', 'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'M19', 'M1A', 'M20', 'M21', 'M22', 'M23', 'M24', 'M25', 'M26', 'M27', 'M30', 'M31', 'M32', 'M33', 'M34', 'M35', 'M36', 'M40', 'M41', 'M42', 'M43', 'M45', 'M46', 'M47', 'M48', 'M49', 'M50', 'M51', 'M53', 'M54', 'M60', 'M61', 'M62', 'M63', 'M65', 'M66', 'M67', 'M70', 'M71', 'M72', 'M75', 'M76', 'M77', 'M79', 'M80', 'M81', 'M83', 'M84', 'M85', 'M86', 'M87', 'M88', 'M89', 'M90', 'M91', 'M92', 'M93', 'M94', 'M95', 'M96', 'M97', 'M99', 'N00', 'N01', 'N02', 'N03', 'N04', 'N05', 'N06', 'N07', 'N08', 'N10', 'N11', 'N12', 'N13', 'N14', 'N15', 'N16', 'N17', 'N18', 'N19', 'N20', 'N21', 'N22', 'N23', 'N25', 'N26', 'N27', 'N28', 'N29', 'N30', 'N31', 'N32', 'N33', 'N34', 'N35', 'N36', 'N37', 'N39', 'N40', 'N41', 'N42', 'N43', 'N44', 'N45', 'N46', 'N47', 'N48', 'N49', 'N50', 'N51', 'N52', 'N53', 'N60', 'N61', 'N62', 'N63', 'N64', 'N65', 'N70', 'N71', 'N72', 'N73', 'N74', 'N75', 'N76', 'N77', 'N80', 'N81', 'N82', 'N83', 'N84', 'N85', 'N86', 'N87', 'N88', 'N89', 'N90', 'N91', 'N92', 'N93', 'N94', 'N95', 'N96', 'N97', 'N98', 'N99', 'O00', 'O01', 'O02', 'O03', 'O04', 'O07', 'O08', 'O09', 'O10', 'O11', 'O12', 'O13', 'O14', 'O15', 'O16', 'O20', 'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O28', 'O29', 'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47', 'O48', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65', 'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74', 'O75', 'O76', 'O77', 'O80', 'O82', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92', 'O94', 'O98', 'O99', 'O9A', 'P00', 'P01', 'P02', 'P03', 'P04', 'P05', 'P07', 'P08', 'P09', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P19', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', 'P28', 'P29', 'P35', 'P36', 'P37', 'P38', 'P39', 'P50', 'P51', 'P52', 'P53', 'P54', 'P55', 'P56', 'P57', 'P58', 'P59', 'P60', 'P61', 'P70', 'P71', 'P72', 'P74', 'P76', 'P77', 'P78', 'P80', 'P81', 'P83', 'P84', 'P90', 'P91', 'P92', 'P93', 'P94', 'P95', 'P96', 'Q00', 'Q01', 'Q02', 'Q03', 'Q04', 'Q05', 'Q06', 'Q07', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q50', 'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q60', 'Q61', 'Q62', 'Q63', 'Q64', 'Q65', 'Q66', 'Q67', 'Q68', 'Q69', 'Q70', 'Q71', 'Q72', 'Q73', 'Q74', 'Q75', 'Q76', 'Q77', 'Q78', 'Q79', 'Q80', 'Q81', 'Q82', 'Q83', 'Q84', 'Q85', 'Q86', 'Q87', 'Q89', 'Q90', 'Q91', 'Q92', 'Q93', 'Q95', 'Q96', 'Q97', 'Q98', 'Q99', 'R00', 'R01', 'R03', 'R04', 'R05', 'R06', 'R07', 'R09', 'R10', 'R11', 'R12', 'R13', 'R14', 'R15', 'R16', 'R17', 'R18', 'R19', 'R20', 'R21', 'R22', 'R23', 'R25', 'R26', 'R27', 'R29', 'R30', 'R31', 'R32', 'R33', 'R34', 'R35', 'R36', 'R37', 'R39', 'R40', 'R41', 'R42', 'R43', 'R44', 'R45', 'R46', 'R47', 'R48', 'R49', 'R50', 'R51', 'R52', 'R53', 'R54', 'R55', 'R56', 'R57', 'R58', 'R59', 'R60', 'R61', 'R62', 'R63', 'R64', 'R65', 'R68', 'R69', 'R70', 'R71', 'R73', 'R74', 'R75', 'R76', 'R77', 'R78', 'R79', 'R80', 'R81', 'R82', 'R83', 'R84', 'R85', 'R86', 'R87', 'R88', 'R89', 'R90', 'R91', 'R92', 'R93', 'R94', 'R97', 'R99', 'S00', 'S01', 'S02', 'S03', 'S04', 'S05', 'S06', 'S07', 'S08', 'S09', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S19', 'S20', 'S21', 'S22', 'S23', 'S24', 'S25', 'S26', 'S27', 'S28', 'S29', 'S30', 'S31', 'S32', 'S33', 'S34', 'S35', 'S36', 'S37', 'S38', 'S39', 'S40', 'S41', 'S42', 'S43', 'S44', 'S45', 'S46', 'S47', 'S48', 'S49', 'S50', 'S51', 'S52', 'S53', 'S54', 'S55', 'S56', 'S57', 'S58', 'S59', 'S60', 'S61', 'S62', 'S63', 'S64', 'S65', 'S66', 'S67', 'S68', 'S69', 'S70', 'S71', 'S72', 'S73', 'S74', 'S75', 'S76', 'S77', 'S78', 'S79', 'S80', 'S81', 'S82', 'S83', 'S84', 'S85', 'S86', 'S87', 'S88', 'S89', 'S90', 'S91', 'S92', 'S93', 'S94', 'S95', 'S96', 'S97', 'S98', 'S99', 'T07', 'T14', 'T15', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21', 'T22', 'T23', 'T24', 'T25', 'T26', 'T27', 'T28', 'T30', 'T31', 'T32', 'T33', 'T34', 'T36', 'T37', 'T38', 'T39', 'T40', 'T41', 'T42', 'T43', 'T44', 'T45', 'T46', 'T47', 'T48', 'T49', 'T50', 'T51', 'T52', 'T53', 'T54', 'T55', 'T56', 'T57', 'T58', 'T59', 'T60', 'T61', 'T62', 'T63', 'T64', 'T65', 'T66', 'T67', 'T68', 'T69', 'T70', 'T71', 'T73', 'T74', 'T75', 'T76', 'T78', 'T79', 'T80', 'T81', 'T82', 'T83', 'T84', 'T85', 'T86', 'T87', 'T88', 'U07', 'U09', 'V00', 'V01', 'V02', 'V03', 'V04', 'V05', 'V06', 'V09', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'W00', 'W01', 'W03', 'W04', 'W05', 'W06', 'W07', 'W08', 'W09', 'W10', 'W11', 'W12', 'W13', 'W14', 'W15', 'W16', 'W17', 'W18', 'W19', 'W20', 'W21', 'W22', 'W23', 'W24', 'W25', 'W26', 'W27', 'W28', 'W29', 'W30', 'W31', 'W32', 'W33', 'W34', 'W35', 'W36', 'W37', 'W38', 'W39', 'W40', 'W42', 'W45', 'W46', 'W49', 'W50', 'W51', 'W52', 'W53', 'W54', 'W55', 'W56', 'W57', 'W58', 'W59', 'W60', 'W61', 'W62', 'W64', 'W65', 'W67', 'W69', 'W73', 'W74', 'W85', 'W86', 'W88', 'W89', 'W90', 'W92', 'W93', 'W94', 'W99', 'X00', 'X01', 'X02', 'X03', 'X04', 'X05', 'X06', 'X08', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X30', 'X31', 'X32', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X50', 'X52', 'X58', 'X71', 'X72', 'X73', 'X74', 'X75', 'X76', 'X77', 'X78', 'X79', 'X80', 'X81', 'X82', 'X83', 'X92', 'X93', 'X94', 'X95', 'X96', 'X97', 'X98', 'X99', 'Y00', 'Y01', 'Y02', 'Y03', 'Y04', 'Y07', 'Y08', 'Y09', 'Y21', 'Y22', 'Y23', 'Y24', 'Y25', 'Y26', 'Y27', 'Y28', 'Y29', 'Y30', 'Y31', 'Y32', 'Y33', 'Y35', 'Y36', 'Y37', 'Y38', 'Y62', 'Y63', 'Y64', 'Y65', 'Y66', 'Y69', 'Y70', 'Y71', 'Y72', 'Y73', 'Y74', 'Y75', 'Y76', 'Y77', 'Y78', 'Y79', 'Y80', 'Y81', 'Y82', 'Y83', 'Y84', 'Y90', 'Y92', 'Y93', 'Y95', 'Y99', 'Z00', 'Z01', 'Z02', 'Z03', 'Z04', 'Z05', 'Z08', 'Z09', 'Z11', 'Z12', 'Z13', 'Z14', 'Z15', 'Z16', 'Z17', 'Z18', 'Z19', 'Z20', 'Z21', 'Z22', 'Z23', 'Z28', 'Z29', 'Z30', 'Z31', 'Z32', 'Z33', 'Z34', 'Z36', 'Z37', 'Z38', 'Z39', 'Z3A', 'Z40', 'Z41', 'Z42', 'Z43', 'Z44', 'Z45', 'Z46', 'Z47', 'Z48', 'Z49', 'Z51', 'Z52', 'Z53', 'Z55', 'Z56', 'Z57', 'Z58', 'Z59', 'Z60', 'Z62', 'Z63', 'Z64', 'Z65', 'Z66', 'Z67', 'Z68', 'Z69', 'Z70', 'Z71', 'Z72', 'Z73', 'Z74', 'Z75', 'Z76', 'Z77', 'Z78', 'Z79', 'Z80', 'Z81', 'Z82', 'Z83', 'Z84', 'Z85', 'Z86', 'Z87', 'Z88', 'Z89', 'Z90', 'Z91', 'Z92', 'Z93', 'Z94', 'Z95', 'Z96', 'Z97', 'Z98', 'Z99']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A01.00', 'A01.4', 'A02.9', 'A03.8', 'A04.5', 'A04.8', 'A15.0', 'A15.4', 'A15.6', 'A15.9', 'A17.81', 'A18.09', 'A18.10', 'A18.12', 'A18.15', 'A18.2', 'A18.4', 'A18.50', 'A23.9', 'A28.1', 'A31.9', 'A32.11', 'A32.9', 'A38.9', 'A40.3', 'A41.02', 'A41.1', 'A41.81', 'A41.9', 'A43.9', 'A44.0', 'A44.9', 'A48.1', 'A49.1', 'A49.8', 'A49.9', 'A53.9', 'A54.9', 'A63.0', 'A69.20', 'A74.9', 'A79.9', 'A87.2', 'B00.9', 'B01.9', 'B02.21', 'B02.29', 'B02.39', 'B05.9', 'B06.9', 'B07.9', 'B08.3', 'B10.89', 'B15.9', 'B17.9', 'B18.2', 'B19.10', 'B19.20', 'B19.9', 'B25.9', 'B27.00', 'B27.90', 'B27.99', 'B30.0', 'B30.9', 'B33.3', 'B34.1', 'B34.8', 'B35.2', 'B35.9', 'B37.0', 'B37.2', 'B37.3', 'B37.81', 'B37.9', 'B44.9', 'B45.2', 'B45.9', 'B46.5', 'B48.8', 'B55.9', 'B57.2', 'B58.2', 'B58.9', 'B65.0', 'B65.9', 'B67.90', 'B67.99', 'B69.0', 'B69.9', 'B74.9', 'B83.0', 'B95.0', 'B95.2', 'B95.4', 'B95.5', 'B95.61', 'B95.62', 'B95.7', 'B95.8', 'B96.0', 'B96.1', 'B96.20', 'B96.3', 'B96.4', 'B96.5', 'B96.7', 'B96.81', 'B96.89', 'B97.0', 'B97.10', 'B97.12', 'B97.29', 'B97.4', 'B97.6', 'B97.7', 'B99.9', 'C02.1', 'C02.9', 'C04.9', 'C08.0', 'C10.9', 'C15.9', 'C16.0', 'C16.9', 'C17.1', 'C18.6', 'C18.7', 'C18.9', 'C21.0', 'C22.0', 'C22.1', 'C26.0', 'C31.2', 'C34.9', 'C34.90', 'C34.91', 'C40.20', 'C41.0', 'C41.1', 'C43.9', 'C44.311', 'C44.49', 'C48.0', 'C48.2', 'C49.21', 'C49.5', 'C49.A', 'C49.A2', 'C50.312', 'C50.519', 'C50.9', 'C50.91', 'C50.912', 'C50.919', 'C53.9', 'C54.1', 'C56.2', 'C60.1', 'C62.9', 'C62.90', 'C62.91', 'C62.92', 'C63.10', 'C63.8', 'C64.1', 'C64.2', 'C64.9', 'C65.9', 'C66.9', 'C67.2', 'C67.7', 'C67.9', 'C68.0', 'C69.32', 'C70.9', 'C71.0', 'C72.30', 'C74.90', 'C74.92', 'C75.0', 'C76.3', 'C77.2', 'C77.3', 'C77.8', 'C77.9', 'C78.00', 'C78.01', 'C78.02', 'C78.1', 'C78.39', 'C78.5', 'C78.6', 'C78.7', 'C78.89', 'C79.00', 'C79.02', 'C79.2', 'C79.31', 'C79.49', 'C79.51', 'C79.52', 'C79.70', 'C79.71', 'C79.72', 'C79.81', 'C79.82', 'C79.89', 'C79.9', 'C80.0', 'C80.1', 'C81.1', 'C83.0', 'C83.1', 'C83.30', 'C83.39', 'C83.70', 'C84.49', 'C84.A', 'C85.9', 'C85.90', 'C85.99', 'C88.4', 'C90.0', 'C90.3', 'C91.90', 'C92.10', 'C94.6', 'C96.6', 'D09.0', 'D10.30', 'D11.0', 'D12.1', 'D12.6', 'D15.1', 'D16.22', 'D16.5', 'D17.23', 'D17.9', 'D18.00', 'D18.03', 'D18.09', 'D18.1', 'D22.9', 'D23.11', 'D23.9', 'D24.1', 'D24.9', 'D29.1', 'D29.30', 'D29.31', 'D30.00', 'D30.01', 'D30.02', 'D30.3', 'D31.62', 'D31.9', 'D32.0', 'D32.9', 'D35.00', 'D35.02', 'D35.1', 'D36.11', 'D37.030', 'D37.8', 'D40.10', 'D40.11', 'D40.8', 'D41.00', 'D41.02', 'D43.1', 'D44.10', 'D44.12', 'D44.2', 'D44.6', 'D44.7', 'D47.1', 'D47.2', 'D47.3', 'D47.9', 'D48.0', 'D48.1', 'D49.0', 'D49.1', 'D49.2', 'D49.3', 'D49.4', 'D49.511', 'D49.512', 'D49.519', 'D49.59', 'D49.7', 'D49.89', 'D50.0', 'D50.9', 'D53.1', 'D58.9', 'D61.818', 'D63.1', 'D64.9', 'D68.51', 'D68.59', 'D68.61', 'D68.9', 'D69.0', 'D69.2', 'D69.3', 'D69.41', 'D69.6', 'D69.9', 'D70.9', 'D72.0', 'D72.1', 'D72.810', 'D72.819', 'D72.821', 'D72.822', 'D72.829', 'D73.1', 'D73.3', 'D73.5', 'D73.89', 'D74.8', 'D75.89', 'D76.3', 'D80.1', 'D84.9', 'D86.9', 'D89.2', 'E03.8', 'E03.9', 'E04.1', 'E04.2', 'E04.9', 'E05.00', 'E05.80', 'E05.90', 'E06.3', 'E07.9', 'E10.10', 'E10.9', 'E11.22', 'E11.319', 'E11.359', 'E11.42', 'E11.622', 'E11.628', 'E11.9', 'E13.9', 'E16.2', 'E21.0', 'E21.3', 'E21.5', 'E23.0', 'E23.2', 'E27.0', 'E27.8', 'E27.9', 'E29.1', 'E44.0', 'E44.1', 'E50.9', 'E51.9', 'E53.1', 'E53.8', 'E56.9', 'E63.9', 'E66.01', 'E66.3', 'E66.9', 'E72.01', 'E74.00', 'E74.04', 'E75.29', 'E75.5', 'E77.8', 'E78.00', 'E78.1', 'E78.5', 'E79.0', 'E80.20', 'E80.7', 'E83.119', 'E83.39', 'E83.41', 'E83.42', 'E83.51', 'E83.52', 'E83.59', 'E83.81', 'E85.4', 'E85.9', 'E86.0', 'E87.0', 'E87.1', 'E87.2', 'E87.3', 'E87.5', 'E87.6', 'E88.09', 'E88.9', 'E89.0', 'F02.80', 'F10.10', 'F10.20', 'F10.21', 'F10.23', 'F11.20', 'F12.10', 'F12.20', 'F14.10', 'F14.20', 'F17.200', 'F17.210', 'F17.290', 'F19.20', 'F19.21', 'F20.5', 'F25.0', 'F30.9', 'F31.9', 'F32.9', 'F34.1', 'F40.9', 'F41.8', 'F41.9', 'F43.20', 'F43.9', 'F45.29', 'F50.2', 'F60.3', 'F63.9', 'F65.3', 'F80.81', 'F84.0', 'F90.9', 'F98.8', 'G00.1', 'G03.9', 'G04.1', 'G04.90', 'G06.0', 'G06.2', 'G12.20', 'G12.21', 'G24.5', 'G25.0', 'G25.3', 'G30.9', 'G31.84', 'G40.109', 'G40.119', 'G40.309', 'G40.401', 'G40.409', 'G40.909', 'G44.209', 'G45.9', 'G47.00', 'G47.30', 'G47.32', 'G47.33', 'G47.9', 'G50.0', 'G51.0', 'G54.6', 'G56.92', 'G57.00', 'G57.01', 'G57.42', 'G58.9', 'G61.0', 'G62.9', 'G70.00', 'G71.8', 'G72.3', 'G72.49', 'G72.9', 'G81.14', 'G81.90', 'G81.91', 'G81.94', 'G82.20', 'G82.21', 'G83.14', 'G83.2', 'G83.9', 'G89.29', 'G90.2', 'G90.50', 'G90.511', 'G91.8', 'G91.9', 'G93.0', 'G93.2', 'G93.40', 'G93.5', 'G93.6', 'G93.9', 'G95.20', 'G95.9', 'G96.0', 'G97.2', 'H00.19', 'H01.009', 'H01.8', 'H02.40', 'H02.401', 'H02.402', 'H02.409', 'H02.411', 'H02.841', 'H02.843', 'H02.844', 'H02.846', 'H02.849', 'H02.9', 'H04.20', 'H04.202', 'H05.2', 'H05.20', 'H05.221', 'H05.231', 'H10.9', 'H11.001', 'H11.002', 'H11.42', 'H11.421', 'H11.422', 'H11.429', 'H11.439', 'H15.00', 'H15.032', 'H15.092', 'H16.0', 'H16.001', 'H16.012', 'H16.07', 'H16.071', 'H16.9', 'H17.12', 'H17.9', 'H18.20', 'H18.89', 'H18.891', 'H18.9', 'H20.052', 'H20.059', 'H20.9', 'H21.26', 'H21.309', 'H21.42', 'H21.50', 'H21.501', 'H21.509', 'H21.542', 'H21.9', 'H25.1', 'H26.8', 'H26.9', 'H27.10', 'H30.14', 'H30.89', 'H30.93', 'H31.101', 'H31.103', 'H31.309', 'H31.32', 'H33.10', 'H33.101', 'H33.102', 'H33.19', 'H33.20', 'H33.21', 'H33.22', 'H35.00', 'H35.349', 'H35.50', 'H35.6', 'H35.61', 'H35.62', 'H35.81', 'H35.89', 'H35.9', 'H40.10', 'H40.11', 'H40.83', 'H40.9', 'H43.1', 'H43.12', 'H43.13', 'H44.00', 'H44.001', 'H44.002', 'H44.009', 'H44.139', 'H44.40', 'H46.00', 'H46.9', 'H47.091', 'H47.092', 'H47.10', 'H49.02', 'H49.11', 'H49.21', 'H49.22', 'H49.23', 'H49.9', 'H50.011', 'H50.012', 'H50.10', 'H50.112', 'H50.21', 'H50.22', 'H50.9', 'H52.1', 'H52.7', 'H53.14', 'H53.142', 'H53.143', 'H53.149', 'H53.15', 'H53.2', 'H53.30', 'H53.40', 'H53.462', 'H53.8', 'H53.9', 'H54.0', 'H54.2', 'H54.3', 'H54.61', 'H54.62', 'H54.7', 'H55.00', 'H55.01', 'H57.02', 'H57.03', 'H57.04', 'H57.1', 'H57.10', 'H57.11', 'H57.12', 'H57.13', 'H57.8', 'H57.9', 'H59.03', 'H59.033', 'H60.91', 'H80.90', 'H90.12', 'H90.5', 'H91.20', 'H91.3', 'H91.90', 'H91.91', 'H91.93', 'H92.01', 'H92.09', 'H93.11', 'H93.19', 'I05.0', 'I05.9', 'I11.9', 'I12.0', 'I12.9', 'I20.8', 'I20.9', 'I21.11', 'I21.19', 'I21.29', 'I21.3', 'I23.7', 'I24.9', 'I25.10', 'I25.2', 'I25.9', 'I26.99', 'I27.2', 'I28.1', 'I30.9', 'I31.2', 'I31.3', 'I31.4', 'I33.0', 'I34.0', 'I34.1', 'I35.0', 'I35.8', 'I35.9', 'I37.0', 'I42.0', 'I42.9', 'I44.2', 'I44.30', 'I45.10', 'I46.9', 'I47.1', 'I48.0', 'I48.2', 'I48.91', 'I48.92', 'I49.01', 'I49.9', 'I50.9', 'I51.4', 'I51.7', 'I51.9', 'I60.9', 'I61.5', 'I61.8', 'I61.9', 'I62.00', 'I62.01', 'I62.03', 'I62.9', 'I63.512', 'I63.519', 'I63.9', 'I65.21', 'I65.8', 'I66.9', 'I67.1', 'I67.82', 'I69.354', 'I70.0', 'I70.90', 'I71.00', 'I71.2', 'I71.4', 'I72.9', 'I73.8', 'I74.8', 'I74.9', 'I75.81', 'I75.89', 'I77.0', 'I77.1', 'I77.6', 'I77.9', 'I78.1', 'I80.8', 'I82.0', 'I82.210', 'I82.220', 'I82.3', 'I82.40', 'I82.401', 'I82.402', 'I82.409', 'I82.411', 'I82.431', 'I82.439', 'I82.90', 'I83.90', 'I83.93', 'I85.00', 'I85.01', 'I86.1', 'I86.4', 'I87.1', 'I87.2', 'I87.8', 'I88.1', 'I88.9', 'I89.0', 'I89.1', 'I89.8', 'I95.9', 'I99.8', 'J01.90', 'J02.9', 'J03.90', 'J03.91', 'J11.0', 'J11.1', 'J12.0', 'J18.1', 'J18.9', 'J21.8', 'J21.9', 'J30.1', 'J32.0', 'J32.4', 'J32.9', 'J34.1', 'J34.3', 'J34.89', 'J35.1', 'J38.1', 'J38.4', 'J39.8', 'J43.9', 'J44.9', 'J45.909', 'J47.9', 'J62.8', 'J69.0', 'J81.0', 'J81.1', 'J84.01', 'J84.10', 'J84.89', 'J85.2', 'J86.0', 'J93.9', 'J94.0', 'J94.2', 'J94.8', 'J96.00', 'J96.90', 'J96.92', 'J98.01', 'J98.11', 'J98.2', 'J98.4', 'J98.51', 'J98.8', 'K00.0', 'K00.1', 'K01.0', 'K02.9', 'K04.7', 'K05.10', 'K06.1', 'K06.2', 'K06.8', 'K08.109', 'K08.89', 'K08.9', 'K09.0', 'K11.1', 'K11.20', 'K11.6', 'K11.7', 'K11.9', 'K12.0', 'K12.1', 'K12.2', 'K13.0', 'K13.21', 'K13.29', 'K13.70', 'K13.79', 'K14.5', 'K14.6', 'K14.9', 'K20.9', 'K21.9', 'K22.2', 'K22.70', 'K22.8', 'K22.9', 'K25.9', 'K26.4', 'K26.9', 'K27.9', 'K31.1', 'K31.5', 'K31.7', 'K31.819', 'K31.89', 'K31.9', 'K35.2', 'K35.80', 'K38.8', 'K40.20', 'K40.30', 'K40.90', 'K42.9', 'K44.9', 'K46.9', 'K50.00', 'K50.90', 'K51.00', 'K51.90', 'K52.3', 'K52.81', 'K52.82', 'K52.9', 'K55.049', 'K55.059', 'K55.1', 'K55.20', 'K55.21', 'K55.9', 'K56.1', 'K56.2', 'K56.41', 'K56.60', 'K56.69', 'K57.00', 'K57.10', 'K57.20', 'K57.32', 'K57.90', 'K57.92', 'K59.00', 'K59.39', 'K59.8', 'K59.9', 'K60.3', 'K62.1', 'K62.5', 'K62.6', 'K62.7', 'K62.89', 'K63.1', 'K63.2', 'K63.5', 'K63.9', 'K64.8', 'K64.9', 'K65.0', 'K65.1', 'K65.3', 'K65.8', 'K65.9', 'K66.0', 'K66.1', 'K66.8', 'K68.12', 'K68.19', 'K68.9', 'K70.10', 'K70.30', 'K70.9', 'K71.6', 'K72.00', 'K72.90', 'K74.0', 'K74.60', 'K75.0', 'K75.4', 'K75.9', 'K76.0', 'K76.6', 'K76.7', 'K76.81', 'K76.89', 'K76.9', 'K80.10', 'K80.20', 'K80.5', 'K80.50', 'K80.51', 'K81.0', 'K82.8', 'K83.0', 'K83.1', 'K83.3', 'K83.8', 'K85.20', 'K85.90', 'K86.0', 'K86.1', 'K86.3', 'K86.89', 'K86.9', 'K90.0', 'K90.9', 'K91.7', 'K92.0', 'K92.1', 'K92.2', 'L02.01', 'L02.211', 'L02.31', 'L02.41', 'L02.91', 'L03.115', 'L03.90', 'L08.9', 'L10.0', 'L11.9', 'L21.9', 'L25.9', 'L28.2', 'L29.0', 'L29.9', 'L30.9', 'L40.53', 'L40.9', 'L43.9', 'L51.1', 'L51.2', 'L51.9', 'L53.9', 'L57.0', 'L60.8', 'L60.9', 'L65.9', 'L68.0', 'L71.9', 'L74.0', 'L76.3', 'L81.9', 'L85.8', 'L85.9', 'L89.150', 'L90.5', 'L90.8', 'L91.0', 'L92.9', 'L93.0', 'L97.909', 'L97.919', 'L98.0', 'L98.49', 'L98.8', 'L98.9', 'M00.071', 'M00.9', 'M05.9', 'M06.9', 'M08.90', 'M08.961', 'M08.99', 'M13.0', 'M15.9', 'M16.0', 'M19.90', 'M21.959', 'M24.60', 'M24.641', 'M24.642', 'M25.40', 'M25.451', 'M25.50', 'M25.511', 'M25.512', 'M25.519', 'M25.531', 'M25.532', 'M25.541', 'M25.551', 'M25.552', 'M25.561', 'M25.562', 'M25.569', 'M25.571', 'M25.60', 'M25.9', 'M26.02', 'M26.04', 'M26.09', 'M26.30', 'M26.32', 'M26.601', 'M26.609', 'M26.619', 'M26.9', 'M27.2', 'M30.3', 'M31.0', 'M31.1', 'M31.6', 'M32.9', 'M35.3', 'M41.9', 'M43.6', 'M45.9', 'M46.40', 'M46.47', 'M46.90', 'M46.96', 'M47.895', 'M47.896', 'M47.9', 'M48.00', 'M48.04', 'M51.24', 'M54.2', 'M54.40', 'M54.41', 'M54.5', 'M54.6', 'M54.9', 'M60.059', 'M60.9', 'M61.10', 'M62.50', 'M62.81', 'M62.82', 'M62.838', 'M62.89', 'M65.9', 'M71.30', 'M75.90', 'M79.1', 'M79.2', 'M79.60', 'M79.604', 'M79.605', 'M79.621', 'M79.641', 'M79.643', 'M79.644', 'M79.645', 'M79.652', 'M79.659', 'M79.671', 'M79.672', 'M79.673', 'M79.7', 'M80.08X', 'M81.0', 'M83.9', 'M84.30X', 'M84.453', 'M84.529', 'M85.2', 'M85.50', 'M85.60', 'M85.8', 'M85.80', 'M86.60', 'M86.68', 'M86.9', 'M87.80', 'M88.832', 'M88.9', 'M89.072', 'M89.549', 'M89.59', 'M89.70', 'M89.8X', 'M89.8X9', 'M89.9', 'M94.359', 'N02.8', 'N03.9', 'N04.9', 'N05.5', 'N05.7', 'N05.9', 'N11.9', 'N13.30', 'N13.5', 'N13.6', 'N13.70', 'N13.8', 'N13.9', 'N17.0', 'N17.9', 'N18.2', 'N18.3', 'N18.4', 'N18.5', 'N18.6', 'N18.9', 'N20.0', 'N20.1', 'N20.9', 'N25.81', 'N26.1', 'N26.9', 'N28.0', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.8', 'N30.90', 'N31.9', 'N32.0', 'N32.1', 'N32.3', 'N32.89', 'N32.9', 'N34.2', 'N36.0', 'N36.8', 'N39.0', 'N39.44', 'N40.0', 'N40.2', 'N41.0', 'N41.1', 'N43.3', 'N44.00', 'N44.2', 'N44.8', 'N45.1', 'N45.2', 'N45.3', 'N45.4', 'N48.21', 'N48.29', 'N48.30', 'N48.6', 'N48.81', 'N48.89', 'N48.9', 'N49.2', 'N50.0', 'N50.1', 'N50.3', 'N50.811', 'N50.812', 'N50.819', 'N50.82', 'N50.89', 'N50.9', 'N52.9', 'N53.12', 'N60.01', 'N60.02', 'N60.11', 'N60.12', 'N60.19', 'N64.4', 'N64.89', 'N64.9', 'N80.8', 'N80.9', 'N83.00', 'N83.9', 'N85.8', 'N89.5', 'N90.89', 'N91.0', 'N92.1', 'N93.9', 'N94.89', 'N97.9', 'O02.0', 'O03.9', 'O21.0', 'O24.419', 'O32.1', 'O40.9XX0', 'O41.0', 'O41.00X', 'O41.1290', 'O42.912', 'O42.92', 'O47.9', 'O65.0', 'O75.9', 'O99.11', 'P52.3', 'P81.9', 'P91.60', 'Q03.1', 'Q03.9', 'Q04.0', 'Q05.9', 'Q07.00', 'Q07.8', 'Q10.0', 'Q12.4', 'Q13.0', 'Q13.4', 'Q21.1', 'Q23.1', 'Q24.8', 'Q24.9', 'Q27.30', 'Q27.9', 'Q28.2', 'Q32.4', 'Q35.3', 'Q37.9', 'Q38.2', 'Q42.9', 'Q44.6', 'Q44.7', 'Q45.0', 'Q51.0', 'Q51.3', 'Q51.811', 'Q52.0', 'Q53.10', 'Q55.29', 'Q60.6', 'Q61.02', 'Q61.19', 'Q61.3', 'Q61.4', 'Q62.8', 'Q63.1', 'Q63.9', 'Q64.4', 'Q67.0', 'Q68.0', 'Q70.9', 'Q75.0', 'Q75.3', 'Q76.49', 'Q78.2', 'Q79.1', 'Q85.00', 'Q85.01', 'Q85.1', 'Q85.8', 'Q85.9', 'Q87.2', 'Q87.3', 'Q87.81', 'Q89.2', 'Q98.4', 'R00.0', 'R00.1', 'R00.2', 'R01.1', 'R04.0', 'R04.2', 'R04.89', 'R06.00', 'R06.01', 'R06.09', 'R06.1', 'R06.4', 'R06.6', 'R06.82', 'R06.89', 'R07.0', 'R07.2', 'R07.81', 'R07.89', 'R07.9', 'R09.02', 'R09.2', 'R10.0', 'R10.10', 'R10.12', 'R10.13', 'R10.2', 'R10.30', 'R10.31', 'R10.32', 'R10.33', 'R10.811', 'R10.812', 'R10.813', 'R10.814', 'R10.815', 'R10.816', 'R10.817', 'R10.819', 'R10.83', 'R10.84', 'R10.9', 'R11.0', 'R11.10', 'R11.12', 'R11.14', 'R11.2', 'R13.10', 'R14.0', 'R16.0', 'R16.1', 'R16.2', 'R18.0', 'R18.8', 'R19.0', 'R19.00', 'R19.01', 'R19.02', 'R19.03', 'R19.04', 'R19.06', 'R19.2', 'R19.5', 'R19.7', 'R19.8', 'R20.0', 'R20.1', 'R20.2', 'R20.8', 'R20.9', 'R22.0', 'R22.1', 'R22.2', 'R22.9', 'R23.0', 'R23.1', 'R23.3', 'R23.4', 'R23.8', 'R25.1', 'R25.2', 'R25.3', 'R26.0', 'R26.2', 'R26.81', 'R26.89', 'R26.9', 'R27.0', 'R27.8', 'R29.2', 'R29.6', 'R29.723', 'R29.810', 'R29.898', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R33.9', 'R35.0', 'R35.1', 'R35.8', 'R36.1', 'R39.12', 'R39.14', 'R39.15', 'R39.198', 'R39.89', 'R39.9', 'R40.0', 'R40.1', 'R40.20', 'R40.241', 'R40.2410', 'R40.2420', 'R40.2421', 'R40.243', 'R40.2430', 'R40.3', 'R40.4', 'R41.0', 'R41.3', 'R41.840', 'R41.843', 'R43.2', 'R43.9', 'R44.0', 'R44.1', 'R44.3', 'R44.9', 'R45.0', 'R45.1', 'R45.3', 'R45.4', 'R46.0', 'R47.01', 'R47.02', 'R47.1', 'R47.89', 'R47.9', 'R48.2', 'R49.0', 'R49.1', 'R50.81', 'R50.82', 'R50.9', 'R53.1', 'R53.81', 'R53.83', 'R56.00', 'R56.9', 'R57.0', 'R57.1', 'R57.9', 'R59.0', 'R59.9', 'R60.0', 'R60.1', 'R60.9', 'R63.0', 'R63.1', 'R63.3', 'R63.4', 'R65.20', 'R65.21', 'R68.83', 'R68.84', 'R68.89', 'R73.9', 'R74.0', 'R76.0', 'R76.11', 'R78.81', 'R79.82', 'R80.9', 'R82.2', 'R82.3', 'R91.1', 'R91.8', 'R97.1', 'R97.20', 'R97.8', 'S00.32X', 'S00.33X', 'S00.522', 'S00.532', 'S01.101', 'S01.20X', 'S01.501', 'S01.512', 'S01.80X', 'S01.95X', 'S02.0XX', 'S02.19X', 'S02.5XX', 'S02.601', 'S02.652', 'S03.00X', 'S03.2XX', 'S05.8X2', 'S05.9', 'S05.92X', 'S06.0X0', 'S06.2X', 'S06.36', 'S06.9', 'S06.9X', 'S06.9X0', 'S09.90X', 'S09.92X', 'S11.80X', 'S11.90X', 'S11.91X', 'S19.9X', 'S20.92X', 'S22.39X', 'S22.4', 'S23.163', 'S27.329', 'S27.899', 'S30.0XX', 'S30.1XX', 'S30.23', 'S31.809', 'S32.019', 'S32.50', 'S32.502', 'S32.602', 'S32.9', 'S34.139', 'S35.229', 'S36.00X', 'S36.029', 'S36.09X', 'S37.009', 'S37.039', 'S37.812', 'S39.92', 'S39.94', 'S39.94X', 'S42.402', 'S42.409', 'S42.90X', 'S43.006', 'S43.40', 'S50.10X', 'S52.002', 'S52.102', 'S52.92X', 'S53.101', 'S60.229', 'S60.511', 'S61.209', 'S70.312', 'S71.101', 'S80.821', 'S91.051', 'S92.312', 'S93.402', 'T14.8', 'T14.90', 'T14.91', 'T18.3XX', 'T19.2XX', 'T20.00', 'T20.02X', 'T20.04X', 'T24.009', 'T24.011', 'T24.012', 'T30.0', 'T31.2', 'T56.0', 'T74.2', 'T79.7', 'T79.7XX', 'T81.30', 'T81.4', 'T81.49X', 'T82.01X', 'T82.7XX', 'T82.868', 'T85.41X', 'T86.11', 'T86.822', 'V00.121', 'V29.99X', 'V37.0', 'V87.9', 'V89.9XX', 'V99.XXX', 'W16.011', 'W19.XXX', 'W34.00', 'W34.00X', 'W55.03', 'W55.22X', 'W56.81X', 'W57.XXX', 'W86.8XX', 'X08.8XX', 'X58.XXX', 'Y84.2', 'Z16.11', 'Z16.19', 'Z16.24', 'Z16.35', 'Z17.0', 'Z20.818', 'Z37.0', 'Z3A.16', 'Z3A.18', 'Z3A.20', 'Z3A.24', 'Z3A.35', 'Z3A.38', 'Z3A.39', 'Z51.5', 'Z53.29', 'Z53.31', 'Z65.1', 'Z67.10', 'Z67.11', 'Z68.1', 'Z68.26', 'Z68.34', 'Z68.36', 'Z68.4', 'Z68.41', 'Z68.42', 'Z68.45', 'Z74.01', 'Z75.1', 'Z76.82', 'Z77.29', 'Z79.01', 'Z79.02', 'Z79.1', 'Z79.4', 'Z79.52', 'Z79.82', 'Z79.83', 'Z79.84', 'Z79.890', 'Z80.0', 'Z80.3', 'Z82.41', 'Z83.3', 'Z85.3', 'Z86.11', 'Z86.61', 'Z86.718', 'Z86.73', 'Z87.01', 'Z87.440', 'Z87.442', 'Z87.81', 'Z87.891', 'Z88.0', 'Z88.1', 'Z88.2', 'Z88.8', 'Z90.3', 'Z90.49', 'Z90.5', 'Z90.710', 'Z90.721', 'Z90.79', 'Z90.81', 'Z91.041', 'Z92.0', 'Z92.21', 'Z92.3', 'Z93.0', 'Z93.2', 'Z94.0', 'Z95.1', 'Z95.2', 'Z96.0', 'Z96.1', 'Z97.4', 'Z98.52', 'Z98.84', 'Z98.85', 'Z99.2', 'Z99.3', 'Z99.81', 'Z99.89']\n",
      "Parent Accuracy: 100.00% | Child Accuracy: 90.91%\n",
      "F1 Validation | Micro: 0.00942 | Macro: 0.00575 | Best: 0.00575 | Epochs without improvement: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 603/603 [01:17<00:00,  7.79it/s, loss=0.863, lr=3e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 1.9889 | LR: 3.00E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['A01', 'A02', 'A03', 'A04', 'A09', 'A15', 'A17', 'A18', 'A23', 'A24', 'A25', 'A28', 'A31', 'A32', 'A35', 'A38', 'A40', 'A41', 'A43', 'A44', 'A48', 'A49', 'A53', 'A54', 'A55', 'A60', 'A63', 'A64', 'A69', 'A74', 'A78', 'A79', 'A87', 'A90', 'A91', 'A93', 'B00', 'B01', 'B02', 'B05', 'B06', 'B07', 'B08', 'B10', 'B15', 'B17', 'B18', 'B19', 'B20', 'B25', 'B27', 'B30', 'B33', 'B34', 'B35', 'B37', 'B44', 'B45', 'B46', 'B48', 'B55', 'B57', 'B58', 'B59', 'B65', 'B67', 'B69', 'B74', 'B83', 'B91', 'B95', 'B96', 'B97', 'B99', 'C01', 'C02', 'C04', 'C07', 'C08', 'C10', 'C12', 'C15', 'C16', 'C17', 'C18', 'C21', 'C22', 'C23', 'C25', 'C26', 'C31', 'C34', 'C40', 'C41', 'C43', 'C44', 'C48', 'C49', 'C50', 'C52', 'C53', 'C54', 'C55', 'C56', 'C60', 'C61', 'C62', 'C63', 'C64', 'C65', 'C66', 'C67', 'C68', 'C69', 'C70', 'C71', 'C72', 'C73', 'C74', 'C75', 'C76', 'C77', 'C78', 'C79', 'C80', 'C81', 'C83', 'C84', 'C85', 'C88', 'C90', 'C91', 'C92', 'C94', 'C96', 'D09', 'D10', 'D11', 'D12', 'D15', 'D16', 'D17', 'D18', 'D22', 'D23', 'D24', 'D29', 'D30', 'D31', 'D32', 'D35', 'D36', 'D37', 'D3A', 'D40', 'D41', 'D43', 'D44', 'D45', 'D47', 'D48', 'D49', 'D50', 'D53', 'D58', 'D61', 'D62', 'D63', 'D64', 'D65', 'D66', 'D68', 'D69', 'D70', 'D72', 'D73', 'D74', 'D75', 'D76', 'D80', 'D82', 'D84', 'D86', 'D89', 'E03', 'E04', 'E05', 'E06', 'E07', 'E10', 'E11', 'E13', 'E16', 'E21', 'E23', 'E27', 'E29', 'E34', 'E36', 'E41', 'E43', 'E44', 'E46', 'E50', 'E51', 'E53', 'E56', 'E63', 'E66', 'E72', 'E74', 'E75', 'E77', 'E78', 'E79', 'E80', 'E83', 'E85', 'E86', 'E87', 'E88', 'E89', 'F02', 'F05', 'F09', 'F10', 'F11', 'F12', 'F14', 'F17', 'F19', 'F20', 'F23', 'F25', 'F29', 'F30', 'F31', 'F32', 'F34', 'F39', 'F40', 'F41', 'F43', 'F45', 'F50', 'F51', 'F60', 'F63', 'F65', 'F70', 'F71', 'F72', 'F73', 'F79', 'F80', 'F82', 'F84', 'F90', 'F98', 'F99', 'G00', 'G03', 'G04', 'G06', 'G12', 'G14', 'G21', 'G24', 'G25', 'G30', 'G31', 'G35', 'G40', 'G44', 'G45', 'G46', 'G47', 'G50', 'G51', 'G54', 'G56', 'G57', 'G58', 'G60', 'G61', 'G62', 'G70', 'G71', 'G72', 'G81', 'G82', 'G83', 'G89', 'G90', 'G91', 'G93', 'G95', 'G96', 'G97', 'H00', 'H01', 'H02', 'H04', 'H05', 'H10', 'H11', 'H15', 'H16', 'H17', 'H18', 'H20', 'H21', 'H25', 'H26', 'H27', 'H30', 'H31', 'H33', 'H35', 'H40', 'H43', 'H44', 'H46', 'H47', 'H49', 'H50', 'H52', 'H53', 'H54', 'H55', 'H57', 'H59', 'H60', 'H80', 'H90', 'H91', 'H92', 'H93', 'I05', 'I10', 'I11', 'I12', 'I20', 'I21', 'I23', 'I24', 'I25', 'I26', 'I27', 'I28', 'I30', 'I31', 'I33', 'I34', 'I35', 'I37', 'I38', 'I42', 'I43', 'I44', 'I45', 'I46', 'I47', 'I48', 'I49', 'I50', 'I51', 'I60', 'I61', 'I62', 'I63', 'I65', 'I66', 'I67', 'I69', 'I70', 'I71', 'I72', 'I73', 'I74', 'I75', 'I77', 'I78', 'I80', 'I81', 'I82', 'I83', 'I85', 'I86', 'I87', 'I88', 'I89', 'I95', 'I96', 'I99', 'J00', 'J01', 'J02', 'J03', 'J05', 'J11', 'J12', 'J16', 'J18', 'J21', 'J30', 'J32', 'J34', 'J35', 'J38', 'J39', 'J42', 'J43', 'J44', 'J45', 'J47', 'J60', 'J62', 'J64', 'J68', 'J69', 'J80', 'J81', 'J84', 'J85', 'J86', 'J90', 'J93', 'J94', 'J96', 'J98', 'J99', 'K00', 'K01', 'K02', 'K04', 'K05', 'K06', 'K08', 'K09', 'K11', 'K12', 'K13', 'K14', 'K20', 'K21', 'K22', 'K25', 'K26', 'K27', 'K30', 'K31', 'K35', 'K36', 'K37', 'K38', 'K40', 'K41', 'K42', 'K44', 'K46', 'K50', 'K51', 'K52', 'K55', 'K56', 'K57', 'K58', 'K59', 'K60', 'K62', 'K63', 'K64', 'K65', 'K66', 'K68', 'K70', 'K71', 'K72', 'K74', 'K75', 'K76', 'K80', 'K81', 'K82', 'K83', 'K85', 'K86', 'K90', 'K91', 'K92', 'L00', 'L02', 'L03', 'L05', 'L08', 'L10', 'L11', 'L21', 'L24', 'L25', 'L28', 'L29', 'L30', 'L40', 'L42', 'L43', 'L51', 'L52', 'L53', 'L57', 'L60', 'L65', 'L68', 'L71', 'L74', 'L76', 'L81', 'L83', 'L85', 'L89', 'L90', 'L91', 'L92', 'L93', 'L94', 'L97', 'L98', 'M00', 'M01', 'M05', 'M06', 'M08', 'M13', 'M15', 'M16', 'M19', 'M21', 'M24', 'M25', 'M26', 'M27', 'M30', 'M31', 'M32', 'M35', 'M41', 'M43', 'M45', 'M46', 'M47', 'M48', 'M51', 'M54', 'M60', 'M61', 'M62', 'M65', 'M71', 'M75', 'M77', 'M79', 'M80', 'M81', 'M83', 'M84', 'M85', 'M86', 'M87', 'M88', 'M89', 'M90', 'M94', 'N02', 'N03', 'N04', 'N05', 'N11', 'N12', 'N13', 'N14', 'N17', 'N18', 'N19', 'N20', 'N23', 'N25', 'N26', 'N28', 'N29', 'N30', 'N31', 'N32', 'N34', 'N36', 'N39', 'N40', 'N41', 'N43', 'N44', 'N45', 'N48', 'N49', 'N50', 'N52', 'N53', 'N60', 'N63', 'N64', 'N80', 'N83', 'N85', 'N89', 'N90', 'N91', 'N92', 'N93', 'N94', 'N96', 'N97', 'O02', 'O03', 'O21', 'O24', 'O32', 'O40', 'O41', 'O42', 'O47', 'O62', 'O65', 'O69', 'O75', 'O77', 'O80', 'O99', 'P35', 'P52', 'P55', 'P81', 'P91', 'Q02', 'Q03', 'Q04', 'Q05', 'Q07', 'Q10', 'Q12', 'Q13', 'Q21', 'Q23', 'Q24', 'Q27', 'Q28', 'Q32', 'Q35', 'Q37', 'Q38', 'Q42', 'Q44', 'Q45', 'Q51', 'Q52', 'Q53', 'Q55', 'Q60', 'Q61', 'Q62', 'Q63', 'Q64', 'Q67', 'Q68', 'Q70', 'Q75', 'Q76', 'Q78', 'Q79', 'Q85', 'Q87', 'Q89', 'Q91', 'Q98', 'R00', 'R01', 'R04', 'R05', 'R06', 'R07', 'R09', 'R10', 'R11', 'R12', 'R13', 'R14', 'R16', 'R17', 'R18', 'R19', 'R20', 'R21', 'R22', 'R23', 'R25', 'R26', 'R27', 'R29', 'R30', 'R31', 'R32', 'R33', 'R34', 'R35', 'R36', 'R39', 'R40', 'R41', 'R42', 'R43', 'R44', 'R45', 'R46', 'R47', 'R48', 'R49', 'R50', 'R51', 'R52', 'R53', 'R55', 'R56', 'R57', 'R58', 'R59', 'R60', 'R61', 'R63', 'R64', 'R65', 'R68', 'R69', 'R73', 'R74', 'R76', 'R78', 'R79', 'R80', 'R81', 'R82', 'R86', 'R91', 'R92', 'R97', 'R99', 'S00', 'S01', 'S02', 'S03', 'S05', 'S06', 'S09', 'S11', 'S19', 'S20', 'S22', 'S23', 'S27', 'S30', 'S31', 'S32', 'S34', 'S35', 'S36', 'S37', 'S39', 'S40', 'S42', 'S43', 'S50', 'S52', 'S53', 'S60', 'S61', 'S63', 'S64', 'S70', 'S71', 'S80', 'S91', 'S92', 'S93', 'S95', 'T07', 'T14', 'T17', 'T18', 'T19', 'T20', 'T23', 'T24', 'T30', 'T31', 'T56', 'T66', 'T74', 'T79', 'T80', 'T81', 'T82', 'T85', 'T86', 'V00', 'V29', 'V37', 'V40', 'V55', 'V63', 'V78', 'V80', 'V87', 'V89', 'V99', 'W16', 'W19', 'W34', 'W55', 'W56', 'W57', 'W74', 'W86', 'W94', 'X08', 'X16', 'X30', 'X37', 'X58', 'X80', 'X95', 'Y23', 'Y80', 'Y82', 'Y84', 'Y95', 'Z16', 'Z17', 'Z20', 'Z21', 'Z29', 'Z36', 'Z37', 'Z38', 'Z3A', 'Z51', 'Z53', 'Z65', 'Z67', 'Z68', 'Z74', 'Z75', 'Z76', 'Z77', 'Z79', 'Z80', 'Z82', 'Z83', 'Z85', 'Z86', 'Z87', 'Z88', 'Z90', 'Z91', 'Z92', 'Z93', 'Z94', 'Z95', 'Z96', 'Z97', 'Z98', 'Z99']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A01.00', 'A01.4', 'A02.9', 'A03.8', 'A04.5', 'A04.8', 'A15.0', 'A15.4', 'A15.6', 'A15.9', 'A17.81', 'A18.09', 'A18.10', 'A18.12', 'A18.15', 'A18.2', 'A18.4', 'A18.50', 'A23.9', 'A28.1', 'A31.9', 'A32.11', 'A32.9', 'A38.9', 'A40.3', 'A41.02', 'A41.1', 'A41.81', 'A41.9', 'A43.9', 'A44.0', 'A44.9', 'A48.1', 'A49.1', 'A49.8', 'A49.9', 'A53.9', 'A54.9', 'A63.0', 'A69.20', 'A74.9', 'A79.9', 'A87.2', 'B00.9', 'B01.9', 'B02.21', 'B02.29', 'B02.39', 'B05.9', 'B06.9', 'B07.9', 'B08.3', 'B10.89', 'B15.9', 'B17.9', 'B18.2', 'B19.10', 'B19.20', 'B19.9', 'B25.9', 'B27.00', 'B27.90', 'B27.99', 'B30.0', 'B30.9', 'B33.3', 'B34.1', 'B34.8', 'B35.2', 'B35.9', 'B37.0', 'B37.2', 'B37.3', 'B37.81', 'B37.9', 'B44.9', 'B45.2', 'B45.9', 'B46.5', 'B48.8', 'B55.9', 'B57.2', 'B58.2', 'B58.9', 'B65.0', 'B65.9', 'B67.90', 'B67.99', 'B69.0', 'B69.9', 'B74.9', 'B83.0', 'B95.0', 'B95.2', 'B95.4', 'B95.5', 'B95.61', 'B95.62', 'B95.7', 'B95.8', 'B96.0', 'B96.1', 'B96.20', 'B96.3', 'B96.4', 'B96.5', 'B96.7', 'B96.81', 'B96.89', 'B97.0', 'B97.10', 'B97.12', 'B97.29', 'B97.4', 'B97.6', 'B97.7', 'B99.9', 'C02.1', 'C02.9', 'C04.9', 'C08.0', 'C10.9', 'C15.9', 'C16.0', 'C16.9', 'C17.1', 'C18.6', 'C18.7', 'C18.9', 'C21.0', 'C22.0', 'C22.1', 'C26.0', 'C31.2', 'C34.9', 'C34.90', 'C34.91', 'C40.20', 'C41.0', 'C41.1', 'C43.9', 'C44.311', 'C44.49', 'C48.0', 'C48.2', 'C49.21', 'C49.5', 'C49.A', 'C49.A2', 'C50.312', 'C50.519', 'C50.9', 'C50.91', 'C50.912', 'C50.919', 'C53.9', 'C54.1', 'C56.2', 'C60.1', 'C62.9', 'C62.90', 'C62.91', 'C62.92', 'C63.10', 'C63.8', 'C64.1', 'C64.2', 'C64.9', 'C65.9', 'C66.9', 'C67.2', 'C67.7', 'C67.9', 'C68.0', 'C69.32', 'C70.9', 'C71.0', 'C72.30', 'C74.90', 'C74.92', 'C75.0', 'C76.3', 'C77.2', 'C77.3', 'C77.8', 'C77.9', 'C78.00', 'C78.01', 'C78.02', 'C78.1', 'C78.39', 'C78.5', 'C78.6', 'C78.7', 'C78.89', 'C79.00', 'C79.02', 'C79.2', 'C79.31', 'C79.49', 'C79.51', 'C79.52', 'C79.70', 'C79.71', 'C79.72', 'C79.81', 'C79.82', 'C79.89', 'C79.9', 'C80.0', 'C80.1', 'C81.1', 'C83.0', 'C83.1', 'C83.30', 'C83.39', 'C83.70', 'C84.49', 'C84.A', 'C85.9', 'C85.90', 'C85.99', 'C88.4', 'C90.0', 'C90.3', 'C91.90', 'C92.10', 'C94.6', 'C96.6', 'D09.0', 'D10.30', 'D11.0', 'D12.1', 'D12.6', 'D15.1', 'D16.22', 'D16.5', 'D17.23', 'D17.9', 'D18.00', 'D18.03', 'D18.09', 'D18.1', 'D22.9', 'D23.11', 'D23.9', 'D24.1', 'D24.9', 'D29.1', 'D29.30', 'D29.31', 'D30.00', 'D30.01', 'D30.02', 'D30.3', 'D31.62', 'D31.9', 'D32.0', 'D32.9', 'D35.00', 'D35.02', 'D35.1', 'D36.11', 'D37.030', 'D37.8', 'D40.10', 'D40.11', 'D40.8', 'D41.00', 'D41.02', 'D43.1', 'D44.10', 'D44.12', 'D44.2', 'D44.6', 'D44.7', 'D47.1', 'D47.2', 'D47.3', 'D47.9', 'D48.0', 'D48.1', 'D49.0', 'D49.1', 'D49.2', 'D49.3', 'D49.4', 'D49.511', 'D49.512', 'D49.519', 'D49.59', 'D49.7', 'D49.89', 'D50.0', 'D50.9', 'D53.1', 'D58.9', 'D61.818', 'D63.1', 'D64.9', 'D68.51', 'D68.59', 'D68.61', 'D68.9', 'D69.0', 'D69.2', 'D69.3', 'D69.41', 'D69.6', 'D69.9', 'D70.9', 'D72.0', 'D72.1', 'D72.810', 'D72.819', 'D72.821', 'D72.822', 'D72.829', 'D73.1', 'D73.3', 'D73.5', 'D73.89', 'D74.8', 'D75.89', 'D76.3', 'D80.1', 'D84.9', 'D86.9', 'D89.2', 'E03.8', 'E03.9', 'E04.1', 'E04.2', 'E04.9', 'E05.00', 'E05.80', 'E05.90', 'E06.3', 'E07.9', 'E10.10', 'E10.9', 'E11.22', 'E11.319', 'E11.359', 'E11.42', 'E11.622', 'E11.628', 'E11.9', 'E13.9', 'E16.2', 'E21.0', 'E21.3', 'E21.5', 'E23.0', 'E23.2', 'E27.0', 'E27.8', 'E27.9', 'E29.1', 'E44.0', 'E44.1', 'E50.9', 'E51.9', 'E53.1', 'E53.8', 'E56.9', 'E63.9', 'E66.01', 'E66.3', 'E66.9', 'E72.01', 'E74.00', 'E74.04', 'E75.29', 'E75.5', 'E77.8', 'E78.00', 'E78.1', 'E78.5', 'E79.0', 'E80.20', 'E80.7', 'E83.119', 'E83.39', 'E83.41', 'E83.42', 'E83.51', 'E83.52', 'E83.59', 'E83.81', 'E85.4', 'E85.9', 'E86.0', 'E87.0', 'E87.1', 'E87.2', 'E87.3', 'E87.5', 'E87.6', 'E88.09', 'E88.9', 'E89.0', 'F02.80', 'F10.10', 'F10.20', 'F10.21', 'F10.23', 'F11.20', 'F12.10', 'F12.20', 'F14.10', 'F14.20', 'F17.200', 'F17.210', 'F17.290', 'F19.20', 'F19.21', 'F20.5', 'F25.0', 'F30.9', 'F31.9', 'F32.9', 'F34.1', 'F40.9', 'F41.8', 'F41.9', 'F43.20', 'F43.9', 'F45.29', 'F50.2', 'F60.3', 'F63.9', 'F65.3', 'F80.81', 'F84.0', 'F90.9', 'F98.8', 'G00.1', 'G03.9', 'G04.1', 'G04.90', 'G06.0', 'G06.2', 'G12.20', 'G12.21', 'G24.5', 'G25.0', 'G25.3', 'G30.9', 'G31.84', 'G40.109', 'G40.119', 'G40.309', 'G40.401', 'G40.409', 'G40.909', 'G44.209', 'G45.9', 'G47.00', 'G47.30', 'G47.32', 'G47.33', 'G47.9', 'G50.0', 'G51.0', 'G54.6', 'G56.92', 'G57.00', 'G57.01', 'G57.42', 'G58.9', 'G61.0', 'G62.9', 'G70.00', 'G71.8', 'G72.3', 'G72.49', 'G72.9', 'G81.14', 'G81.90', 'G81.91', 'G81.94', 'G82.20', 'G82.21', 'G83.14', 'G83.2', 'G83.9', 'G89.29', 'G90.2', 'G90.50', 'G90.511', 'G91.8', 'G91.9', 'G93.0', 'G93.2', 'G93.40', 'G93.5', 'G93.6', 'G93.9', 'G95.20', 'G95.9', 'G96.0', 'G97.2', 'H00.19', 'H01.009', 'H01.8', 'H02.40', 'H02.401', 'H02.402', 'H02.409', 'H02.411', 'H02.841', 'H02.843', 'H02.844', 'H02.846', 'H02.849', 'H02.9', 'H04.20', 'H04.202', 'H05.2', 'H05.20', 'H05.221', 'H05.231', 'H10.9', 'H11.001', 'H11.002', 'H11.42', 'H11.421', 'H11.422', 'H11.429', 'H11.439', 'H15.00', 'H15.032', 'H15.092', 'H16.0', 'H16.001', 'H16.012', 'H16.07', 'H16.071', 'H16.9', 'H17.12', 'H17.9', 'H18.20', 'H18.89', 'H18.891', 'H18.9', 'H20.052', 'H20.059', 'H20.9', 'H21.26', 'H21.309', 'H21.42', 'H21.50', 'H21.501', 'H21.509', 'H21.542', 'H21.9', 'H25.1', 'H26.8', 'H26.9', 'H27.10', 'H30.14', 'H30.89', 'H30.93', 'H31.101', 'H31.103', 'H31.309', 'H31.32', 'H33.10', 'H33.101', 'H33.102', 'H33.19', 'H33.20', 'H33.21', 'H33.22', 'H35.00', 'H35.349', 'H35.50', 'H35.6', 'H35.61', 'H35.62', 'H35.81', 'H35.89', 'H35.9', 'H40.10', 'H40.11', 'H40.83', 'H40.9', 'H43.1', 'H43.12', 'H43.13', 'H44.00', 'H44.001', 'H44.002', 'H44.009', 'H44.139', 'H44.40', 'H46.00', 'H46.9', 'H47.091', 'H47.092', 'H47.10', 'H49.02', 'H49.11', 'H49.21', 'H49.22', 'H49.23', 'H49.9', 'H50.011', 'H50.012', 'H50.10', 'H50.112', 'H50.21', 'H50.22', 'H50.9', 'H52.1', 'H52.7', 'H53.14', 'H53.142', 'H53.143', 'H53.149', 'H53.15', 'H53.2', 'H53.30', 'H53.40', 'H53.462', 'H53.8', 'H53.9', 'H54.0', 'H54.2', 'H54.3', 'H54.61', 'H54.62', 'H54.7', 'H55.00', 'H55.01', 'H57.02', 'H57.03', 'H57.04', 'H57.1', 'H57.10', 'H57.11', 'H57.12', 'H57.13', 'H57.8', 'H57.9', 'H59.03', 'H59.033', 'H60.91', 'H80.90', 'H90.12', 'H90.5', 'H91.20', 'H91.3', 'H91.90', 'H91.91', 'H91.93', 'H92.01', 'H92.09', 'H93.11', 'H93.19', 'I05.0', 'I05.9', 'I11.9', 'I12.0', 'I12.9', 'I20.8', 'I20.9', 'I21.11', 'I21.19', 'I21.29', 'I21.3', 'I23.7', 'I24.9', 'I25.10', 'I25.2', 'I25.9', 'I26.99', 'I27.2', 'I28.1', 'I30.9', 'I31.2', 'I31.3', 'I31.4', 'I33.0', 'I34.0', 'I34.1', 'I35.0', 'I35.8', 'I35.9', 'I37.0', 'I42.0', 'I42.9', 'I44.2', 'I44.30', 'I45.10', 'I46.9', 'I47.1', 'I48.0', 'I48.2', 'I48.91', 'I48.92', 'I49.01', 'I49.9', 'I50.9', 'I51.4', 'I51.7', 'I51.9', 'I60.9', 'I61.5', 'I61.8', 'I61.9', 'I62.00', 'I62.01', 'I62.03', 'I62.9', 'I63.512', 'I63.519', 'I63.9', 'I65.21', 'I65.8', 'I66.9', 'I67.1', 'I67.82', 'I69.354', 'I70.0', 'I70.90', 'I71.00', 'I71.2', 'I71.4', 'I72.9', 'I73.8', 'I74.8', 'I74.9', 'I75.81', 'I75.89', 'I77.0', 'I77.1', 'I77.6', 'I77.9', 'I78.1', 'I80.8', 'I82.0', 'I82.210', 'I82.220', 'I82.3', 'I82.40', 'I82.401', 'I82.402', 'I82.409', 'I82.411', 'I82.431', 'I82.439', 'I82.90', 'I83.90', 'I83.93', 'I85.00', 'I85.01', 'I86.1', 'I86.4', 'I87.1', 'I87.2', 'I87.8', 'I88.1', 'I88.9', 'I89.0', 'I89.1', 'I89.8', 'I95.9', 'I99.8', 'J01.90', 'J02.9', 'J03.90', 'J03.91', 'J11.0', 'J11.1', 'J12.0', 'J18.1', 'J18.9', 'J21.8', 'J21.9', 'J30.1', 'J32.0', 'J32.4', 'J32.9', 'J34.1', 'J34.3', 'J34.89', 'J35.1', 'J38.1', 'J38.4', 'J39.8', 'J43.9', 'J44.9', 'J45.909', 'J47.9', 'J62.8', 'J69.0', 'J81.0', 'J81.1', 'J84.01', 'J84.10', 'J84.89', 'J85.2', 'J86.0', 'J93.9', 'J94.0', 'J94.2', 'J94.8', 'J96.00', 'J96.90', 'J96.92', 'J98.01', 'J98.11', 'J98.2', 'J98.4', 'J98.51', 'J98.8', 'K00.0', 'K00.1', 'K01.0', 'K02.9', 'K04.7', 'K05.10', 'K06.1', 'K06.2', 'K06.8', 'K08.109', 'K08.89', 'K08.9', 'K09.0', 'K11.1', 'K11.20', 'K11.6', 'K11.7', 'K11.9', 'K12.0', 'K12.1', 'K12.2', 'K13.0', 'K13.21', 'K13.29', 'K13.70', 'K13.79', 'K14.5', 'K14.6', 'K14.9', 'K20.9', 'K21.9', 'K22.2', 'K22.70', 'K22.8', 'K22.9', 'K25.9', 'K26.4', 'K26.9', 'K27.9', 'K31.1', 'K31.5', 'K31.7', 'K31.819', 'K31.89', 'K31.9', 'K35.2', 'K35.80', 'K38.8', 'K40.20', 'K40.30', 'K40.90', 'K42.9', 'K44.9', 'K46.9', 'K50.00', 'K50.90', 'K51.00', 'K51.90', 'K52.3', 'K52.81', 'K52.82', 'K52.9', 'K55.049', 'K55.059', 'K55.1', 'K55.20', 'K55.21', 'K55.9', 'K56.1', 'K56.2', 'K56.41', 'K56.60', 'K56.69', 'K57.00', 'K57.10', 'K57.20', 'K57.32', 'K57.90', 'K57.92', 'K59.00', 'K59.39', 'K59.8', 'K59.9', 'K60.3', 'K62.1', 'K62.5', 'K62.6', 'K62.7', 'K62.89', 'K63.1', 'K63.2', 'K63.5', 'K63.9', 'K64.8', 'K64.9', 'K65.0', 'K65.1', 'K65.3', 'K65.8', 'K65.9', 'K66.0', 'K66.1', 'K66.8', 'K68.12', 'K68.19', 'K68.9', 'K70.10', 'K70.30', 'K70.9', 'K71.6', 'K72.00', 'K72.90', 'K74.0', 'K74.60', 'K75.0', 'K75.4', 'K75.9', 'K76.0', 'K76.6', 'K76.7', 'K76.81', 'K76.89', 'K76.9', 'K80.10', 'K80.20', 'K80.5', 'K80.50', 'K80.51', 'K81.0', 'K82.8', 'K83.0', 'K83.1', 'K83.3', 'K83.8', 'K85.20', 'K85.90', 'K86.0', 'K86.1', 'K86.3', 'K86.89', 'K86.9', 'K90.0', 'K90.9', 'K91.7', 'K92.0', 'K92.1', 'K92.2', 'L02.01', 'L02.211', 'L02.31', 'L02.41', 'L02.91', 'L03.115', 'L03.90', 'L08.9', 'L10.0', 'L11.9', 'L21.9', 'L25.9', 'L28.2', 'L29.0', 'L29.9', 'L30.9', 'L40.53', 'L40.9', 'L43.9', 'L51.1', 'L51.2', 'L51.9', 'L53.9', 'L57.0', 'L60.8', 'L60.9', 'L65.9', 'L68.0', 'L71.9', 'L74.0', 'L76.3', 'L81.9', 'L85.8', 'L85.9', 'L89.150', 'L90.5', 'L90.8', 'L91.0', 'L92.9', 'L93.0', 'L97.909', 'L97.919', 'L98.0', 'L98.49', 'L98.8', 'L98.9', 'M00.071', 'M00.9', 'M05.9', 'M06.9', 'M08.90', 'M08.961', 'M08.99', 'M13.0', 'M15.9', 'M16.0', 'M19.90', 'M21.959', 'M24.60', 'M24.641', 'M24.642', 'M25.40', 'M25.451', 'M25.50', 'M25.511', 'M25.512', 'M25.519', 'M25.531', 'M25.532', 'M25.541', 'M25.551', 'M25.552', 'M25.561', 'M25.562', 'M25.569', 'M25.571', 'M25.60', 'M25.9', 'M26.02', 'M26.04', 'M26.09', 'M26.30', 'M26.32', 'M26.601', 'M26.609', 'M26.619', 'M26.9', 'M27.2', 'M30.3', 'M31.0', 'M31.1', 'M31.6', 'M32.9', 'M35.3', 'M41.9', 'M43.6', 'M45.9', 'M46.40', 'M46.47', 'M46.90', 'M46.96', 'M47.895', 'M47.896', 'M47.9', 'M48.00', 'M48.04', 'M51.24', 'M54.2', 'M54.40', 'M54.41', 'M54.5', 'M54.6', 'M54.9', 'M60.059', 'M60.9', 'M61.10', 'M62.50', 'M62.81', 'M62.82', 'M62.838', 'M62.89', 'M65.9', 'M71.30', 'M75.90', 'M79.1', 'M79.2', 'M79.60', 'M79.604', 'M79.605', 'M79.621', 'M79.641', 'M79.643', 'M79.644', 'M79.645', 'M79.652', 'M79.659', 'M79.671', 'M79.672', 'M79.673', 'M79.7', 'M80.08X', 'M81.0', 'M83.9', 'M84.30X', 'M84.453', 'M84.529', 'M85.2', 'M85.50', 'M85.60', 'M85.8', 'M85.80', 'M86.60', 'M86.68', 'M86.9', 'M87.80', 'M88.832', 'M88.9', 'M89.072', 'M89.549', 'M89.59', 'M89.70', 'M89.8X', 'M89.8X9', 'M89.9', 'M94.359', 'N02.8', 'N03.9', 'N04.9', 'N05.5', 'N05.7', 'N05.9', 'N11.9', 'N13.30', 'N13.5', 'N13.6', 'N13.70', 'N13.8', 'N13.9', 'N17.0', 'N17.9', 'N18.2', 'N18.3', 'N18.4', 'N18.5', 'N18.6', 'N18.9', 'N20.0', 'N20.1', 'N20.9', 'N25.81', 'N26.1', 'N26.9', 'N28.0', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.8', 'N30.90', 'N31.9', 'N32.0', 'N32.1', 'N32.3', 'N32.89', 'N32.9', 'N34.2', 'N36.0', 'N36.8', 'N39.0', 'N39.44', 'N40.0', 'N40.2', 'N41.0', 'N41.1', 'N43.3', 'N44.00', 'N44.2', 'N44.8', 'N45.1', 'N45.2', 'N45.3', 'N45.4', 'N48.21', 'N48.29', 'N48.30', 'N48.6', 'N48.81', 'N48.89', 'N48.9', 'N49.2', 'N50.0', 'N50.1', 'N50.3', 'N50.811', 'N50.812', 'N50.819', 'N50.82', 'N50.89', 'N50.9', 'N52.9', 'N53.12', 'N60.01', 'N60.02', 'N60.11', 'N60.12', 'N60.19', 'N64.4', 'N64.89', 'N64.9', 'N80.8', 'N80.9', 'N83.00', 'N83.9', 'N85.8', 'N89.5', 'N90.89', 'N91.0', 'N92.1', 'N93.9', 'N94.89', 'N97.9', 'O02.0', 'O03.9', 'O21.0', 'O24.419', 'O32.1', 'O40.9XX0', 'O41.0', 'O41.00X', 'O41.1290', 'O42.912', 'O42.92', 'O47.9', 'O75.9', 'O99.11', 'P52.3', 'P81.9', 'P91.60', 'Q03.1', 'Q03.9', 'Q04.0', 'Q05.9', 'Q07.00', 'Q07.8', 'Q10.0', 'Q12.4', 'Q13.0', 'Q13.4', 'Q21.1', 'Q23.1', 'Q24.8', 'Q24.9', 'Q27.30', 'Q27.9', 'Q28.2', 'Q32.4', 'Q35.3', 'Q37.9', 'Q38.2', 'Q42.9', 'Q44.6', 'Q44.7', 'Q45.0', 'Q51.0', 'Q51.3', 'Q51.811', 'Q52.0', 'Q53.10', 'Q55.29', 'Q60.6', 'Q61.02', 'Q61.19', 'Q61.3', 'Q61.4', 'Q62.8', 'Q63.1', 'Q63.9', 'Q64.4', 'Q67.0', 'Q68.0', 'Q70.9', 'Q75.0', 'Q75.3', 'Q76.49', 'Q78.2', 'Q79.1', 'Q85.00', 'Q85.01', 'Q85.1', 'Q85.8', 'Q85.9', 'Q87.2', 'Q87.3', 'Q87.81', 'Q89.2', 'Q98.4', 'R00.0', 'R00.1', 'R00.2', 'R01.1', 'R04.0', 'R04.2', 'R04.89', 'R06.00', 'R06.01', 'R06.09', 'R06.1', 'R06.4', 'R06.6', 'R06.82', 'R06.89', 'R07.0', 'R07.2', 'R07.81', 'R07.89', 'R07.9', 'R09.02', 'R09.2', 'R10.0', 'R10.10', 'R10.12', 'R10.13', 'R10.2', 'R10.30', 'R10.31', 'R10.32', 'R10.33', 'R10.811', 'R10.812', 'R10.813', 'R10.814', 'R10.815', 'R10.816', 'R10.817', 'R10.819', 'R10.83', 'R10.84', 'R10.9', 'R11.0', 'R11.10', 'R11.12', 'R11.14', 'R11.2', 'R13.10', 'R14.0', 'R16.0', 'R16.1', 'R16.2', 'R18.0', 'R18.8', 'R19.0', 'R19.00', 'R19.01', 'R19.02', 'R19.03', 'R19.04', 'R19.06', 'R19.2', 'R19.5', 'R19.7', 'R19.8', 'R20.0', 'R20.1', 'R20.2', 'R20.8', 'R20.9', 'R22.0', 'R22.1', 'R22.2', 'R22.9', 'R23.0', 'R23.1', 'R23.3', 'R23.4', 'R23.8', 'R25.1', 'R25.2', 'R25.3', 'R26.0', 'R26.2', 'R26.81', 'R26.89', 'R26.9', 'R27.0', 'R27.8', 'R29.2', 'R29.6', 'R29.723', 'R29.810', 'R29.898', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R33.9', 'R35.0', 'R35.1', 'R35.8', 'R36.1', 'R39.12', 'R39.14', 'R39.15', 'R39.198', 'R39.89', 'R39.9', 'R40.0', 'R40.1', 'R40.20', 'R40.241', 'R40.2410', 'R40.2420', 'R40.2421', 'R40.243', 'R40.2430', 'R40.3', 'R40.4', 'R41.0', 'R41.3', 'R41.840', 'R41.843', 'R43.2', 'R43.9', 'R44.0', 'R44.1', 'R44.3', 'R44.9', 'R45.0', 'R45.1', 'R45.3', 'R45.4', 'R46.0', 'R47.01', 'R47.02', 'R47.1', 'R47.89', 'R47.9', 'R48.2', 'R49.0', 'R49.1', 'R50.81', 'R50.82', 'R50.9', 'R53.1', 'R53.81', 'R53.83', 'R56.00', 'R56.9', 'R57.0', 'R57.1', 'R57.9', 'R59.0', 'R59.9', 'R60.0', 'R60.1', 'R60.9', 'R63.0', 'R63.1', 'R63.3', 'R63.4', 'R65.20', 'R65.21', 'R68.83', 'R68.84', 'R68.89', 'R73.9', 'R74.0', 'R76.0', 'R76.11', 'R78.81', 'R79.82', 'R80.9', 'R82.2', 'R82.3', 'R91.1', 'R91.8', 'R97.1', 'R97.20', 'R97.8', 'S00.32X', 'S00.33X', 'S00.522', 'S00.532', 'S01.101', 'S01.20X', 'S01.501', 'S01.512', 'S01.80X', 'S01.95X', 'S02.0XX', 'S02.19X', 'S02.5XX', 'S02.601', 'S02.652', 'S03.00X', 'S03.2XX', 'S05.8X2', 'S05.9', 'S05.92X', 'S06.0X0', 'S06.2X', 'S06.36', 'S06.9', 'S06.9X', 'S06.9X0', 'S09.90X', 'S09.92X', 'S11.80X', 'S11.90X', 'S11.91X', 'S19.9X', 'S20.92X', 'S22.39X', 'S22.4', 'S23.163', 'S27.329', 'S27.899', 'S30.0XX', 'S30.1XX', 'S30.23', 'S31.809', 'S32.019', 'S32.50', 'S32.502', 'S32.602', 'S32.9', 'S34.139', 'S35.229', 'S36.00X', 'S36.029', 'S36.09X', 'S37.009', 'S37.039', 'S37.812', 'S39.92', 'S39.94', 'S39.94X', 'S42.402', 'S42.409', 'S42.90X', 'S43.006', 'S43.40', 'S50.10X', 'S52.002', 'S52.102', 'S52.92X', 'S53.101', 'S60.229', 'S60.511', 'S61.209', 'S70.312', 'S71.101', 'S80.821', 'S91.051', 'S92.312', 'S93.402', 'T14.8', 'T14.90', 'T14.91', 'T18.3XX', 'T19.2XX', 'T20.00', 'T20.02X', 'T20.04X', 'T24.009', 'T24.011', 'T24.012', 'T30.0', 'T31.2', 'T56.0', 'T74.2', 'T79.7', 'T79.7XX', 'T81.30', 'T81.4', 'T81.49X', 'T82.01X', 'T82.7XX', 'T82.868', 'T85.41X', 'T86.11', 'T86.822', 'V00.121', 'V29.99X', 'V37.0', 'V87.9', 'V89.9XX', 'V99.XXX', 'W16.011', 'W19.XXX', 'W34.00', 'W34.00X', 'W55.03', 'W55.22X', 'W56.81X', 'W57.XXX', 'W86.8XX', 'X08.8XX', 'X58.XXX', 'Y84.2', 'Z16.11', 'Z16.19', 'Z16.24', 'Z16.35', 'Z17.0', 'Z20.818', 'Z37.0', 'Z3A.16', 'Z3A.18', 'Z3A.20', 'Z3A.24', 'Z3A.35', 'Z3A.38', 'Z3A.39', 'Z51.5', 'Z53.29', 'Z53.31', 'Z65.1', 'Z67.10', 'Z67.11', 'Z68.1', 'Z68.26', 'Z68.34', 'Z68.36', 'Z68.4', 'Z68.41', 'Z68.42', 'Z68.45', 'Z74.01', 'Z75.1', 'Z76.82', 'Z77.29', 'Z79.01', 'Z79.02', 'Z79.1', 'Z79.4', 'Z79.52', 'Z79.82', 'Z79.83', 'Z79.84', 'Z79.890', 'Z80.0', 'Z80.3', 'Z82.41', 'Z83.3', 'Z85.3', 'Z86.11', 'Z86.61', 'Z86.718', 'Z86.73', 'Z87.01', 'Z87.440', 'Z87.442', 'Z87.81', 'Z87.891', 'Z88.0', 'Z88.1', 'Z88.2', 'Z88.8', 'Z90.3', 'Z90.49', 'Z90.5', 'Z90.710', 'Z90.721', 'Z90.79', 'Z90.81', 'Z91.041', 'Z92.0', 'Z92.21', 'Z92.3', 'Z93.0', 'Z93.2', 'Z94.0', 'Z95.1', 'Z95.2', 'Z96.0', 'Z96.1', 'Z97.4', 'Z98.52', 'Z98.84', 'Z98.85', 'Z99.2', 'Z99.3', 'Z99.81', 'Z99.89']\n",
      "Parent Accuracy: 100.00% | Child Accuracy: 90.91%\n",
      "F1 Validation | Micro: 0.01406 | Macro: 0.00587 | Best: 0.00575 | Epochs without improvement: 3\n",
      "Nuevos umbrales: Parent=0.640, Child=0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 603/603 [01:16<00:00,  7.88it/s, loss=0.789, lr=3e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 1.1925 | LR: 3.00E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['A01', 'A23', 'A32', 'A41', 'A49', 'A53', 'A55', 'A63', 'A69', 'B02', 'B06', 'B10', 'B19', 'B20', 'B25', 'B37', 'B57', 'B58', 'B59', 'B83', 'B95', 'B96', 'B97', 'B99', 'C04', 'C15', 'C16', 'C17', 'C18', 'C22', 'C26', 'C44', 'C48', 'C49', 'C50', 'C55', 'C56', 'C61', 'C62', 'C63', 'C64', 'C67', 'C70', 'C73', 'C74', 'C77', 'C78', 'C79', 'C80', 'C91', 'C94', 'D10', 'D12', 'D16', 'D18', 'D24', 'D30', 'D35', 'D44', 'D49', 'D50', 'D61', 'D64', 'D65', 'D68', 'D69', 'D70', 'D72', 'D73', 'D75', 'D76', 'D84', 'E03', 'E04', 'E05', 'E10', 'E11', 'E21', 'E29', 'E46', 'E66', 'E78', 'E79', 'E80', 'E83', 'E85', 'E86', 'E87', 'E88', 'F10', 'F12', 'F14', 'F17', 'F29', 'F31', 'F43', 'F50', 'F70', 'G06', 'G12', 'G25', 'G40', 'G45', 'G54', 'G56', 'G72', 'G81', 'G82', 'G83', 'G89', 'G93', 'G95', 'G97', 'H02', 'H05', 'H10', 'H11', 'H17', 'H18', 'H30', 'H35', 'H49', 'H50', 'H53', 'H54', 'H57', 'H91', 'I05', 'I10', 'I12', 'I21', 'I23', 'I25', 'I26', 'I27', 'I30', 'I31', 'I38', 'I44', 'I48', 'I50', 'I51', 'I60', 'I70', 'I77', 'I81', 'I82', 'I83', 'I85', 'I86', 'I87', 'I89', 'I95', 'I96', 'J00', 'J01', 'J21', 'J32', 'J42', 'J43', 'J44', 'J45', 'J81', 'J90', 'J96', 'J98', 'K02', 'K04', 'K08', 'K11', 'K12', 'K20', 'K21', 'K22', 'K26', 'K31', 'K35', 'K38', 'K40', 'K44', 'K51', 'K52', 'K55', 'K56', 'K57', 'K59', 'K62', 'K63', 'K64', 'K65', 'K66', 'K72', 'K75', 'K76', 'K80', 'K83', 'K85', 'K86', 'K90', 'K92', 'L02', 'L29', 'L53', 'L65', 'L92', 'L98', 'M00', 'M06', 'M19', 'M21', 'M25', 'M27', 'M32', 'M46', 'M47', 'M54', 'M60', 'M62', 'M65', 'M79', 'M81', 'M84', 'M85', 'M89', 'N13', 'N17', 'N18', 'N19', 'N20', 'N23', 'N26', 'N28', 'N29', 'N30', 'N31', 'N32', 'N36', 'N39', 'N40', 'N43', 'N44', 'N45', 'N48', 'N50', 'N52', 'N64', 'N80', 'N92', 'N96', 'O21', 'Q13', 'Q23', 'Q28', 'Q44', 'Q53', 'Q61', 'Q62', 'Q63', 'Q64', 'Q89', 'R00', 'R01', 'R04', 'R06', 'R07', 'R10', 'R11', 'R12', 'R13', 'R14', 'R16', 'R17', 'R18', 'R19', 'R20', 'R21', 'R22', 'R23', 'R25', 'R26', 'R27', 'R30', 'R31', 'R32', 'R33', 'R34', 'R35', 'R39', 'R40', 'R41', 'R42', 'R44', 'R45', 'R47', 'R49', 'R50', 'R51', 'R52', 'R53', 'R56', 'R57', 'R58', 'R59', 'R60', 'R61', 'R63', 'R65', 'R68', 'R69', 'R73', 'R80', 'R82', 'R91', 'R99', 'S01', 'S06', 'S09', 'S11', 'S27', 'S32', 'S36', 'S39', 'S42', 'S52', 'T14', 'T81', 'T82', 'T85', 'W19', 'W34', 'Z20', 'Z37', 'Z3A', 'Z51', 'Z53', 'Z68', 'Z79', 'Z80', 'Z83', 'Z86', 'Z87', 'Z88', 'Z90', 'Z92', 'Z94', 'Z95', 'Z99']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A01.00', 'A01.4', 'A02.9', 'A04.5', 'A04.8', 'A15.0', 'A15.4', 'A15.6', 'A15.9', 'A17.81', 'A18.09', 'A18.10', 'A18.12', 'A18.15', 'A18.2', 'A18.4', 'A18.50', 'A23.9', 'A31.9', 'A32.11', 'A32.9', 'A38.9', 'A40.3', 'A41.02', 'A41.1', 'A41.81', 'A41.9', 'A43.9', 'A44.9', 'A48.1', 'A49.1', 'A49.8', 'A49.9', 'A53.9', 'A54.9', 'A63.0', 'A69.20', 'A74.9', 'A79.9', 'A87.2', 'B00.9', 'B01.9', 'B02.21', 'B02.29', 'B02.39', 'B05.9', 'B06.9', 'B07.9', 'B08.3', 'B10.89', 'B15.9', 'B17.9', 'B18.2', 'B19.10', 'B19.20', 'B19.9', 'B25.9', 'B27.00', 'B27.90', 'B27.99', 'B30.0', 'B30.9', 'B33.3', 'B34.1', 'B34.8', 'B35.2', 'B35.9', 'B37.0', 'B37.2', 'B37.3', 'B37.81', 'B37.9', 'B44.9', 'B45.2', 'B45.9', 'B46.5', 'B48.8', 'B55.9', 'B57.2', 'B58.2', 'B58.9', 'B65.0', 'B65.9', 'B67.90', 'B67.99', 'B69.0', 'B69.9', 'B74.9', 'B83.0', 'B95.0', 'B95.2', 'B95.4', 'B95.5', 'B95.61', 'B95.62', 'B95.7', 'B95.8', 'B96.0', 'B96.1', 'B96.20', 'B96.3', 'B96.4', 'B96.5', 'B96.7', 'B96.81', 'B96.89', 'B97.0', 'B97.10', 'B97.12', 'B97.29', 'B97.4', 'B97.6', 'B97.7', 'B99.9', 'C02.1', 'C02.9', 'C04.9', 'C08.0', 'C15.9', 'C16.0', 'C16.9', 'C17.1', 'C18.6', 'C18.7', 'C18.9', 'C21.0', 'C22.0', 'C22.1', 'C26.0', 'C31.2', 'C34.9', 'C34.90', 'C34.91', 'C40.20', 'C41.0', 'C43.9', 'C44.311', 'C44.49', 'C48.0', 'C48.2', 'C49.21', 'C49.5', 'C49.A', 'C49.A2', 'C50.312', 'C50.519', 'C50.9', 'C50.91', 'C50.912', 'C50.919', 'C53.9', 'C54.1', 'C56.2', 'C60.1', 'C62.90', 'C62.91', 'C62.92', 'C63.10', 'C63.8', 'C64.1', 'C64.2', 'C64.9', 'C65.9', 'C66.9', 'C67.2', 'C67.7', 'C67.9', 'C68.0', 'C69.32', 'C70.9', 'C74.90', 'C74.92', 'C75.0', 'C76.3', 'C77.2', 'C77.3', 'C77.8', 'C77.9', 'C78.00', 'C78.01', 'C78.02', 'C78.1', 'C78.39', 'C78.5', 'C78.6', 'C78.7', 'C78.89', 'C79.00', 'C79.02', 'C79.2', 'C79.31', 'C79.49', 'C79.51', 'C79.52', 'C79.70', 'C79.71', 'C79.72', 'C79.81', 'C79.82', 'C79.89', 'C79.9', 'C80.0', 'C80.1', 'C81.1', 'C83.0', 'C83.1', 'C83.30', 'C83.39', 'C83.70', 'C84.49', 'C84.A', 'C85.9', 'C85.90', 'C85.99', 'C88.4', 'C90.0', 'C90.3', 'C91.90', 'C92.10', 'C94.6', 'C96.6', 'D09.0', 'D10.30', 'D11.0', 'D12.1', 'D12.6', 'D15.1', 'D16.22', 'D16.5', 'D17.23', 'D17.9', 'D18.00', 'D18.03', 'D18.09', 'D18.1', 'D23.11', 'D23.9', 'D24.1', 'D24.9', 'D29.1', 'D29.30', 'D29.31', 'D30.00', 'D30.01', 'D30.02', 'D30.3', 'D31.62', 'D31.9', 'D32.0', 'D32.9', 'D35.00', 'D35.02', 'D35.1', 'D36.11', 'D37.030', 'D37.8', 'D40.10', 'D40.11', 'D40.8', 'D41.00', 'D41.02', 'D44.10', 'D44.12', 'D44.2', 'D44.6', 'D44.7', 'D47.1', 'D47.2', 'D47.3', 'D47.9', 'D48.1', 'D49.0', 'D49.1', 'D49.2', 'D49.3', 'D49.4', 'D49.511', 'D49.512', 'D49.519', 'D49.59', 'D49.7', 'D49.89', 'D50.0', 'D50.9', 'D53.1', 'D58.9', 'D61.818', 'D63.1', 'D64.9', 'D68.51', 'D68.59', 'D68.61', 'D68.9', 'D69.0', 'D69.2', 'D69.3', 'D69.41', 'D69.6', 'D69.9', 'D70.9', 'D72.0', 'D72.1', 'D72.810', 'D72.819', 'D72.821', 'D72.822', 'D72.829', 'D73.1', 'D73.3', 'D73.5', 'D73.89', 'D74.8', 'D75.89', 'D76.3', 'D84.9', 'D86.9', 'D89.2', 'E03.8', 'E03.9', 'E04.1', 'E04.2', 'E04.9', 'E05.00', 'E05.80', 'E05.90', 'E06.3', 'E07.9', 'E10.9', 'E11.42', 'E11.622', 'E11.628', 'E11.9', 'E13.9', 'E16.2', 'E21.0', 'E21.3', 'E21.5', 'E23.0', 'E23.2', 'E27.0', 'E27.8', 'E27.9', 'E29.1', 'E44.0', 'E44.1', 'E50.9', 'E51.9', 'E53.1', 'E53.8', 'E56.9', 'E63.9', 'E66.01', 'E66.3', 'E66.9', 'E72.01', 'E74.00', 'E74.04', 'E75.29', 'E75.5', 'E77.8', 'E78.00', 'E78.1', 'E78.5', 'E79.0', 'E80.20', 'E80.7', 'E83.119', 'E83.39', 'E83.41', 'E83.42', 'E83.51', 'E83.52', 'E83.59', 'E83.81', 'E85.4', 'E85.9', 'E86.0', 'E87.0', 'E87.1', 'E87.2', 'E87.3', 'E87.5', 'E87.6', 'E88.09', 'E88.9', 'E89.0', 'F02.80', 'F10.10', 'F10.20', 'F10.21', 'F10.23', 'F11.20', 'F12.10', 'F12.20', 'F14.10', 'F14.20', 'F17.200', 'F17.210', 'F17.290', 'F19.20', 'F19.21', 'F20.5', 'F25.0', 'F30.9', 'F31.9', 'F32.9', 'F34.1', 'F40.9', 'F41.8', 'F41.9', 'F43.20', 'F43.9', 'F45.29', 'F50.2', 'F60.3', 'F63.9', 'F65.3', 'F84.0', 'F90.9', 'F98.8', 'G00.1', 'G03.9', 'G04.1', 'G04.90', 'G06.0', 'G06.2', 'G12.20', 'G12.21', 'G24.5', 'G25.0', 'G25.3', 'G30.9', 'G31.84', 'G40.109', 'G40.119', 'G40.309', 'G40.401', 'G40.409', 'G40.909', 'G44.209', 'G45.9', 'G47.00', 'G47.30', 'G47.32', 'G47.33', 'G50.0', 'G51.0', 'G54.6', 'G56.92', 'G57.00', 'G57.01', 'G57.42', 'G58.9', 'G61.0', 'G62.9', 'G70.00', 'G71.8', 'G72.3', 'G72.49', 'G72.9', 'G81.14', 'G81.90', 'G81.91', 'G81.94', 'G82.20', 'G82.21', 'G83.14', 'G83.2', 'G83.9', 'G89.29', 'G90.2', 'G90.50', 'G90.511', 'G91.8', 'G91.9', 'G93.0', 'G93.2', 'G93.40', 'G93.5', 'G93.6', 'G93.9', 'G95.20', 'G95.9', 'G96.0', 'G97.2', 'H01.8', 'H02.40', 'H02.401', 'H02.402', 'H02.409', 'H02.411', 'H02.841', 'H02.843', 'H02.844', 'H02.846', 'H02.849', 'H02.9', 'H04.20', 'H04.202', 'H05.2', 'H05.20', 'H05.221', 'H05.231', 'H10.9', 'H11.001', 'H11.002', 'H11.42', 'H11.421', 'H11.422', 'H11.429', 'H11.439', 'H15.00', 'H15.032', 'H15.092', 'H16.0', 'H16.001', 'H16.012', 'H16.07', 'H16.071', 'H16.9', 'H17.12', 'H17.9', 'H18.20', 'H18.89', 'H18.891', 'H18.9', 'H20.052', 'H20.059', 'H20.9', 'H21.26', 'H21.309', 'H21.42', 'H21.50', 'H21.501', 'H21.509', 'H21.542', 'H21.9', 'H25.1', 'H26.8', 'H26.9', 'H27.10', 'H30.14', 'H30.89', 'H30.93', 'H31.101', 'H31.103', 'H31.309', 'H31.32', 'H33.10', 'H33.101', 'H33.102', 'H33.19', 'H33.20', 'H33.21', 'H33.22', 'H35.00', 'H35.349', 'H35.50', 'H35.61', 'H35.62', 'H35.81', 'H35.89', 'H35.9', 'H40.10', 'H40.11', 'H40.9', 'H43.1', 'H43.12', 'H43.13', 'H44.00', 'H44.001', 'H44.002', 'H44.009', 'H44.139', 'H44.40', 'H46.00', 'H46.9', 'H47.091', 'H47.092', 'H47.10', 'H49.02', 'H49.11', 'H49.21', 'H49.22', 'H49.23', 'H49.9', 'H50.011', 'H50.012', 'H50.112', 'H50.21', 'H50.22', 'H50.9', 'H52.1', 'H52.7', 'H53.14', 'H53.142', 'H53.143', 'H53.15', 'H53.2', 'H53.40', 'H53.462', 'H53.8', 'H53.9', 'H54.0', 'H54.2', 'H54.3', 'H54.61', 'H54.62', 'H54.7', 'H55.00', 'H55.01', 'H57.02', 'H57.03', 'H57.04', 'H57.1', 'H57.10', 'H57.11', 'H57.12', 'H57.13', 'H57.9', 'H59.03', 'H59.033', 'H60.91', 'H80.90', 'H90.12', 'H90.5', 'H91.20', 'H91.3', 'H91.90', 'H91.91', 'H91.93', 'H92.01', 'H92.09', 'H93.11', 'H93.19', 'I05.0', 'I05.9', 'I11.9', 'I12.0', 'I12.9', 'I20.8', 'I20.9', 'I21.11', 'I21.19', 'I21.29', 'I21.3', 'I23.7', 'I24.9', 'I25.10', 'I25.2', 'I25.9', 'I26.99', 'I27.2', 'I28.1', 'I30.9', 'I31.2', 'I31.3', 'I31.4', 'I33.0', 'I34.0', 'I34.1', 'I35.0', 'I35.8', 'I37.0', 'I42.0', 'I42.9', 'I44.2', 'I44.30', 'I45.10', 'I46.9', 'I47.1', 'I48.0', 'I48.2', 'I48.91', 'I48.92', 'I49.01', 'I49.9', 'I50.9', 'I51.4', 'I51.7', 'I51.9', 'I60.9', 'I61.5', 'I61.8', 'I61.9', 'I62.00', 'I62.01', 'I62.03', 'I62.9', 'I63.512', 'I63.519', 'I63.9', 'I65.21', 'I66.9', 'I67.1', 'I67.82', 'I69.354', 'I70.0', 'I70.90', 'I71.00', 'I71.2', 'I71.4', 'I72.9', 'I73.8', 'I74.8', 'I74.9', 'I75.81', 'I75.89', 'I77.0', 'I77.1', 'I77.6', 'I77.9', 'I78.1', 'I80.8', 'I82.0', 'I82.210', 'I82.220', 'I82.3', 'I82.40', 'I82.401', 'I82.402', 'I82.409', 'I82.411', 'I82.431', 'I82.439', 'I82.90', 'I83.90', 'I83.93', 'I85.00', 'I85.01', 'I86.1', 'I86.4', 'I87.1', 'I87.2', 'I87.8', 'I88.1', 'I88.9', 'I89.0', 'I89.1', 'I89.8', 'I95.9', 'I99.8', 'J01.90', 'J02.9', 'J03.90', 'J03.91', 'J11.0', 'J11.1', 'J12.0', 'J18.1', 'J18.9', 'J21.8', 'J21.9', 'J30.1', 'J32.0', 'J32.4', 'J32.9', 'J34.1', 'J34.3', 'J34.89', 'J38.1', 'J38.4', 'J39.8', 'J43.9', 'J44.9', 'J45.909', 'J47.9', 'J62.8', 'J69.0', 'J81.0', 'J81.1', 'J84.01', 'J84.10', 'J84.89', 'J85.2', 'J86.0', 'J93.9', 'J94.0', 'J94.2', 'J94.8', 'J96.00', 'J96.90', 'J96.92', 'J98.01', 'J98.11', 'J98.2', 'J98.4', 'J98.51', 'J98.8', 'K00.0', 'K00.1', 'K01.0', 'K02.9', 'K04.7', 'K05.10', 'K06.1', 'K06.2', 'K06.8', 'K08.109', 'K08.89', 'K08.9', 'K09.0', 'K11.1', 'K11.20', 'K11.6', 'K11.7', 'K11.9', 'K12.0', 'K12.1', 'K12.2', 'K13.0', 'K13.21', 'K13.29', 'K13.70', 'K13.79', 'K14.5', 'K14.9', 'K20.9', 'K21.9', 'K22.2', 'K22.70', 'K22.8', 'K22.9', 'K25.9', 'K26.4', 'K26.9', 'K27.9', 'K31.1', 'K31.5', 'K31.7', 'K31.819', 'K31.89', 'K31.9', 'K35.2', 'K35.80', 'K38.8', 'K40.20', 'K40.30', 'K40.90', 'K42.9', 'K44.9', 'K46.9', 'K50.00', 'K50.90', 'K51.00', 'K51.90', 'K52.3', 'K52.81', 'K52.82', 'K52.9', 'K55.049', 'K55.059', 'K55.1', 'K55.20', 'K55.21', 'K55.9', 'K56.1', 'K56.2', 'K56.60', 'K56.69', 'K57.00', 'K57.10', 'K57.20', 'K57.32', 'K57.90', 'K57.92', 'K59.00', 'K59.39', 'K59.8', 'K59.9', 'K60.3', 'K62.1', 'K62.5', 'K62.6', 'K62.7', 'K62.89', 'K63.1', 'K63.2', 'K63.5', 'K63.9', 'K64.8', 'K64.9', 'K65.1', 'K65.3', 'K65.8', 'K65.9', 'K66.0', 'K66.1', 'K66.8', 'K68.12', 'K68.19', 'K68.9', 'K70.10', 'K70.30', 'K70.9', 'K71.6', 'K72.00', 'K72.90', 'K74.0', 'K74.60', 'K75.0', 'K75.4', 'K75.9', 'K76.0', 'K76.6', 'K76.7', 'K76.81', 'K76.89', 'K76.9', 'K80.10', 'K80.20', 'K80.5', 'K80.50', 'K80.51', 'K81.0', 'K82.8', 'K83.0', 'K83.1', 'K83.3', 'K83.8', 'K85.20', 'K85.90', 'K86.0', 'K86.1', 'K86.3', 'K86.89', 'K86.9', 'K90.0', 'K90.9', 'K91.7', 'K92.0', 'K92.1', 'K92.2', 'L02.01', 'L02.211', 'L02.31', 'L02.41', 'L02.91', 'L03.115', 'L03.90', 'L08.9', 'L10.0', 'L11.9', 'L21.9', 'L25.9', 'L28.2', 'L29.0', 'L29.9', 'L30.9', 'L40.53', 'L40.9', 'L43.9', 'L51.1', 'L51.2', 'L51.9', 'L53.9', 'L57.0', 'L60.8', 'L60.9', 'L65.9', 'L68.0', 'L74.0', 'L76.3', 'L81.9', 'L85.8', 'L85.9', 'L89.150', 'L90.5', 'L90.8', 'L91.0', 'L92.9', 'L93.0', 'L97.909', 'L97.919', 'L98.0', 'L98.49', 'L98.8', 'L98.9', 'M00.071', 'M00.9', 'M05.9', 'M06.9', 'M08.90', 'M08.961', 'M08.99', 'M13.0', 'M15.9', 'M16.0', 'M19.90', 'M21.959', 'M24.60', 'M24.641', 'M24.642', 'M25.40', 'M25.451', 'M25.50', 'M25.511', 'M25.519', 'M25.531', 'M25.532', 'M25.541', 'M25.551', 'M25.552', 'M25.561', 'M25.562', 'M25.569', 'M25.571', 'M25.60', 'M25.9', 'M26.02', 'M26.04', 'M26.09', 'M26.30', 'M26.32', 'M26.601', 'M26.609', 'M26.619', 'M26.9', 'M27.2', 'M30.3', 'M31.0', 'M31.1', 'M31.6', 'M32.9', 'M35.3', 'M41.9', 'M43.6', 'M45.9', 'M46.40', 'M46.47', 'M46.90', 'M46.96', 'M47.895', 'M47.9', 'M48.04', 'M51.24', 'M54.2', 'M54.40', 'M54.41', 'M54.5', 'M54.6', 'M54.9', 'M60.059', 'M60.9', 'M61.10', 'M62.50', 'M62.81', 'M62.82', 'M62.838', 'M62.89', 'M65.9', 'M71.30', 'M75.90', 'M79.1', 'M79.2', 'M79.60', 'M79.604', 'M79.605', 'M79.621', 'M79.641', 'M79.643', 'M79.644', 'M79.645', 'M79.652', 'M79.659', 'M79.671', 'M79.672', 'M79.673', 'M79.7', 'M80.08X', 'M81.0', 'M83.9', 'M84.30X', 'M84.453', 'M84.529', 'M85.2', 'M85.50', 'M85.60', 'M85.8', 'M85.80', 'M86.68', 'M86.9', 'M87.80', 'M88.832', 'M88.9', 'M89.072', 'M89.549', 'M89.59', 'M89.70', 'M89.8X', 'M89.8X9', 'M89.9', 'M94.359', 'N02.8', 'N03.9', 'N04.9', 'N05.5', 'N05.7', 'N05.9', 'N11.9', 'N13.30', 'N13.5', 'N13.6', 'N13.70', 'N13.8', 'N13.9', 'N17.0', 'N17.9', 'N18.2', 'N18.3', 'N18.4', 'N18.5', 'N18.6', 'N18.9', 'N20.0', 'N20.1', 'N20.9', 'N25.81', 'N26.1', 'N26.9', 'N28.0', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.8', 'N30.90', 'N31.9', 'N32.1', 'N32.3', 'N32.89', 'N32.9', 'N36.0', 'N36.8', 'N39.0', 'N39.44', 'N40.0', 'N40.2', 'N41.0', 'N41.1', 'N43.3', 'N44.00', 'N44.2', 'N44.8', 'N45.1', 'N45.2', 'N45.3', 'N45.4', 'N48.21', 'N48.29', 'N48.30', 'N48.6', 'N48.81', 'N48.89', 'N48.9', 'N49.2', 'N50.0', 'N50.3', 'N50.811', 'N50.819', 'N50.82', 'N50.89', 'N50.9', 'N52.9', 'N53.12', 'N60.01', 'N60.02', 'N60.11', 'N60.12', 'N60.19', 'N64.4', 'N64.89', 'N64.9', 'N80.8', 'N80.9', 'N83.00', 'N83.9', 'N85.8', 'N89.5', 'N90.89', 'N91.0', 'N92.1', 'N94.89', 'N97.9', 'O02.0', 'O03.9', 'O21.0', 'O32.1', 'O40.9XX0', 'O41.0', 'O41.00X', 'O41.1290', 'O42.912', 'O42.92', 'O47.9', 'O75.9', 'O99.11', 'P52.3', 'P91.60', 'Q03.1', 'Q03.9', 'Q04.0', 'Q05.9', 'Q07.00', 'Q10.0', 'Q12.4', 'Q13.0', 'Q13.4', 'Q21.1', 'Q23.1', 'Q24.8', 'Q24.9', 'Q27.30', 'Q27.9', 'Q28.2', 'Q32.4', 'Q35.3', 'Q37.9', 'Q38.2', 'Q42.9', 'Q44.6', 'Q44.7', 'Q45.0', 'Q51.0', 'Q51.3', 'Q51.811', 'Q52.0', 'Q53.10', 'Q55.29', 'Q60.6', 'Q61.02', 'Q61.19', 'Q61.3', 'Q62.8', 'Q63.1', 'Q64.4', 'Q67.0', 'Q68.0', 'Q70.9', 'Q75.0', 'Q75.3', 'Q78.2', 'Q79.1', 'Q85.00', 'Q85.1', 'Q85.8', 'Q85.9', 'Q87.2', 'Q87.3', 'Q87.81', 'Q89.2', 'Q98.4', 'R00.0', 'R00.1', 'R00.2', 'R01.1', 'R04.0', 'R04.2', 'R04.89', 'R06.00', 'R06.01', 'R06.09', 'R06.1', 'R06.4', 'R06.6', 'R06.82', 'R06.89', 'R07.0', 'R07.2', 'R07.81', 'R07.89', 'R07.9', 'R09.02', 'R09.2', 'R10.0', 'R10.10', 'R10.12', 'R10.13', 'R10.2', 'R10.30', 'R10.31', 'R10.32', 'R10.33', 'R10.811', 'R10.812', 'R10.813', 'R10.814', 'R10.815', 'R10.816', 'R10.817', 'R10.819', 'R10.83', 'R10.84', 'R10.9', 'R11.0', 'R11.10', 'R11.12', 'R11.14', 'R11.2', 'R13.10', 'R14.0', 'R16.0', 'R16.1', 'R16.2', 'R18.0', 'R18.8', 'R19.0', 'R19.00', 'R19.01', 'R19.02', 'R19.03', 'R19.04', 'R19.06', 'R19.2', 'R19.5', 'R19.7', 'R19.8', 'R20.0', 'R20.1', 'R20.2', 'R20.8', 'R20.9', 'R22.0', 'R22.1', 'R22.2', 'R22.9', 'R23.0', 'R23.1', 'R23.3', 'R23.4', 'R23.8', 'R25.1', 'R25.2', 'R25.3', 'R26.0', 'R26.2', 'R26.81', 'R26.89', 'R26.9', 'R27.0', 'R27.8', 'R29.2', 'R29.6', 'R29.723', 'R29.810', 'R29.898', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R33.9', 'R35.0', 'R35.1', 'R35.8', 'R36.1', 'R39.12', 'R39.14', 'R39.15', 'R39.198', 'R39.89', 'R39.9', 'R40.0', 'R40.1', 'R40.20', 'R40.241', 'R40.2410', 'R40.2420', 'R40.243', 'R40.2430', 'R40.3', 'R41.0', 'R41.3', 'R41.840', 'R41.843', 'R43.2', 'R43.9', 'R44.0', 'R44.1', 'R44.3', 'R44.9', 'R45.0', 'R45.1', 'R45.3', 'R45.4', 'R46.0', 'R47.01', 'R47.02', 'R47.1', 'R47.89', 'R47.9', 'R48.2', 'R49.0', 'R49.1', 'R50.81', 'R50.82', 'R50.9', 'R53.1', 'R53.81', 'R53.83', 'R56.00', 'R56.9', 'R57.0', 'R57.1', 'R57.9', 'R59.0', 'R59.9', 'R60.0', 'R60.1', 'R60.9', 'R63.0', 'R63.1', 'R63.3', 'R63.4', 'R65.20', 'R65.21', 'R68.83', 'R68.84', 'R68.89', 'R73.9', 'R74.0', 'R76.0', 'R76.11', 'R78.81', 'R79.82', 'R80.9', 'R82.2', 'R82.3', 'R91.1', 'R91.8', 'R97.1', 'R97.20', 'R97.8', 'S00.32X', 'S00.522', 'S00.532', 'S01.101', 'S01.20X', 'S01.501', 'S01.512', 'S01.80X', 'S01.95X', 'S02.19X', 'S02.5XX', 'S02.601', 'S02.652', 'S03.2XX', 'S05.8X2', 'S05.9', 'S05.92X', 'S06.0X0', 'S06.2X', 'S06.36', 'S06.9', 'S06.9X', 'S06.9X0', 'S09.90X', 'S09.92X', 'S11.80X', 'S11.90X', 'S11.91X', 'S19.9X', 'S20.92X', 'S22.39X', 'S23.163', 'S27.329', 'S27.899', 'S30.0XX', 'S30.1XX', 'S30.23', 'S31.809', 'S32.019', 'S32.50', 'S32.502', 'S32.602', 'S34.139', 'S35.229', 'S36.00X', 'S36.029', 'S36.09X', 'S37.009', 'S37.039', 'S37.812', 'S39.92', 'S39.94', 'S39.94X', 'S42.402', 'S42.409', 'S42.90X', 'S43.006', 'S43.40', 'S50.10X', 'S52.002', 'S52.102', 'S52.92X', 'S53.101', 'S60.229', 'S61.209', 'S70.312', 'S71.101', 'S80.821', 'S91.051', 'S92.312', 'S93.402', 'T14.8', 'T14.90', 'T14.91', 'T18.3XX', 'T20.00', 'T20.02X', 'T20.04X', 'T24.009', 'T24.011', 'T24.012', 'T30.0', 'T31.2', 'T56.0', 'T74.2', 'T79.7XX', 'T81.30', 'T81.4', 'T81.49X', 'T82.01X', 'T82.7XX', 'T82.868', 'T85.41X', 'T86.11', 'T86.822', 'V00.121', 'V37.0', 'V87.9', 'V99.XXX', 'W19.XXX', 'W34.00', 'W34.00X', 'W55.03', 'W55.22X', 'W56.81X', 'W57.XXX', 'W86.8XX', 'X08.8XX', 'X58.XXX', 'Z16.19', 'Z16.24', 'Z16.35', 'Z17.0', 'Z20.818', 'Z37.0', 'Z3A.16', 'Z3A.18', 'Z3A.20', 'Z3A.24', 'Z3A.35', 'Z3A.38', 'Z3A.39', 'Z51.5', 'Z53.31', 'Z67.10', 'Z68.1', 'Z68.26', 'Z68.34', 'Z68.36', 'Z68.4', 'Z68.41', 'Z68.42', 'Z68.45', 'Z74.01', 'Z75.1', 'Z76.82', 'Z77.29', 'Z79.01', 'Z79.02', 'Z79.1', 'Z79.4', 'Z79.52', 'Z79.82', 'Z79.83', 'Z79.84', 'Z79.890', 'Z80.0', 'Z80.3', 'Z82.41', 'Z83.3', 'Z85.3', 'Z86.11', 'Z86.61', 'Z86.718', 'Z86.73', 'Z87.01', 'Z87.440', 'Z87.442', 'Z87.81', 'Z87.891', 'Z88.0', 'Z88.1', 'Z88.2', 'Z88.8', 'Z90.3', 'Z90.49', 'Z90.5', 'Z90.710', 'Z90.721', 'Z90.79', 'Z90.81', 'Z91.041', 'Z92.0', 'Z92.21', 'Z92.3', 'Z93.0', 'Z93.2', 'Z94.0', 'Z95.1', 'Z95.2', 'Z96.0', 'Z96.1', 'Z97.4', 'Z98.84', 'Z98.85', 'Z99.2', 'Z99.3', 'Z99.81', 'Z99.89']\n",
      "Parent Accuracy: 100.00% | Child Accuracy: 90.91%\n",
      "F1 Validation | Micro: 0.02632 | Macro: 0.00624 | Best: 0.00575 | Epochs without improvement: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 603/603 [01:18<00:00,  7.71it/s, loss=0.752, lr=2.99e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 0.8319 | LR: 2.99E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['A23', 'A41', 'A55', 'A63', 'B02', 'B19', 'B20', 'B95', 'B96', 'B99', 'C18', 'C22', 'C48', 'C50', 'C61', 'C63', 'C64', 'C67', 'C70', 'C73', 'C77', 'C78', 'C80', 'D11', 'D12', 'D16', 'D49', 'D50', 'D64', 'D70', 'D72', 'E03', 'E05', 'E10', 'E11', 'E29', 'E66', 'E79', 'E80', 'E85', 'F10', 'F17', 'G45', 'G83', 'G93', 'H17', 'H18', 'H30', 'I10', 'I12', 'I25', 'I26', 'I48', 'I50', 'I51', 'I85', 'I86', 'I89', 'I95', 'I96', 'J44', 'J45', 'J90', 'J98', 'K02', 'K04', 'K12', 'K31', 'K35', 'K38', 'K40', 'K44', 'K51', 'K52', 'K55', 'K59', 'K62', 'K63', 'K65', 'K66', 'K75', 'K76', 'K85', 'L53', 'L92', 'L98', 'M06', 'M19', 'M25', 'M32', 'M45', 'M46', 'M54', 'M79', 'M89', 'N13', 'N18', 'N19', 'N20', 'N23', 'N26', 'N28', 'N30', 'N31', 'N32', 'N36', 'N39', 'N40', 'N43', 'N44', 'N45', 'N48', 'N50', 'N64', 'N92', 'Q28', 'Q51', 'Q61', 'Q63', 'Q64', 'Q89', 'R00', 'R04', 'R06', 'R10', 'R12', 'R13', 'R14', 'R16', 'R18', 'R19', 'R20', 'R22', 'R30', 'R31', 'R33', 'R35', 'R39', 'R50', 'R52', 'R53', 'R57', 'R58', 'R59', 'R60', 'R61', 'R63', 'R68', 'R69', 'R73', 'T81', 'T82', 'T85', 'W34', 'Z20', 'Z37', 'Z51', 'Z53', 'Z79', 'Z80', 'Z83', 'Z86', 'Z87', 'Z88', 'Z90', 'Z92', 'Z94', 'Z99']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A01.00', 'A01.4', 'A02.9', 'A04.5', 'A04.8', 'A15.0', 'A15.4', 'A15.6', 'A15.9', 'A18.09', 'A18.10', 'A18.12', 'A18.15', 'A18.2', 'A18.4', 'A18.50', 'A23.9', 'A31.9', 'A32.11', 'A32.9', 'A38.9', 'A40.3', 'A41.02', 'A41.1', 'A41.81', 'A41.9', 'A43.9', 'A44.9', 'A49.1', 'A49.8', 'A49.9', 'A53.9', 'A54.9', 'A63.0', 'A69.20', 'A74.9', 'A87.2', 'B00.9', 'B01.9', 'B02.21', 'B02.29', 'B05.9', 'B06.9', 'B07.9', 'B08.3', 'B10.89', 'B15.9', 'B18.2', 'B19.10', 'B19.20', 'B19.9', 'B27.00', 'B27.90', 'B27.99', 'B30.0', 'B30.9', 'B33.3', 'B34.1', 'B34.8', 'B35.9', 'B37.0', 'B37.2', 'B37.3', 'B37.81', 'B37.9', 'B45.2', 'B45.9', 'B46.5', 'B48.8', 'B55.9', 'B57.2', 'B65.0', 'B65.9', 'B67.90', 'B69.0', 'B69.9', 'B74.9', 'B83.0', 'B95.0', 'B95.2', 'B95.4', 'B95.5', 'B95.61', 'B95.62', 'B95.7', 'B95.8', 'B96.0', 'B96.1', 'B96.20', 'B96.3', 'B96.4', 'B96.5', 'B96.7', 'B96.81', 'B96.89', 'B97.0', 'B97.10', 'B97.12', 'B97.29', 'B97.4', 'B97.6', 'B97.7', 'B99.9', 'C02.1', 'C02.9', 'C04.9', 'C08.0', 'C10.9', 'C15.9', 'C16.0', 'C16.9', 'C17.1', 'C18.6', 'C18.7', 'C18.9', 'C21.0', 'C22.0', 'C22.1', 'C26.0', 'C31.2', 'C34.9', 'C34.90', 'C34.91', 'C40.20', 'C41.0', 'C43.9', 'C44.311', 'C44.49', 'C48.0', 'C48.2', 'C49.21', 'C49.5', 'C49.A', 'C49.A2', 'C50.312', 'C50.519', 'C50.9', 'C50.91', 'C50.912', 'C50.919', 'C53.9', 'C54.1', 'C56.2', 'C60.1', 'C62.90', 'C62.91', 'C62.92', 'C63.10', 'C63.8', 'C64.1', 'C64.2', 'C64.9', 'C65.9', 'C66.9', 'C67.2', 'C67.7', 'C67.9', 'C68.0', 'C69.32', 'C70.9', 'C74.90', 'C74.92', 'C75.0', 'C76.3', 'C77.2', 'C77.3', 'C77.8', 'C77.9', 'C78.00', 'C78.01', 'C78.02', 'C78.1', 'C78.39', 'C78.5', 'C78.6', 'C78.7', 'C78.89', 'C79.00', 'C79.02', 'C79.2', 'C79.31', 'C79.49', 'C79.51', 'C79.52', 'C79.70', 'C79.71', 'C79.72', 'C79.81', 'C79.82', 'C79.89', 'C79.9', 'C80.0', 'C80.1', 'C83.0', 'C83.1', 'C83.30', 'C83.39', 'C83.70', 'C84.49', 'C84.A', 'C85.9', 'C85.90', 'C85.99', 'C90.0', 'C90.3', 'C92.10', 'C94.6', 'C96.6', 'D09.0', 'D10.30', 'D11.0', 'D12.1', 'D12.6', 'D15.1', 'D16.22', 'D16.5', 'D17.23', 'D18.00', 'D18.03', 'D18.09', 'D18.1', 'D23.11', 'D23.9', 'D24.1', 'D24.9', 'D29.1', 'D29.30', 'D29.31', 'D30.00', 'D30.01', 'D30.02', 'D30.3', 'D31.9', 'D32.0', 'D32.9', 'D35.00', 'D35.02', 'D35.1', 'D36.11', 'D37.030', 'D37.8', 'D40.10', 'D40.11', 'D40.8', 'D41.00', 'D41.02', 'D44.10', 'D44.12', 'D44.2', 'D44.6', 'D44.7', 'D47.1', 'D47.3', 'D47.9', 'D48.1', 'D49.0', 'D49.1', 'D49.2', 'D49.3', 'D49.4', 'D49.511', 'D49.512', 'D49.519', 'D49.59', 'D49.7', 'D49.89', 'D50.0', 'D50.9', 'D53.1', 'D58.9', 'D61.818', 'D63.1', 'D64.9', 'D68.51', 'D68.59', 'D68.61', 'D68.9', 'D69.0', 'D69.2', 'D69.3', 'D69.41', 'D69.6', 'D69.9', 'D70.9', 'D72.0', 'D72.1', 'D72.810', 'D72.819', 'D72.821', 'D72.822', 'D72.829', 'D73.1', 'D73.3', 'D73.5', 'D73.89', 'D74.8', 'D75.89', 'D76.3', 'D84.9', 'D86.9', 'D89.2', 'E03.8', 'E03.9', 'E04.1', 'E04.2', 'E04.9', 'E05.00', 'E05.80', 'E05.90', 'E06.3', 'E07.9', 'E10.10', 'E10.9', 'E11.319', 'E11.359', 'E11.42', 'E11.622', 'E11.628', 'E11.9', 'E13.9', 'E16.2', 'E21.0', 'E21.3', 'E21.5', 'E23.0', 'E23.2', 'E27.0', 'E27.8', 'E27.9', 'E29.1', 'E44.0', 'E44.1', 'E50.9', 'E51.9', 'E56.9', 'E63.9', 'E66.01', 'E66.3', 'E66.9', 'E72.01', 'E74.00', 'E74.04', 'E75.29', 'E75.5', 'E77.8', 'E78.00', 'E78.1', 'E78.5', 'E79.0', 'E80.20', 'E80.7', 'E83.119', 'E83.39', 'E83.41', 'E83.42', 'E83.52', 'E83.59', 'E83.81', 'E85.4', 'E85.9', 'E86.0', 'E87.0', 'E87.1', 'E87.2', 'E87.3', 'E87.5', 'E87.6', 'E88.09', 'E89.0', 'F02.80', 'F10.10', 'F10.20', 'F10.21', 'F10.23', 'F11.20', 'F12.10', 'F12.20', 'F14.10', 'F14.20', 'F17.200', 'F17.210', 'F17.290', 'F19.20', 'F19.21', 'F25.0', 'F30.9', 'F32.9', 'F34.1', 'F41.8', 'F41.9', 'F43.20', 'F43.9', 'F45.29', 'F50.2', 'F63.9', 'F65.3', 'F80.81', 'F84.0', 'F90.9', 'F98.8', 'G00.1', 'G03.9', 'G04.1', 'G04.90', 'G06.0', 'G06.2', 'G12.20', 'G12.21', 'G25.0', 'G25.3', 'G30.9', 'G31.84', 'G40.119', 'G40.409', 'G40.909', 'G44.209', 'G45.9', 'G47.00', 'G47.30', 'G47.32', 'G47.33', 'G50.0', 'G51.0', 'G54.6', 'G56.92', 'G57.00', 'G57.01', 'G57.42', 'G58.9', 'G62.9', 'G70.00', 'G71.8', 'G72.3', 'G72.49', 'G72.9', 'G81.14', 'G81.90', 'G81.91', 'G81.94', 'G82.20', 'G82.21', 'G83.14', 'G83.2', 'G83.9', 'G89.29', 'G90.2', 'G90.50', 'G90.511', 'G91.8', 'G91.9', 'G93.0', 'G93.2', 'G93.40', 'G93.5', 'G93.6', 'G95.20', 'G95.9', 'G96.0', 'G97.2', 'H01.8', 'H02.40', 'H02.401', 'H02.402', 'H02.409', 'H02.411', 'H02.841', 'H02.843', 'H02.846', 'H02.849', 'H02.9', 'H04.20', 'H04.202', 'H05.2', 'H05.20', 'H05.221', 'H05.231', 'H10.9', 'H11.001', 'H11.002', 'H11.42', 'H11.421', 'H11.422', 'H11.429', 'H11.439', 'H15.00', 'H15.032', 'H15.092', 'H16.0', 'H16.001', 'H16.012', 'H16.07', 'H16.071', 'H16.9', 'H17.12', 'H17.9', 'H18.20', 'H18.89', 'H18.891', 'H18.9', 'H20.052', 'H20.059', 'H20.9', 'H21.26', 'H21.309', 'H21.42', 'H21.50', 'H21.501', 'H21.509', 'H21.542', 'H21.9', 'H25.1', 'H26.8', 'H26.9', 'H27.10', 'H30.14', 'H30.89', 'H30.93', 'H31.101', 'H31.103', 'H31.309', 'H31.32', 'H33.10', 'H33.101', 'H33.102', 'H33.19', 'H33.20', 'H33.21', 'H33.22', 'H35.00', 'H35.349', 'H35.50', 'H35.61', 'H35.62', 'H35.81', 'H35.89', 'H35.9', 'H40.10', 'H40.11', 'H40.9', 'H43.1', 'H43.12', 'H43.13', 'H44.00', 'H44.001', 'H44.009', 'H44.139', 'H44.40', 'H46.00', 'H46.9', 'H47.091', 'H47.092', 'H47.10', 'H49.02', 'H49.11', 'H49.21', 'H49.22', 'H49.23', 'H49.9', 'H50.011', 'H50.012', 'H50.112', 'H50.21', 'H50.22', 'H50.9', 'H52.1', 'H52.7', 'H53.14', 'H53.143', 'H53.15', 'H53.2', 'H53.40', 'H53.462', 'H53.8', 'H53.9', 'H54.0', 'H54.2', 'H54.3', 'H54.61', 'H54.62', 'H54.7', 'H55.00', 'H55.01', 'H57.02', 'H57.03', 'H57.1', 'H57.10', 'H57.11', 'H57.12', 'H57.13', 'H57.9', 'H59.03', 'H59.033', 'H60.91', 'H80.90', 'H90.12', 'H91.20', 'H91.3', 'H91.90', 'H91.91', 'H91.93', 'H92.01', 'H92.09', 'H93.19', 'I05.0', 'I05.9', 'I11.9', 'I12.0', 'I12.9', 'I20.8', 'I20.9', 'I21.11', 'I21.19', 'I21.29', 'I21.3', 'I23.7', 'I24.9', 'I25.10', 'I25.2', 'I25.9', 'I26.99', 'I27.2', 'I28.1', 'I30.9', 'I31.2', 'I31.3', 'I31.4', 'I33.0', 'I34.0', 'I34.1', 'I35.0', 'I35.8', 'I37.0', 'I42.0', 'I42.9', 'I44.2', 'I44.30', 'I45.10', 'I46.9', 'I47.1', 'I48.0', 'I48.2', 'I48.91', 'I48.92', 'I49.01', 'I49.9', 'I50.9', 'I51.4', 'I51.7', 'I51.9', 'I61.8', 'I61.9', 'I62.00', 'I62.01', 'I62.03', 'I62.9', 'I63.512', 'I63.519', 'I63.9', 'I65.21', 'I66.9', 'I67.1', 'I67.82', 'I70.0', 'I70.90', 'I71.00', 'I71.4', 'I72.9', 'I73.8', 'I74.9', 'I75.81', 'I75.89', 'I77.0', 'I77.1', 'I77.6', 'I77.9', 'I78.1', 'I80.8', 'I82.0', 'I82.210', 'I82.220', 'I82.3', 'I82.40', 'I82.401', 'I82.402', 'I82.409', 'I82.411', 'I82.431', 'I82.439', 'I82.90', 'I83.90', 'I83.93', 'I85.00', 'I86.1', 'I86.4', 'I87.1', 'I87.2', 'I87.8', 'I88.1', 'I88.9', 'I89.0', 'I89.1', 'I89.8', 'I95.9', 'J01.90', 'J02.9', 'J03.90', 'J03.91', 'J11.0', 'J11.1', 'J12.0', 'J18.1', 'J18.9', 'J21.8', 'J21.9', 'J30.1', 'J32.0', 'J32.4', 'J32.9', 'J34.1', 'J34.3', 'J34.89', 'J38.1', 'J38.4', 'J39.8', 'J43.9', 'J44.9', 'J45.909', 'J47.9', 'J69.0', 'J81.0', 'J81.1', 'J84.01', 'J84.10', 'J84.89', 'J85.2', 'J86.0', 'J93.9', 'J94.0', 'J94.2', 'J94.8', 'J96.00', 'J96.90', 'J96.92', 'J98.01', 'J98.11', 'J98.2', 'J98.4', 'J98.51', 'J98.8', 'K00.0', 'K00.1', 'K01.0', 'K02.9', 'K04.7', 'K05.10', 'K06.1', 'K06.2', 'K06.8', 'K08.109', 'K08.89', 'K08.9', 'K09.0', 'K11.1', 'K11.20', 'K11.6', 'K11.7', 'K11.9', 'K12.0', 'K12.1', 'K12.2', 'K13.0', 'K13.21', 'K13.29', 'K13.70', 'K13.79', 'K14.5', 'K14.9', 'K20.9', 'K21.9', 'K22.2', 'K22.70', 'K22.8', 'K22.9', 'K25.9', 'K26.4', 'K26.9', 'K27.9', 'K31.1', 'K31.5', 'K31.7', 'K31.819', 'K31.89', 'K31.9', 'K35.2', 'K35.80', 'K38.8', 'K40.20', 'K40.30', 'K40.90', 'K42.9', 'K44.9', 'K46.9', 'K50.00', 'K50.90', 'K51.00', 'K51.90', 'K52.3', 'K52.81', 'K52.82', 'K52.9', 'K55.049', 'K55.059', 'K55.1', 'K55.20', 'K55.21', 'K55.9', 'K56.1', 'K56.2', 'K56.60', 'K56.69', 'K57.00', 'K57.10', 'K57.20', 'K57.32', 'K57.90', 'K57.92', 'K59.00', 'K59.39', 'K59.8', 'K59.9', 'K62.1', 'K62.5', 'K62.6', 'K62.7', 'K62.89', 'K63.1', 'K63.2', 'K63.5', 'K63.9', 'K64.8', 'K64.9', 'K65.1', 'K65.3', 'K65.8', 'K65.9', 'K66.0', 'K66.1', 'K66.8', 'K68.12', 'K68.19', 'K68.9', 'K70.10', 'K70.30', 'K70.9', 'K71.6', 'K72.00', 'K72.90', 'K74.0', 'K74.60', 'K75.0', 'K75.4', 'K75.9', 'K76.0', 'K76.6', 'K76.7', 'K76.81', 'K76.89', 'K76.9', 'K80.10', 'K80.20', 'K80.5', 'K80.50', 'K80.51', 'K81.0', 'K82.8', 'K83.0', 'K83.1', 'K83.3', 'K83.8', 'K85.20', 'K85.90', 'K86.0', 'K86.1', 'K86.3', 'K86.89', 'K86.9', 'K90.0', 'K90.9', 'K91.7', 'K92.0', 'K92.1', 'K92.2', 'L02.01', 'L02.211', 'L02.31', 'L02.41', 'L02.91', 'L03.115', 'L03.90', 'L08.9', 'L10.0', 'L21.9', 'L25.9', 'L28.2', 'L29.0', 'L29.9', 'L30.9', 'L40.9', 'L43.9', 'L51.1', 'L51.2', 'L51.9', 'L53.9', 'L57.0', 'L60.8', 'L60.9', 'L65.9', 'L68.0', 'L74.0', 'L76.3', 'L81.9', 'L85.8', 'L85.9', 'L89.150', 'L90.5', 'L90.8', 'L91.0', 'L92.9', 'L93.0', 'L97.909', 'L97.919', 'L98.0', 'L98.49', 'L98.8', 'L98.9', 'M00.071', 'M00.9', 'M05.9', 'M06.9', 'M08.90', 'M08.961', 'M08.99', 'M13.0', 'M15.9', 'M16.0', 'M19.90', 'M21.959', 'M24.641', 'M24.642', 'M25.40', 'M25.451', 'M25.50', 'M25.512', 'M25.519', 'M25.531', 'M25.532', 'M25.541', 'M25.551', 'M25.552', 'M25.561', 'M25.562', 'M25.569', 'M25.571', 'M25.60', 'M25.9', 'M26.02', 'M26.04', 'M26.09', 'M26.30', 'M26.32', 'M26.601', 'M26.609', 'M26.619', 'M26.9', 'M27.2', 'M30.3', 'M31.0', 'M31.1', 'M31.6', 'M32.9', 'M35.3', 'M41.9', 'M43.6', 'M45.9', 'M46.40', 'M46.47', 'M46.90', 'M46.96', 'M47.895', 'M47.9', 'M51.24', 'M54.2', 'M54.40', 'M54.41', 'M54.5', 'M54.6', 'M54.9', 'M60.059', 'M60.9', 'M61.10', 'M62.50', 'M62.82', 'M62.838', 'M62.89', 'M65.9', 'M71.30', 'M79.1', 'M79.2', 'M79.60', 'M79.604', 'M79.605', 'M79.621', 'M79.641', 'M79.643', 'M79.644', 'M79.645', 'M79.652', 'M79.659', 'M79.671', 'M79.672', 'M79.673', 'M79.7', 'M80.08X', 'M81.0', 'M83.9', 'M84.453', 'M84.529', 'M85.2', 'M85.50', 'M85.8', 'M86.60', 'M86.68', 'M86.9', 'M87.80', 'M88.832', 'M88.9', 'M89.072', 'M89.59', 'M89.70', 'M89.8X', 'M89.8X9', 'M89.9', 'M94.359', 'N02.8', 'N03.9', 'N04.9', 'N05.5', 'N05.7', 'N05.9', 'N11.9', 'N13.30', 'N13.5', 'N13.6', 'N13.70', 'N13.8', 'N13.9', 'N17.0', 'N17.9', 'N18.2', 'N18.3', 'N18.4', 'N18.5', 'N18.6', 'N18.9', 'N20.0', 'N20.1', 'N20.9', 'N25.81', 'N26.1', 'N26.9', 'N28.0', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.8', 'N30.90', 'N31.9', 'N32.0', 'N32.1', 'N32.3', 'N32.89', 'N32.9', 'N34.2', 'N36.0', 'N36.8', 'N39.0', 'N39.44', 'N40.0', 'N40.2', 'N41.0', 'N41.1', 'N43.3', 'N44.00', 'N44.2', 'N44.8', 'N45.1', 'N45.2', 'N45.3', 'N45.4', 'N48.21', 'N48.29', 'N48.30', 'N48.6', 'N48.81', 'N48.89', 'N48.9', 'N49.2', 'N50.0', 'N50.3', 'N50.811', 'N50.812', 'N50.819', 'N50.82', 'N50.89', 'N50.9', 'N52.9', 'N53.12', 'N60.01', 'N60.02', 'N60.11', 'N60.12', 'N60.19', 'N64.4', 'N64.89', 'N64.9', 'N80.8', 'N80.9', 'N83.00', 'N83.9', 'N85.8', 'N89.5', 'N91.0', 'N92.1', 'N94.89', 'N97.9', 'O02.0', 'O03.9', 'O21.0', 'O32.1', 'O40.9XX0', 'O41.0', 'O41.00X', 'O41.1290', 'O42.912', 'O42.92', 'P81.9', 'P91.60', 'Q03.1', 'Q05.9', 'Q07.00', 'Q12.4', 'Q13.0', 'Q13.4', 'Q21.1', 'Q23.1', 'Q24.8', 'Q24.9', 'Q27.30', 'Q27.9', 'Q28.2', 'Q32.4', 'Q35.3', 'Q37.9', 'Q38.2', 'Q42.9', 'Q44.6', 'Q44.7', 'Q45.0', 'Q51.0', 'Q51.3', 'Q51.811', 'Q52.0', 'Q53.10', 'Q55.29', 'Q60.6', 'Q61.02', 'Q61.19', 'Q61.3', 'Q62.8', 'Q63.1', 'Q64.4', 'Q67.0', 'Q70.9', 'Q75.0', 'Q75.3', 'Q78.2', 'Q79.1', 'Q85.00', 'Q85.1', 'Q85.8', 'Q85.9', 'Q87.2', 'Q87.3', 'Q87.81', 'Q89.2', 'Q98.4', 'R00.0', 'R00.1', 'R00.2', 'R01.1', 'R04.0', 'R04.2', 'R04.89', 'R06.00', 'R06.01', 'R06.09', 'R06.1', 'R06.4', 'R06.6', 'R06.82', 'R06.89', 'R07.0', 'R07.2', 'R07.81', 'R07.89', 'R07.9', 'R09.02', 'R09.2', 'R10.0', 'R10.10', 'R10.12', 'R10.13', 'R10.2', 'R10.30', 'R10.31', 'R10.32', 'R10.33', 'R10.811', 'R10.812', 'R10.813', 'R10.814', 'R10.815', 'R10.816', 'R10.817', 'R10.819', 'R10.83', 'R10.84', 'R10.9', 'R11.0', 'R11.10', 'R11.12', 'R11.14', 'R11.2', 'R13.10', 'R14.0', 'R16.0', 'R16.1', 'R16.2', 'R18.0', 'R18.8', 'R19.0', 'R19.00', 'R19.01', 'R19.02', 'R19.03', 'R19.04', 'R19.06', 'R19.2', 'R19.5', 'R19.7', 'R19.8', 'R20.0', 'R20.1', 'R20.2', 'R20.8', 'R20.9', 'R22.0', 'R22.1', 'R22.2', 'R22.9', 'R23.0', 'R23.1', 'R23.3', 'R23.4', 'R23.8', 'R25.1', 'R25.2', 'R26.0', 'R26.2', 'R26.81', 'R26.89', 'R27.8', 'R29.2', 'R29.6', 'R29.723', 'R29.810', 'R29.898', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R33.9', 'R35.0', 'R35.1', 'R35.8', 'R36.1', 'R39.12', 'R39.14', 'R39.15', 'R39.198', 'R39.89', 'R39.9', 'R40.0', 'R40.1', 'R40.20', 'R40.241', 'R40.2410', 'R40.2420', 'R40.243', 'R40.2430', 'R40.3', 'R40.4', 'R41.3', 'R41.840', 'R41.843', 'R43.2', 'R43.9', 'R44.1', 'R44.3', 'R44.9', 'R45.0', 'R45.1', 'R45.3', 'R45.4', 'R46.0', 'R47.01', 'R47.02', 'R47.1', 'R47.89', 'R47.9', 'R49.0', 'R49.1', 'R50.81', 'R50.82', 'R50.9', 'R53.1', 'R53.81', 'R53.83', 'R56.00', 'R57.0', 'R57.1', 'R57.9', 'R59.0', 'R59.9', 'R60.0', 'R60.1', 'R60.9', 'R63.0', 'R63.1', 'R63.3', 'R63.4', 'R65.20', 'R65.21', 'R68.83', 'R68.84', 'R68.89', 'R73.9', 'R74.0', 'R76.0', 'R76.11', 'R78.81', 'R79.82', 'R80.9', 'R82.2', 'R82.3', 'R91.1', 'R91.8', 'R97.1', 'R97.8', 'S00.32X', 'S00.522', 'S00.532', 'S01.101', 'S01.20X', 'S01.501', 'S01.512', 'S01.80X', 'S01.95X', 'S02.0XX', 'S02.19X', 'S02.5XX', 'S02.601', 'S02.652', 'S03.2XX', 'S05.8X2', 'S05.9', 'S05.92X', 'S06.0X0', 'S06.2X', 'S06.36', 'S06.9', 'S06.9X', 'S06.9X0', 'S09.90X', 'S09.92X', 'S11.80X', 'S11.90X', 'S19.9X', 'S20.92X', 'S27.899', 'S30.0XX', 'S30.23', 'S31.809', 'S32.019', 'S32.50', 'S32.502', 'S35.229', 'S36.00X', 'S36.029', 'S36.09X', 'S39.94', 'S39.94X', 'S42.402', 'S42.409', 'S42.90X', 'S43.40', 'S50.10X', 'S52.002', 'S52.102', 'S52.92X', 'S60.229', 'S61.209', 'S70.312', 'S71.101', 'S91.051', 'S92.312', 'S93.402', 'T14.8', 'T14.90', 'T14.91', 'T18.3XX', 'T20.00', 'T20.02X', 'T20.04X', 'T24.009', 'T24.011', 'T24.012', 'T30.0', 'T31.2', 'T56.0', 'T74.2', 'T79.7XX', 'T81.30', 'T81.4', 'T81.49X', 'T82.01X', 'T82.7XX', 'T82.868', 'T85.41X', 'T86.11', 'T86.822', 'V00.121', 'V37.0', 'V87.9', 'V89.9XX', 'W16.011', 'W19.XXX', 'W34.00', 'W34.00X', 'W55.03', 'W55.22X', 'W56.81X', 'W57.XXX', 'W86.8XX', 'X58.XXX', 'Z16.19', 'Z16.24', 'Z16.35', 'Z17.0', 'Z20.818', 'Z37.0', 'Z3A.16', 'Z3A.18', 'Z3A.20', 'Z3A.24', 'Z3A.38', 'Z3A.39', 'Z51.5', 'Z53.29', 'Z53.31', 'Z67.10', 'Z68.1', 'Z68.26', 'Z68.34', 'Z68.36', 'Z68.4', 'Z68.41', 'Z68.42', 'Z68.45', 'Z74.01', 'Z75.1', 'Z76.82', 'Z77.29', 'Z79.01', 'Z79.02', 'Z79.1', 'Z79.4', 'Z79.52', 'Z79.82', 'Z79.83', 'Z79.84', 'Z79.890', 'Z80.0', 'Z80.3', 'Z82.41', 'Z83.3', 'Z85.3', 'Z86.11', 'Z86.61', 'Z86.718', 'Z86.73', 'Z87.440', 'Z87.442', 'Z87.81', 'Z87.891', 'Z88.0', 'Z88.1', 'Z88.2', 'Z88.8', 'Z90.3', 'Z90.49', 'Z90.5', 'Z90.710', 'Z90.721', 'Z90.79', 'Z90.81', 'Z91.041', 'Z92.0', 'Z92.21', 'Z92.3', 'Z93.0', 'Z93.2', 'Z94.0', 'Z95.1', 'Z95.2', 'Z96.0', 'Z96.1', 'Z97.4', 'Z98.84', 'Z98.85', 'Z99.2', 'Z99.3', 'Z99.81', 'Z99.89']\n",
      "Parent Accuracy: 70.00% | Child Accuracy: 90.91%\n",
      "Saving best model... 0.00575 -> 0.00779\n",
      "F1 Validation | Micro: 0.03850 | Macro: 0.00779 | Best: 0.00779 | Epochs without improvement: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 603/603 [01:17<00:00,  7.79it/s, loss=0.276, lr=2.99e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 0.5969 | LR: 2.99E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'C48', 'C50', 'C64', 'C67', 'C78', 'D49', 'D72', 'E03', 'E11', 'E66', 'E79', 'E80', 'E85', 'F17', 'I10', 'I82', 'I85', 'I86', 'I96', 'J45', 'J98', 'K31', 'K40', 'K52', 'K59', 'K62', 'K63', 'K65', 'K66', 'L53', 'L98', 'M06', 'M19', 'M25', 'M54', 'M79', 'M89', 'N13', 'N18', 'N20', 'N28', 'N30', 'N32', 'N39', 'N40', 'Q61', 'Q64', 'R10', 'R14', 'R16', 'R19', 'R20', 'R22', 'R30', 'R31', 'R33', 'R35', 'R50', 'R52', 'R53', 'R59', 'R60', 'R61', 'R63', 'R68', 'R69', 'Z79', 'Z87', 'Z90', 'Z92', 'Z99']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A04.5', 'A15.0', 'A15.4', 'A15.6', 'A15.9', 'A18.09', 'A18.10', 'A18.12', 'A18.15', 'A18.2', 'A18.4', 'A18.50', 'A23.9', 'A32.11', 'A32.9', 'A40.3', 'A41.9', 'A43.9', 'A49.1', 'A49.8', 'A53.9', 'A63.0', 'A74.9', 'B02.29', 'B10.89', 'B18.2', 'B19.10', 'B19.9', 'B27.90', 'B27.99', 'B37.0', 'B37.2', 'B37.3', 'B37.81', 'B45.2', 'B45.9', 'B46.5', 'B57.2', 'B65.9', 'B67.90', 'B69.0', 'B69.9', 'B74.9', 'B95.4', 'B95.5', 'B95.61', 'B95.7', 'B95.8', 'B96.1', 'B96.20', 'B96.3', 'B96.4', 'B96.5', 'B96.7', 'B96.81', 'B97.7', 'B99.9', 'C02.1', 'C02.9', 'C04.9', 'C08.0', 'C15.9', 'C16.0', 'C16.9', 'C17.1', 'C18.6', 'C18.9', 'C22.0', 'C22.1', 'C26.0', 'C31.2', 'C34.9', 'C34.90', 'C34.91', 'C40.20', 'C41.0', 'C41.1', 'C44.49', 'C48.0', 'C48.2', 'C49.21', 'C49.5', 'C49.A', 'C49.A2', 'C50.312', 'C50.519', 'C50.91', 'C50.912', 'C50.919', 'C53.9', 'C54.1', 'C56.2', 'C60.1', 'C62.90', 'C62.91', 'C62.92', 'C63.10', 'C63.8', 'C64.1', 'C64.2', 'C64.9', 'C65.9', 'C66.9', 'C67.2', 'C67.7', 'C67.9', 'C68.0', 'C69.32', 'C70.9', 'C74.90', 'C74.92', 'C75.0', 'C76.3', 'C77.2', 'C77.3', 'C77.8', 'C77.9', 'C78.00', 'C78.01', 'C78.02', 'C78.1', 'C78.39', 'C78.5', 'C78.6', 'C78.7', 'C79.00', 'C79.02', 'C79.2', 'C79.31', 'C79.49', 'C79.51', 'C79.52', 'C79.70', 'C79.71', 'C79.72', 'C79.81', 'C79.82', 'C79.89', 'C79.9', 'C80.0', 'C80.1', 'C83.1', 'C83.30', 'C83.39', 'C83.70', 'C84.A', 'C85.9', 'C85.90', 'C90.0', 'C90.3', 'C92.10', 'C94.6', 'C96.6', 'D09.0', 'D10.30', 'D11.0', 'D12.1', 'D12.6', 'D15.1', 'D16.22', 'D16.5', 'D17.23', 'D18.00', 'D18.03', 'D18.09', 'D18.1', 'D23.11', 'D23.9', 'D24.1', 'D24.9', 'D29.1', 'D29.30', 'D29.31', 'D30.00', 'D30.01', 'D30.02', 'D30.3', 'D31.9', 'D32.9', 'D35.00', 'D35.02', 'D35.1', 'D36.11', 'D37.030', 'D37.8', 'D40.10', 'D40.11', 'D40.8', 'D41.00', 'D41.02', 'D44.10', 'D44.12', 'D44.6', 'D47.1', 'D47.3', 'D49.0', 'D49.1', 'D49.2', 'D49.3', 'D49.4', 'D49.511', 'D49.512', 'D49.519', 'D49.59', 'D49.7', 'D49.89', 'D50.9', 'D61.818', 'D63.1', 'D64.9', 'D68.51', 'D68.59', 'D68.61', 'D68.9', 'D69.0', 'D69.2', 'D69.3', 'D69.41', 'D69.9', 'D70.9', 'D72.0', 'D72.1', 'D72.819', 'D72.821', 'D72.822', 'D72.829', 'D73.1', 'D73.5', 'D73.89', 'D74.8', 'D76.3', 'E03.9', 'E04.1', 'E04.2', 'E04.9', 'E05.00', 'E05.80', 'E05.90', 'E06.3', 'E07.9', 'E10.9', 'E11.319', 'E11.42', 'E11.622', 'E11.628', 'E11.9', 'E13.9', 'E21.0', 'E21.3', 'E21.5', 'E23.0', 'E27.0', 'E27.9', 'E29.1', 'E44.0', 'E51.9', 'E63.9', 'E66.01', 'E66.3', 'E66.9', 'E72.01', 'E74.04', 'E77.8', 'E78.00', 'E78.1', 'E78.5', 'E79.0', 'E80.20', 'E80.7', 'E83.41', 'E83.52', 'E83.59', 'E83.81', 'E85.4', 'E85.9', 'E86.0', 'E87.2', 'E88.09', 'F02.80', 'F10.10', 'F10.20', 'F10.21', 'F10.23', 'F12.20', 'F14.20', 'F17.200', 'F17.210', 'F17.290', 'F19.20', 'F19.21', 'F32.9', 'F41.8', 'F41.9', 'F50.2', 'F90.9', 'G03.9', 'G06.2', 'G12.20', 'G12.21', 'G25.0', 'G25.3', 'G30.9', 'G40.119', 'G44.209', 'G45.9', 'G47.00', 'G47.30', 'G47.32', 'G47.33', 'G50.0', 'G54.6', 'G57.00', 'G57.01', 'G57.42', 'G58.9', 'G62.9', 'G70.00', 'G71.8', 'G72.3', 'G72.49', 'G72.9', 'G81.14', 'G83.14', 'G83.2', 'G83.9', 'G89.29', 'G90.2', 'G90.50', 'G90.511', 'G91.8', 'G93.2', 'G93.5', 'G95.20', 'G95.9', 'G96.0', 'G97.2', 'H02.40', 'H02.401', 'H02.402', 'H02.409', 'H02.841', 'H02.843', 'H02.849', 'H04.20', 'H05.2', 'H05.20', 'H05.231', 'H10.9', 'H11.42', 'H11.422', 'H15.00', 'H16.0', 'H16.07', 'H16.9', 'H17.9', 'H18.20', 'H18.891', 'H20.9', 'H21.26', 'H21.309', 'H21.501', 'H21.9', 'H25.1', 'H30.14', 'H30.89', 'H30.93', 'H31.101', 'H31.32', 'H33.10', 'H33.101', 'H33.102', 'H33.19', 'H33.21', 'H35.00', 'H35.50', 'H35.61', 'H35.62', 'H35.9', 'H40.10', 'H40.11', 'H43.12', 'H44.001', 'H46.00', 'H47.092', 'H49.02', 'H49.11', 'H49.22', 'H49.23', 'H49.9', 'H50.011', 'H50.012', 'H50.112', 'H50.9', 'H53.15', 'H53.2', 'H53.8', 'H53.9', 'H54.0', 'H54.62', 'H54.7', 'H57.03', 'H57.1', 'H57.10', 'H57.11', 'H57.12', 'H57.13', 'H57.9', 'H59.033', 'H80.90', 'H91.20', 'H91.3', 'H91.90', 'H91.91', 'I05.0', 'I05.9', 'I12.0', 'I12.9', 'I20.8', 'I20.9', 'I21.11', 'I21.19', 'I21.29', 'I21.3', 'I23.7', 'I24.9', 'I25.10', 'I25.2', 'I25.9', 'I26.99', 'I27.2', 'I28.1', 'I30.9', 'I31.4', 'I35.0', 'I35.8', 'I42.0', 'I42.9', 'I44.2', 'I44.30', 'I45.10', 'I47.1', 'I48.2', 'I48.91', 'I48.92', 'I49.01', 'I49.9', 'I50.9', 'I51.7', 'I51.9', 'I62.00', 'I62.01', 'I62.9', 'I63.519', 'I65.21', 'I65.8', 'I67.1', 'I70.0', 'I71.00', 'I71.4', 'I72.9', 'I75.81', 'I77.0', 'I77.1', 'I77.9', 'I78.1', 'I80.8', 'I82.0', 'I82.210', 'I82.220', 'I82.3', 'I82.411', 'I82.431', 'I82.439', 'I82.90', 'I83.90', 'I83.93', 'I85.00', 'I86.1', 'I86.4', 'I87.1', 'I87.2', 'I87.8', 'I88.1', 'I88.9', 'I89.0', 'I89.8', 'J01.90', 'J02.9', 'J03.90', 'J03.91', 'J18.1', 'J32.0', 'J32.4', 'J32.9', 'J34.1', 'J34.3', 'J34.89', 'J38.1', 'J39.8', 'J43.9', 'J44.9', 'J45.909', 'J47.9', 'J81.0', 'J84.01', 'J85.2', 'J94.0', 'J94.8', 'J96.00', 'J98.01', 'J98.11', 'J98.4', 'J98.51', 'J98.8', 'K00.0', 'K00.1', 'K01.0', 'K02.9', 'K04.7', 'K05.10', 'K06.1', 'K06.2', 'K06.8', 'K08.109', 'K08.89', 'K08.9', 'K09.0', 'K11.1', 'K11.6', 'K11.9', 'K12.0', 'K12.1', 'K12.2', 'K13.0', 'K13.21', 'K13.29', 'K13.70', 'K13.79', 'K14.5', 'K14.9', 'K20.9', 'K21.9', 'K22.2', 'K22.70', 'K22.8', 'K22.9', 'K25.9', 'K26.4', 'K26.9', 'K31.1', 'K31.5', 'K31.7', 'K31.819', 'K31.89', 'K31.9', 'K35.2', 'K35.80', 'K38.8', 'K40.20', 'K40.30', 'K40.90', 'K42.9', 'K44.9', 'K46.9', 'K50.00', 'K50.90', 'K51.00', 'K51.90', 'K52.3', 'K52.81', 'K52.82', 'K52.9', 'K55.049', 'K55.059', 'K55.1', 'K55.20', 'K55.21', 'K55.9', 'K56.1', 'K56.2', 'K56.60', 'K56.69', 'K57.00', 'K57.10', 'K57.20', 'K57.32', 'K57.90', 'K57.92', 'K59.00', 'K59.39', 'K59.8', 'K59.9', 'K62.1', 'K62.5', 'K62.6', 'K62.7', 'K62.89', 'K63.1', 'K63.2', 'K63.5', 'K63.9', 'K64.8', 'K64.9', 'K65.1', 'K65.3', 'K65.9', 'K66.0', 'K66.1', 'K66.8', 'K68.12', 'K68.19', 'K68.9', 'K70.30', 'K71.6', 'K72.90', 'K75.0', 'K75.9', 'K76.0', 'K76.6', 'K76.7', 'K76.81', 'K76.89', 'K76.9', 'K80.10', 'K80.20', 'K80.5', 'K80.50', 'K80.51', 'K81.0', 'K82.8', 'K83.0', 'K83.1', 'K83.3', 'K83.8', 'K85.20', 'K86.3', 'K86.89', 'K90.0', 'K90.9', 'K91.7', 'K92.0', 'K92.1', 'K92.2', 'L02.01', 'L02.211', 'L02.41', 'L02.91', 'L21.9', 'L25.9', 'L28.2', 'L29.0', 'L30.9', 'L40.9', 'L43.9', 'L53.9', 'L60.9', 'L65.9', 'L74.0', 'L76.3', 'L90.5', 'L91.0', 'L92.9', 'L93.0', 'L97.909', 'L97.919', 'L98.0', 'L98.8', 'L98.9', 'M00.071', 'M00.9', 'M05.9', 'M06.9', 'M08.90', 'M08.961', 'M08.99', 'M13.0', 'M19.90', 'M21.959', 'M25.40', 'M25.451', 'M25.50', 'M25.512', 'M25.519', 'M25.531', 'M25.551', 'M25.552', 'M25.561', 'M25.562', 'M25.569', 'M25.571', 'M25.9', 'M26.02', 'M26.04', 'M26.09', 'M26.30', 'M26.32', 'M26.601', 'M26.609', 'M26.9', 'M27.2', 'M31.1', 'M31.6', 'M32.9', 'M41.9', 'M45.9', 'M46.40', 'M46.47', 'M46.90', 'M46.96', 'M47.895', 'M47.896', 'M47.9', 'M51.24', 'M54.2', 'M54.40', 'M54.41', 'M54.5', 'M54.6', 'M54.9', 'M60.059', 'M62.50', 'M62.82', 'M62.838', 'M62.89', 'M65.9', 'M71.30', 'M79.1', 'M79.2', 'M79.604', 'M79.605', 'M79.621', 'M79.641', 'M79.643', 'M79.644', 'M79.645', 'M79.659', 'M79.671', 'M79.672', 'M79.7', 'M80.08X', 'M84.453', 'M84.529', 'M85.50', 'M85.8', 'M86.68', 'M86.9', 'M87.80', 'M88.9', 'M89.072', 'M89.8X', 'M89.9', 'N04.9', 'N05.7', 'N11.9', 'N13.30', 'N13.6', 'N13.70', 'N13.8', 'N13.9', 'N17.0', 'N17.9', 'N18.2', 'N18.3', 'N18.4', 'N18.5', 'N18.9', 'N20.0', 'N20.1', 'N20.9', 'N26.1', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.8', 'N30.90', 'N31.9', 'N32.1', 'N32.3', 'N32.89', 'N32.9', 'N36.0', 'N39.0', 'N39.44', 'N40.0', 'N41.0', 'N41.1', 'N43.3', 'N44.00', 'N44.2', 'N44.8', 'N45.1', 'N45.2', 'N45.3', 'N45.4', 'N48.21', 'N48.29', 'N48.30', 'N48.6', 'N48.81', 'N48.89', 'N48.9', 'N49.2', 'N50.0', 'N50.3', 'N50.811', 'N50.812', 'N50.819', 'N50.82', 'N50.89', 'N50.9', 'N52.9', 'N53.12', 'N60.01', 'N60.02', 'N60.11', 'N60.12', 'N60.19', 'N64.4', 'N64.89', 'N64.9', 'N80.8', 'N80.9', 'N83.00', 'N83.9', 'N85.8', 'N89.5', 'N91.0', 'N92.1', 'N97.9', 'O03.9', 'O21.0', 'O40.9XX0', 'O41.1290', 'O42.912', 'O42.92', 'P81.9', 'Q12.4', 'Q13.4', 'Q23.1', 'Q24.8', 'Q27.30', 'Q27.9', 'Q28.2', 'Q32.4', 'Q37.9', 'Q38.2', 'Q42.9', 'Q44.6', 'Q44.7', 'Q45.0', 'Q51.3', 'Q52.0', 'Q53.10', 'Q55.29', 'Q61.19', 'Q61.3', 'Q63.1', 'Q64.4', 'Q67.0', 'Q70.9', 'Q79.1', 'Q85.00', 'Q85.1', 'Q85.8', 'Q85.9', 'Q87.2', 'Q87.3', 'Q87.81', 'Q89.2', 'Q98.4', 'R00.0', 'R04.2', 'R04.89', 'R06.00', 'R06.01', 'R06.09', 'R06.1', 'R06.4', 'R06.6', 'R06.82', 'R06.89', 'R07.2', 'R07.89', 'R07.9', 'R09.02', 'R10.0', 'R10.10', 'R10.13', 'R10.2', 'R10.30', 'R10.31', 'R10.32', 'R10.33', 'R10.811', 'R10.812', 'R10.813', 'R10.814', 'R10.815', 'R10.816', 'R10.817', 'R10.819', 'R10.83', 'R10.84', 'R10.9', 'R11.0', 'R11.10', 'R11.12', 'R11.14', 'R11.2', 'R13.10', 'R14.0', 'R16.1', 'R16.2', 'R18.0', 'R18.8', 'R19.0', 'R19.00', 'R19.01', 'R19.02', 'R19.03', 'R19.04', 'R19.06', 'R19.7', 'R19.8', 'R20.0', 'R20.1', 'R20.2', 'R20.8', 'R22.0', 'R22.1', 'R22.2', 'R22.9', 'R23.0', 'R23.1', 'R23.8', 'R25.1', 'R25.2', 'R29.6', 'R29.723', 'R29.898', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R33.9', 'R35.0', 'R35.1', 'R35.8', 'R36.1', 'R39.12', 'R39.14', 'R39.15', 'R39.198', 'R39.89', 'R39.9', 'R40.0', 'R40.1', 'R40.241', 'R40.2410', 'R40.243', 'R40.3', 'R40.4', 'R43.2', 'R44.1', 'R44.9', 'R45.0', 'R45.3', 'R45.4', 'R47.1', 'R47.89', 'R47.9', 'R49.0', 'R49.1', 'R50.81', 'R50.82', 'R50.9', 'R53.1', 'R53.81', 'R57.0', 'R57.1', 'R57.9', 'R59.0', 'R59.9', 'R60.0', 'R60.9', 'R63.0', 'R63.1', 'R63.3', 'R63.4', 'R65.20', 'R65.21', 'R68.83', 'R68.84', 'R68.89', 'R73.9', 'R74.0', 'R76.11', 'R78.81', 'R79.82', 'R80.9', 'R82.3', 'R91.1', 'R91.8', 'R97.1', 'R97.8', 'S00.532', 'S01.20X', 'S01.501', 'S01.512', 'S01.80X', 'S02.0XX', 'S02.5XX', 'S02.601', 'S03.2XX', 'S05.9', 'S06.9X', 'S06.9X0', 'S09.92X', 'S11.90X', 'S19.9X', 'S27.899', 'S31.809', 'S32.019', 'S32.50', 'S35.229', 'S36.00X', 'S36.029', 'S36.09X', 'S39.94', 'S39.94X', 'S42.402', 'S42.409', 'S42.90X', 'S43.40', 'S52.002', 'S52.102', 'S61.209', 'S71.101', 'S93.402', 'T14.8', 'T14.90', 'T20.00', 'T20.02X', 'T20.04X', 'T24.011', 'T31.2', 'T56.0', 'T74.2', 'T79.7XX', 'T81.30', 'T81.49X', 'T82.01X', 'T82.7XX', 'T82.868', 'T85.41X', 'T86.11', 'T86.822', 'W34.00', 'W34.00X', 'W55.22X', 'Z16.35', 'Z20.818', 'Z37.0', 'Z3A.24', 'Z3A.38', 'Z3A.39', 'Z51.5', 'Z53.29', 'Z53.31', 'Z68.1', 'Z68.26', 'Z68.4', 'Z68.41', 'Z68.42', 'Z68.45', 'Z74.01', 'Z75.1', 'Z76.82', 'Z79.01', 'Z79.02', 'Z79.1', 'Z79.4', 'Z79.52', 'Z79.82', 'Z79.83', 'Z79.84', 'Z79.890', 'Z80.0', 'Z80.3', 'Z82.41', 'Z83.3', 'Z85.3', 'Z86.11', 'Z86.718', 'Z86.73', 'Z87.440', 'Z87.442', 'Z87.81', 'Z87.891', 'Z88.0', 'Z88.1', 'Z88.2', 'Z88.8', 'Z90.3', 'Z90.710', 'Z90.721', 'Z90.79', 'Z90.81', 'Z91.041', 'Z92.0', 'Z92.21', 'Z92.3', 'Z93.0', 'Z94.0', 'Z95.1', 'Z95.2', 'Z97.4', 'Z98.84', 'Z99.2', 'Z99.3', 'Z99.81']\n",
      "Parent Accuracy: 60.00% | Child Accuracy: 72.73%\n",
      "Saving best model... 0.00779 -> 0.01002\n",
      "F1 Validation | Micro: 0.05675 | Macro: 0.01002 | Best: 0.01002 | Epochs without improvement: 4\n",
      "Nuevos umbrales: Parent=0.549, Child=0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 603/603 [01:16<00:00,  7.89it/s, loss=0.234, lr=2.99e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 0.3623 | LR: 2.99E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D49', 'D72', 'E11', 'F17', 'I10', 'I86', 'I96', 'K52', 'K59', 'K63', 'L53', 'L98', 'M25', 'M54', 'N13', 'N18', 'N28', 'N32', 'N39', 'N50', 'R10', 'R19', 'R20', 'R31', 'R50', 'R52', 'R53', 'R59', 'R60', 'R63', 'R69', 'Z90']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A04.5', 'A15.4', 'A15.9', 'A18.10', 'A18.12', 'A18.4', 'A23.9', 'A32.9', 'A40.3', 'A41.9', 'A53.9', 'A63.0', 'B02.29', 'B10.89', 'B18.2', 'B27.99', 'B45.9', 'B74.9', 'B95.4', 'B95.5', 'B95.61', 'B95.8', 'B96.1', 'B96.20', 'B96.3', 'B96.4', 'B96.5', 'B96.7', 'B99.9', 'C02.1', 'C04.9', 'C08.0', 'C15.9', 'C16.0', 'C16.9', 'C18.6', 'C18.9', 'C22.0', 'C34.90', 'C34.91', 'C40.20', 'C41.0', 'C44.49', 'C48.0', 'C48.2', 'C49.21', 'C49.5', 'C49.A2', 'C50.312', 'C50.519', 'C50.91', 'C50.919', 'C53.9', 'C56.2', 'C62.90', 'C62.91', 'C62.92', 'C63.10', 'C63.8', 'C64.1', 'C64.2', 'C64.9', 'C65.9', 'C67.7', 'C67.9', 'C68.0', 'C70.9', 'C74.90', 'C75.0', 'C77.3', 'C77.8', 'C77.9', 'C78.00', 'C78.1', 'C78.39', 'C78.5', 'C78.6', 'C78.7', 'C79.00', 'C79.02', 'C79.2', 'C79.49', 'C79.51', 'C79.52', 'C79.70', 'C79.71', 'C79.72', 'C79.82', 'C79.9', 'C80.0', 'C83.1', 'C83.39', 'C90.0', 'D09.0', 'D11.0', 'D12.1', 'D12.6', 'D16.5', 'D17.23', 'D18.1', 'D23.11', 'D24.1', 'D24.9', 'D29.1', 'D29.30', 'D29.31', 'D30.01', 'D30.02', 'D30.3', 'D32.9', 'D36.11', 'D37.030', 'D40.10', 'D40.11', 'D40.8', 'D41.00', 'D44.12', 'D44.6', 'D47.1', 'D49.0', 'D49.1', 'D49.2', 'D49.4', 'D49.511', 'D49.512', 'D49.59', 'D49.7', 'D49.89', 'D50.9', 'D61.818', 'D64.9', 'D68.51', 'D69.0', 'D69.41', 'D72.0', 'D72.1', 'D72.819', 'D72.822', 'D72.829', 'E03.9', 'E04.1', 'E04.2', 'E04.9', 'E05.80', 'E05.90', 'E10.9', 'E11.42', 'E11.9', 'E27.0', 'E27.9', 'E29.1', 'E66.3', 'E66.9', 'E72.01', 'E78.00', 'E78.5', 'E79.0', 'E80.7', 'E85.4', 'E85.9', 'E88.09', 'F02.80', 'F10.21', 'F17.200', 'F17.210', 'F17.290', 'F32.9', 'F41.8', 'F90.9', 'G06.2', 'G40.119', 'G44.209', 'G47.30', 'G50.0', 'G54.6', 'G58.9', 'G83.9', 'G90.2', 'G90.50', 'G90.511', 'H02.402', 'H02.841', 'H02.843', 'H02.849', 'H05.20', 'H05.231', 'H11.422', 'H17.9', 'H18.891', 'H20.9', 'H21.26', 'H21.309', 'H25.1', 'H33.10', 'H33.101', 'H33.102', 'H35.00', 'H35.61', 'H40.10', 'H40.11', 'H44.001', 'H49.22', 'H50.011', 'H50.012', 'H50.9', 'H53.2', 'H53.8', 'H54.0', 'H54.62', 'H54.7', 'H57.1', 'H57.10', 'H57.11', 'H57.12', 'I12.9', 'I21.19', 'I21.29', 'I21.3', 'I25.2', 'I25.9', 'I42.0', 'I47.1', 'I48.2', 'I48.91', 'I49.9', 'I50.9', 'I51.9', 'I63.519', 'I65.21', 'I67.1', 'I77.9', 'I78.1', 'I80.8', 'I82.3', 'I82.90', 'I83.90', 'I85.00', 'I86.1', 'I86.4', 'I87.1', 'I87.8', 'I88.1', 'I89.0', 'I89.8', 'J02.9', 'J32.0', 'J32.4', 'J32.9', 'J34.1', 'J38.1', 'J39.8', 'J43.9', 'J44.9', 'J45.909', 'J81.0', 'J84.01', 'J98.4', 'J98.51', 'K00.0', 'K00.1', 'K01.0', 'K02.9', 'K04.7', 'K05.10', 'K06.2', 'K06.8', 'K08.109', 'K08.89', 'K08.9', 'K09.0', 'K11.1', 'K11.6', 'K11.9', 'K12.0', 'K12.1', 'K12.2', 'K13.0', 'K13.21', 'K13.70', 'K13.79', 'K14.9', 'K22.2', 'K31.1', 'K31.5', 'K31.7', 'K31.89', 'K35.2', 'K35.80', 'K38.8', 'K40.20', 'K40.30', 'K40.90', 'K44.9', 'K50.90', 'K51.90', 'K52.3', 'K52.81', 'K52.82', 'K52.9', 'K55.059', 'K55.1', 'K55.21', 'K55.9', 'K56.2', 'K56.69', 'K57.32', 'K57.90', 'K57.92', 'K59.00', 'K59.8', 'K59.9', 'K62.5', 'K62.6', 'K62.89', 'K63.1', 'K63.2', 'K63.5', 'K63.9', 'K65.1', 'K65.9', 'K66.0', 'K66.1', 'K68.12', 'K68.19', 'K68.9', 'K75.9', 'K76.7', 'K76.81', 'K76.89', 'K76.9', 'K80.20', 'K80.50', 'K80.51', 'K83.0', 'K83.3', 'K85.20', 'K90.0', 'K91.7', 'K92.1', 'K92.2', 'L02.01', 'L02.211', 'L02.91', 'L21.9', 'L30.9', 'L53.9', 'L60.9', 'L65.9', 'L74.0', 'L90.5', 'L92.9', 'L97.919', 'L98.0', 'L98.8', 'L98.9', 'M00.071', 'M00.9', 'M06.9', 'M08.90', 'M19.90', 'M25.40', 'M25.50', 'M25.551', 'M25.561', 'M25.562', 'M25.571', 'M25.9', 'M26.04', 'M26.09', 'M26.30', 'M26.32', 'M26.601', 'M26.609', 'M26.619', 'M26.9', 'M27.2', 'M32.9', 'M41.9', 'M45.9', 'M46.40', 'M46.90', 'M47.9', 'M54.2', 'M54.40', 'M54.41', 'M54.5', 'M54.9', 'M60.059', 'M62.89', 'M71.30', 'M79.1', 'M79.2', 'M79.604', 'M79.605', 'M79.621', 'M79.659', 'M79.7', 'M80.08X', 'M84.453', 'M85.50', 'M85.8', 'M86.9', 'M87.80', 'M89.072', 'M89.9', 'N13.30', 'N13.6', 'N13.9', 'N18.2', 'N18.5', 'N18.9', 'N20.0', 'N20.1', 'N20.9', 'N26.1', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.8', 'N30.90', 'N31.9', 'N32.0', 'N32.1', 'N32.89', 'N32.9', 'N36.0', 'N39.0', 'N40.0', 'N41.1', 'N43.3', 'N44.00', 'N44.2', 'N44.8', 'N45.1', 'N45.2', 'N45.3', 'N45.4', 'N48.21', 'N48.29', 'N48.30', 'N48.6', 'N48.81', 'N48.89', 'N48.9', 'N50.0', 'N50.3', 'N50.811', 'N50.812', 'N50.82', 'N50.89', 'N50.9', 'N52.9', 'N60.01', 'N60.02', 'N64.4', 'N64.89', 'N80.8', 'N80.9', 'N83.00', 'N85.8', 'N92.1', 'N97.9', 'O21.0', 'O42.92', 'Q12.4', 'Q27.30', 'Q27.9', 'Q28.2', 'Q35.3', 'Q37.9', 'Q42.9', 'Q44.6', 'Q52.0', 'Q53.10', 'Q55.29', 'Q61.3', 'Q63.1', 'Q64.4', 'Q67.0', 'Q70.9', 'Q85.00', 'Q87.2', 'Q89.2', 'R00.0', 'R06.00', 'R06.01', 'R06.1', 'R06.6', 'R06.82', 'R07.2', 'R07.89', 'R10.0', 'R10.10', 'R10.13', 'R10.2', 'R10.30', 'R10.31', 'R10.32', 'R10.811', 'R10.812', 'R10.813', 'R10.814', 'R10.84', 'R10.9', 'R11.0', 'R11.10', 'R11.12', 'R11.14', 'R11.2', 'R13.10', 'R14.0', 'R18.0', 'R19.0', 'R19.00', 'R19.01', 'R19.04', 'R19.06', 'R19.7', 'R19.8', 'R20.0', 'R20.1', 'R20.2', 'R20.8', 'R22.1', 'R22.2', 'R23.0', 'R23.8', 'R25.2', 'R29.898', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R33.9', 'R35.0', 'R36.1', 'R39.12', 'R39.14', 'R39.15', 'R39.198', 'R39.89', 'R39.9', 'R40.241', 'R40.4', 'R43.2', 'R47.89', 'R47.9', 'R50.82', 'R50.9', 'R53.1', 'R53.81', 'R57.1', 'R59.0', 'R59.9', 'R60.0', 'R60.9', 'R63.0', 'R63.4', 'R68.84', 'R68.89', 'R74.0', 'R91.1', 'R91.8', 'R97.1', 'R97.8', 'S01.80X', 'S02.0XX', 'S02.5XX', 'S05.9', 'S06.9X0', 'S32.019', 'S35.229', 'S36.00X', 'S36.029', 'S36.09X', 'S39.94X', 'S42.402', 'S52.002', 'S52.102', 'S61.209', 'S93.402', 'T14.8', 'T14.90', 'T20.02X', 'T20.04X', 'T81.30', 'T81.49X', 'T85.41X', 'T86.11', 'T86.822', 'Z20.818', 'Z37.0', 'Z3A.39', 'Z51.5', 'Z53.29', 'Z53.31', 'Z68.26', 'Z74.01', 'Z79.02', 'Z79.1', 'Z79.4', 'Z79.84', 'Z79.890', 'Z80.3', 'Z86.718', 'Z87.440', 'Z87.891', 'Z88.1', 'Z90.710', 'Z90.721', 'Z90.79', 'Z90.81', 'Z92.21', 'Z92.3', 'Z94.0', 'Z98.84', 'Z99.2', 'Z99.3']\n",
      "Parent Accuracy: 50.00% | Child Accuracy: 54.55%\n",
      "Saving best model... 0.01002 -> 0.01281\n",
      "F1 Validation | Micro: 0.07997 | Macro: 0.01281 | Best: 0.01281 | Epochs without improvement: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 603/603 [01:17<00:00,  7.78it/s, loss=0.271, lr=2.98e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 0.2988 | LR: 2.98E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D49', 'D72', 'E03', 'E11', 'F17', 'I10', 'I86', 'I96', 'K31', 'K52', 'K55', 'K59', 'K63', 'L53', 'L98', 'M54', 'N13', 'N18', 'N28', 'N32', 'R10', 'R19', 'R20', 'R30', 'R31', 'R50', 'R52', 'R59', 'R60', 'R63', 'R69', 'Z90']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A04.5', 'A15.9', 'A18.10', 'A18.12', 'A40.3', 'A41.9', 'B02.29', 'B45.9', 'B95.4', 'B95.5', 'B95.61', 'B95.62', 'B96.1', 'B96.20', 'B96.3', 'B96.4', 'B96.5', 'B96.7', 'B99.9', 'C02.1', 'C04.9', 'C08.0', 'C16.9', 'C18.6', 'C34.91', 'C40.20', 'C41.0', 'C44.49', 'C48.0', 'C48.2', 'C50.312', 'C50.519', 'C50.91', 'C50.919', 'C53.9', 'C62.90', 'C62.91', 'C62.92', 'C63.10', 'C64.1', 'C64.2', 'C64.9', 'C67.7', 'C67.9', 'C70.9', 'C74.90', 'C75.0', 'C77.3', 'C77.8', 'C77.9', 'C78.00', 'C78.1', 'C78.39', 'C78.5', 'C78.6', 'C78.7', 'C79.02', 'C79.2', 'C79.49', 'C79.51', 'C79.52', 'C79.70', 'C79.71', 'C79.9', 'C80.0', 'C83.1', 'D09.0', 'D11.0', 'D12.1', 'D12.6', 'D16.5', 'D17.23', 'D23.11', 'D24.1', 'D29.30', 'D30.01', 'D30.02', 'D30.3', 'D32.9', 'D36.11', 'D37.030', 'D40.10', 'D40.11', 'D44.6', 'D47.1', 'D49.0', 'D49.1', 'D49.2', 'D49.4', 'D49.511', 'D49.59', 'D49.7', 'D49.89', 'D50.9', 'D69.0', 'D72.0', 'D72.1', 'D72.829', 'E03.9', 'E04.1', 'E04.2', 'E05.90', 'E11.42', 'E11.9', 'E27.0', 'E29.1', 'E66.01', 'E66.3', 'E66.9', 'E72.01', 'E78.00', 'E78.5', 'E79.0', 'E80.7', 'E85.4', 'E85.9', 'F10.21', 'F17.200', 'F17.210', 'F17.290', 'F32.9', 'F41.8', 'F90.9', 'G06.2', 'G40.119', 'G54.6', 'G58.9', 'G83.9', 'G90.2', 'G90.50', 'G90.511', 'H02.402', 'H02.841', 'H02.849', 'H05.20', 'H20.9', 'H33.10', 'H33.102', 'H35.00', 'H35.61', 'H40.10', 'H50.011', 'H50.012', 'H53.2', 'H53.8', 'H54.0', 'H57.10', 'H57.12', 'I12.9', 'I21.19', 'I21.29', 'I25.9', 'I42.0', 'I47.1', 'I48.2', 'I48.91', 'I50.9', 'I67.1', 'I77.0', 'I77.9', 'I78.1', 'I80.8', 'I82.3', 'I82.90', 'I85.00', 'I86.1', 'I86.4', 'J34.1', 'J38.1', 'J39.8', 'J45.909', 'J81.0', 'J94.8', 'J98.4', 'J98.51', 'K00.0', 'K01.0', 'K02.9', 'K06.2', 'K06.8', 'K08.109', 'K08.89', 'K08.9', 'K11.1', 'K11.6', 'K11.9', 'K12.1', 'K12.2', 'K13.0', 'K13.70', 'K13.79', 'K22.2', 'K31.1', 'K31.5', 'K31.7', 'K31.89', 'K35.2', 'K35.80', 'K38.8', 'K40.20', 'K40.90', 'K44.9', 'K51.00', 'K51.90', 'K52.3', 'K52.81', 'K52.9', 'K55.059', 'K55.1', 'K55.21', 'K55.9', 'K56.69', 'K57.32', 'K57.90', 'K57.92', 'K59.00', 'K59.8', 'K59.9', 'K62.5', 'K62.6', 'K62.89', 'K63.1', 'K63.5', 'K63.9', 'K65.1', 'K65.9', 'K66.0', 'K68.19', 'K75.9', 'K76.7', 'K76.81', 'K76.89', 'K80.50', 'K80.51', 'K83.0', 'K83.3', 'K85.20', 'K90.0', 'K91.7', 'K92.1', 'K92.2', 'L02.211', 'L02.91', 'L21.9', 'L53.9', 'L90.5', 'L92.9', 'L98.0', 'L98.8', 'L98.9', 'M06.9', 'M19.90', 'M25.40', 'M25.50', 'M25.551', 'M25.561', 'M25.562', 'M26.04', 'M26.30', 'M26.32', 'M26.601', 'M26.609', 'M32.9', 'M41.9', 'M45.9', 'M46.90', 'M54.2', 'M54.40', 'M54.41', 'M54.5', 'M54.9', 'M62.89', 'M79.1', 'M79.2', 'M79.605', 'M79.621', 'M85.50', 'M85.8', 'M89.072', 'M89.9', 'N13.30', 'N13.6', 'N13.9', 'N18.2', 'N18.5', 'N18.9', 'N20.0', 'N20.1', 'N20.9', 'N26.1', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.90', 'N31.9', 'N32.0', 'N32.1', 'N32.89', 'N32.9', 'N36.0', 'N39.0', 'N40.0', 'N41.1', 'N43.3', 'N44.00', 'N44.2', 'N44.8', 'N45.2', 'N45.3', 'N48.21', 'N48.29', 'N48.30', 'N48.6', 'N48.81', 'N48.89', 'N48.9', 'N50.3', 'N50.811', 'N50.812', 'N50.82', 'N50.89', 'N50.9', 'N52.9', 'N60.01', 'N60.02', 'N64.4', 'N64.89', 'N80.9', 'N83.00', 'N85.8', 'N92.1', 'N97.9', 'O21.0', 'O42.92', 'Q12.4', 'Q27.30', 'Q27.9', 'Q44.6', 'Q53.10', 'Q61.3', 'Q64.4', 'Q85.00', 'Q87.2', 'Q89.2', 'R00.0', 'R06.01', 'R06.1', 'R06.6', 'R06.82', 'R07.89', 'R10.0', 'R10.10', 'R10.13', 'R10.2', 'R10.30', 'R10.31', 'R10.32', 'R10.811', 'R10.813', 'R10.814', 'R10.84', 'R10.9', 'R11.0', 'R11.10', 'R11.12', 'R11.14', 'R11.2', 'R13.10', 'R14.0', 'R18.0', 'R18.8', 'R19.0', 'R19.00', 'R19.01', 'R19.04', 'R19.06', 'R19.7', 'R19.8', 'R20.0', 'R20.1', 'R20.2', 'R20.8', 'R22.1', 'R23.8', 'R25.2', 'R29.898', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R33.9', 'R35.0', 'R39.12', 'R39.14', 'R39.15', 'R39.198', 'R39.89', 'R39.9', 'R40.241', 'R40.4', 'R43.2', 'R47.89', 'R47.9', 'R50.82', 'R50.9', 'R53.81', 'R57.1', 'R59.0', 'R59.9', 'R60.0', 'R60.9', 'R63.0', 'R63.4', 'R68.84', 'R68.89', 'R74.0', 'R91.1', 'R97.1', 'S02.5XX', 'S36.029', 'S36.09X', 'S39.94X', 'T20.04X', 'T81.30', 'T82.7XX', 'T85.41X', 'Z3A.39', 'Z51.5', 'Z53.29', 'Z53.31', 'Z68.26', 'Z79.1', 'Z79.4', 'Z79.84', 'Z79.890', 'Z80.3', 'Z87.440', 'Z87.891', 'Z88.1', 'Z90.710', 'Z90.721', 'Z90.79', 'Z90.81', 'Z92.21', 'Z92.3', 'Z94.0', 'Z99.2', 'Z99.3']\n",
      "Parent Accuracy: 40.00% | Child Accuracy: 54.55%\n",
      "F1 Validation | Micro: 0.08206 | Macro: 0.01311 | Best: 0.01281 | Epochs without improvement: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 603/603 [01:17<00:00,  7.78it/s, loss=0.0866, lr=2.98e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 0.2240 | LR: 2.98E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D49', 'D72', 'E03', 'E11', 'F17', 'I10', 'I86', 'I96', 'K52', 'K59', 'K63', 'L53', 'L98', 'M25', 'M54', 'N18', 'N28', 'N32', 'N39', 'Q64', 'R10', 'R19', 'R30', 'R31', 'R50', 'R52', 'R59', 'R60', 'R63', 'R69']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A04.5', 'A15.9', 'A18.10', 'A18.12', 'A41.9', 'B95.4', 'B95.5', 'B95.61', 'B96.20', 'B96.3', 'B96.5', 'B96.7', 'B99.9', 'C02.1', 'C16.9', 'C18.6', 'C48.0', 'C48.2', 'C50.312', 'C50.919', 'C53.9', 'C62.90', 'C62.91', 'C62.92', 'C63.10', 'C64.1', 'C64.2', 'C64.9', 'C67.7', 'C67.9', 'C78.00', 'C78.1', 'C78.5', 'C78.6', 'C78.7', 'C79.02', 'C79.51', 'C79.52', 'C79.70', 'C80.0', 'D11.0', 'D12.1', 'D16.5', 'D23.11', 'D30.01', 'D30.3', 'D37.030', 'D40.10', 'D49.0', 'D49.2', 'D49.4', 'D49.511', 'D49.59', 'D49.7', 'D49.89', 'D50.9', 'D69.0', 'D72.0', 'D72.829', 'E03.9', 'E04.1', 'E11.42', 'E11.9', 'E66.3', 'E78.00', 'E78.5', 'E79.0', 'E80.7', 'E85.4', 'E85.9', 'F10.21', 'F17.200', 'F17.210', 'F17.290', 'G06.2', 'G40.119', 'G58.9', 'H02.402', 'H02.849', 'H20.9', 'H50.012', 'H57.10', 'H57.12', 'I12.9', 'I21.29', 'I42.0', 'I47.1', 'I48.2', 'I48.91', 'I67.1', 'I77.9', 'I78.1', 'I82.3', 'I82.90', 'I85.00', 'I86.1', 'I86.4', 'J34.1', 'J39.8', 'J98.4', 'J98.51', 'K00.0', 'K01.0', 'K02.9', 'K08.109', 'K08.89', 'K11.1', 'K11.9', 'K12.1', 'K12.2', 'K22.2', 'K31.1', 'K31.5', 'K31.89', 'K35.2', 'K35.80', 'K38.8', 'K40.20', 'K40.90', 'K44.9', 'K52.3', 'K52.9', 'K55.1', 'K56.69', 'K57.32', 'K57.90', 'K57.92', 'K59.00', 'K59.39', 'K59.8', 'K59.9', 'K62.5', 'K62.6', 'K62.89', 'K63.1', 'K65.9', 'K75.9', 'K76.7', 'K76.81', 'K76.89', 'K80.50', 'K83.0', 'K83.3', 'K85.20', 'K91.7', 'L02.211', 'L02.91', 'L53.9', 'L92.9', 'L98.8', 'L98.9', 'M06.9', 'M19.90', 'M25.40', 'M25.50', 'M25.551', 'M25.561', 'M26.04', 'M26.601', 'M26.609', 'M32.9', 'M41.9', 'M45.9', 'M46.90', 'M54.2', 'M54.40', 'M54.41', 'M54.5', 'M54.9', 'M79.605', 'M79.621', 'M85.50', 'M85.8', 'M89.9', 'N13.30', 'N13.6', 'N13.9', 'N18.2', 'N18.5', 'N18.9', 'N20.0', 'N20.1', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.90', 'N31.9', 'N32.0', 'N32.1', 'N32.89', 'N32.9', 'N36.0', 'N39.0', 'N40.0', 'N41.1', 'N43.3', 'N44.00', 'N44.8', 'N45.2', 'N45.3', 'N48.29', 'N48.6', 'N48.81', 'N48.89', 'N48.9', 'N50.811', 'N50.812', 'N50.82', 'N50.89', 'N50.9', 'N60.01', 'N80.9', 'N92.1', 'N97.9', 'Q27.30', 'Q44.6', 'Q53.10', 'Q61.3', 'Q64.4', 'Q89.2', 'R06.01', 'R06.82', 'R07.89', 'R10.0', 'R10.10', 'R10.13', 'R10.2', 'R10.30', 'R10.31', 'R10.32', 'R10.811', 'R10.813', 'R10.814', 'R10.84', 'R10.9', 'R11.0', 'R11.10', 'R11.12', 'R11.14', 'R13.10', 'R14.0', 'R19.0', 'R19.00', 'R19.04', 'R19.06', 'R19.7', 'R19.8', 'R20.0', 'R20.1', 'R20.2', 'R29.898', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R33.9', 'R35.0', 'R39.12', 'R39.14', 'R39.15', 'R39.198', 'R39.89', 'R39.9', 'R40.4', 'R50.82', 'R50.9', 'R53.81', 'R59.0', 'R59.9', 'R60.0', 'R60.9', 'R63.0', 'R63.4', 'R68.84', 'R74.0', 'R91.1', 'S02.5XX', 'S36.029', 'T81.49X', 'Z3A.39', 'Z51.5', 'Z53.31', 'Z79.1', 'Z79.4', 'Z79.84', 'Z87.440', 'Z87.891', 'Z90.710', 'Z90.79', 'Z92.21', 'Z92.3', 'Z94.0', 'Z99.2', 'Z99.3']\n",
      "Parent Accuracy: 40.00% | Child Accuracy: 54.55%\n",
      "Saving best model... 0.01281 -> 0.01551\n",
      "F1 Validation | Micro: 0.09957 | Macro: 0.01551 | Best: 0.01551 | Epochs without improvement: 5\n",
      "Nuevos umbrales: Parent=0.405, Child=0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 603/603 [01:17<00:00,  7.79it/s, loss=0.161, lr=2.98e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 0.1430 | LR: 2.98E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D49', 'D72', 'E11', 'F17', 'I10', 'I86', 'I96', 'K59', 'L53', 'L98', 'M54', 'N18', 'N28', 'N32', 'R10', 'R19', 'R31', 'R50', 'R52', 'R59', 'R60', 'R63', 'R69']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A04.5', 'A15.9', 'A18.10', 'A18.12', 'A41.9', 'B95.4', 'B95.5', 'B95.61', 'B96.20', 'B96.3', 'B96.5', 'B99.9', 'C02.1', 'C41.1', 'C48.0', 'C48.2', 'C50.312', 'C50.919', 'C62.90', 'C62.91', 'C62.92', 'C63.10', 'C64.2', 'C64.9', 'C67.7', 'C67.9', 'C78.00', 'C78.6', 'C78.7', 'C79.51', 'C79.52', 'C79.70', 'D11.0', 'D16.5', 'D23.11', 'D30.01', 'D30.3', 'D37.030', 'D49.0', 'D49.2', 'D49.4', 'D49.511', 'D49.59', 'D49.89', 'D69.0', 'D72.0', 'D72.829', 'E03.9', 'E11.42', 'E11.9', 'E66.3', 'E78.00', 'E78.5', 'E80.7', 'E85.4', 'E85.9', 'F10.21', 'F17.200', 'F17.210', 'F17.290', 'G40.119', 'G58.9', 'H35.61', 'I12.9', 'I42.0', 'I47.1', 'I48.2', 'I80.8', 'I82.90', 'I85.00', 'I86.1', 'I86.4', 'J34.1', 'J39.8', 'J98.4', 'J98.51', 'K00.0', 'K01.0', 'K02.9', 'K08.109', 'K08.89', 'K11.1', 'K11.6', 'K11.9', 'K12.1', 'K12.2', 'K22.2', 'K31.1', 'K31.5', 'K31.89', 'K35.80', 'K38.8', 'K40.20', 'K40.90', 'K44.9', 'K52.3', 'K52.9', 'K55.059', 'K55.1', 'K57.32', 'K59.00', 'K59.39', 'K59.8', 'K62.6', 'K63.1', 'K65.9', 'K75.9', 'K76.7', 'K76.81', 'K76.89', 'K83.0', 'K83.3', 'K85.20', 'L02.211', 'L02.91', 'L53.9', 'L92.9', 'L98.0', 'L98.8', 'L98.9', 'M06.9', 'M19.90', 'M25.40', 'M25.50', 'M25.551', 'M26.32', 'M26.601', 'M26.609', 'M32.9', 'M45.9', 'M46.90', 'M54.40', 'M54.41', 'M54.5', 'M85.50', 'M85.8', 'M89.9', 'N13.30', 'N13.6', 'N13.9', 'N18.2', 'N18.5', 'N18.9', 'N20.0', 'N20.1', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.90', 'N31.9', 'N32.0', 'N32.89', 'N32.9', 'N39.0', 'N40.0', 'N43.3', 'N44.00', 'N44.8', 'N45.2', 'N45.3', 'N48.29', 'N48.30', 'N48.6', 'N48.81', 'N48.89', 'N50.812', 'N50.82', 'N50.89', 'N50.9', 'N60.01', 'N60.02', 'N80.9', 'N92.1', 'Q44.6', 'Q53.10', 'Q61.3', 'Q64.4', 'Q89.2', 'R06.01', 'R06.82', 'R10.0', 'R10.10', 'R10.13', 'R10.30', 'R10.31', 'R10.32', 'R10.814', 'R10.84', 'R10.9', 'R11.0', 'R11.10', 'R11.12', 'R11.14', 'R13.10', 'R19.0', 'R19.00', 'R19.04', 'R19.7', 'R20.0', 'R20.2', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R33.9', 'R35.0', 'R39.15', 'R39.198', 'R39.89', 'R40.4', 'R47.89', 'R50.82', 'R50.9', 'R53.81', 'R59.0', 'R59.9', 'R60.0', 'R60.9', 'R63.0', 'R63.4', 'R74.0', 'R91.1', 'S02.5XX', 'Z3A.39', 'Z53.29', 'Z53.31', 'Z79.1', 'Z79.4', 'Z79.84', 'Z87.440', 'Z87.891', 'Z90.710', 'Z90.79', 'Z92.21', 'Z99.2', 'Z99.3']\n",
      "Parent Accuracy: 30.00% | Child Accuracy: 54.55%\n",
      "F1 Validation | Micro: 0.11020 | Macro: 0.01598 | Best: 0.01551 | Epochs without improvement: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 603/603 [01:17<00:00,  7.77it/s, loss=0.149, lr=2.98e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 0.1363 | LR: 2.98E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D49', 'D72', 'E03', 'E11', 'F17', 'I10', 'I86', 'I96', 'K31', 'K52', 'K59', 'K63', 'K75', 'L53', 'L98', 'M25', 'M32', 'M54', 'N13', 'N18', 'N28', 'N32', 'N39', 'R10', 'R11', 'R19', 'R31', 'R35', 'R50', 'R52', 'R53', 'R59', 'R60', 'R63', 'R69', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A04.5', 'A15.9', 'A18.10', 'A41.9', 'B95.4', 'B95.5', 'B95.61', 'B96.20', 'B96.3', 'B96.5', 'B99.9', 'C48.2', 'C62.92', 'C63.10', 'C64.9', 'C67.7', 'C67.9', 'C78.00', 'C78.6', 'C79.51', 'C79.70', 'C80.0', 'D16.5', 'D23.11', 'D30.01', 'D30.3', 'D37.030', 'D49.0', 'D49.4', 'D49.59', 'D49.89', 'D50.9', 'D72.0', 'D72.829', 'E03.9', 'E11.42', 'E11.9', 'E66.3', 'E78.00', 'E78.5', 'E79.0', 'E80.7', 'E85.9', 'F10.21', 'F17.200', 'F17.210', 'F17.290', 'G40.119', 'I12.9', 'I48.2', 'I80.8', 'I82.90', 'I85.00', 'I86.1', 'I86.4', 'J39.8', 'J98.4', 'J98.51', 'J98.8', 'K08.109', 'K11.1', 'K11.9', 'K12.1', 'K12.2', 'K21.9', 'K22.2', 'K31.1', 'K31.5', 'K31.89', 'K35.80', 'K38.8', 'K40.20', 'K40.90', 'K44.9', 'K52.3', 'K52.9', 'K55.1', 'K55.9', 'K57.32', 'K57.90', 'K57.92', 'K59.00', 'K59.39', 'K59.8', 'K62.5', 'K62.6', 'K62.89', 'K63.1', 'K65.9', 'K75.9', 'K76.7', 'K76.81', 'K76.89', 'K83.3', 'K85.20', 'K92.1', 'L53.9', 'L92.9', 'L98.8', 'L98.9', 'M06.9', 'M19.90', 'M25.40', 'M25.50', 'M25.551', 'M25.561', 'M26.04', 'M26.601', 'M26.609', 'M32.9', 'M41.9', 'M45.9', 'M46.90', 'M54.2', 'M54.40', 'M54.41', 'M54.5', 'M54.9', 'M79.605', 'M85.8', 'M89.9', 'N13.30', 'N13.6', 'N13.9', 'N18.2', 'N18.5', 'N18.9', 'N20.0', 'N20.1', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.90', 'N31.9', 'N32.0', 'N32.89', 'N32.9', 'N36.0', 'N39.0', 'N40.0', 'N45.3', 'N48.30', 'N48.6', 'N48.81', 'N48.89', 'N50.89', 'N60.01', 'N60.02', 'N92.1', 'Q44.6', 'Q53.10', 'Q61.3', 'Q64.4', 'Q89.2', 'R06.00', 'R06.01', 'R06.82', 'R07.89', 'R10.0', 'R10.10', 'R10.13', 'R10.30', 'R10.31', 'R10.32', 'R10.814', 'R10.84', 'R10.9', 'R11.0', 'R11.10', 'R11.12', 'R11.14', 'R14.0', 'R18.8', 'R19.00', 'R19.04', 'R19.7', 'R20.0', 'R20.2', 'R25.2', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R33.9', 'R35.0', 'R39.15', 'R39.89', 'R40.4', 'R47.89', 'R50.82', 'R50.9', 'R53.1', 'R53.81', 'R59.0', 'R59.9', 'R60.0', 'R60.9', 'R63.0', 'R63.4', 'R91.1', 'S02.5XX', 'Z3A.39', 'Z51.5', 'Z53.31', 'Z79.1', 'Z79.4', 'Z87.440', 'Z87.891', 'Z90.710', 'Z94.0', 'Z99.2', 'Z99.3']\n",
      "Parent Accuracy: 50.00% | Child Accuracy: 54.55%\n",
      "F1 Validation | Micro: 0.09864 | Macro: 0.01454 | Best: 0.01551 | Epochs without improvement: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 603/603 [01:17<00:00,  7.76it/s, loss=0.0831, lr=2.97e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Loss: 0.1085 | LR: 2.97E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D49', 'E11', 'I10', 'I86', 'I96', 'L53', 'L98', 'N18', 'N28', 'R10', 'R31', 'R50', 'R52', 'R60', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A41.9', 'B95.4', 'B95.5', 'B95.61', 'B96.20', 'B96.5', 'B99.9', 'C48.2', 'C64.9', 'C67.7', 'C67.9', 'C78.6', 'D11.0', 'D16.5', 'D23.11', 'D30.01', 'D30.3', 'D49.0', 'D49.2', 'D49.4', 'D49.59', 'D72.0', 'D72.829', 'E03.9', 'E11.42', 'E11.9', 'E66.3', 'E78.00', 'E78.5', 'F17.210', 'F17.290', 'I12.9', 'I80.8', 'I82.90', 'I86.1', 'I86.4', 'J98.4', 'J98.51', 'K08.109', 'K11.1', 'K11.9', 'K12.1', 'K12.2', 'K31.1', 'K31.89', 'K40.90', 'K44.9', 'K52.9', 'K57.32', 'K59.8', 'K76.81', 'K83.3', 'K85.20', 'L53.9', 'L92.9', 'L98.8', 'L98.9', 'M25.40', 'M25.50', 'M25.551', 'M26.601', 'M26.609', 'M32.9', 'M45.9', 'M46.90', 'M54.40', 'M85.8', 'M89.9', 'N13.9', 'N18.2', 'N18.5', 'N18.9', 'N20.0', 'N20.1', 'N28.1', 'N28.82', 'N28.89', 'N30.90', 'N32.0', 'N32.89', 'N32.9', 'N39.0', 'N45.3', 'N48.6', 'N48.81', 'N48.89', 'N60.01', 'Q44.6', 'Q53.10', 'Q61.3', 'Q64.4', 'Q89.2', 'R06.82', 'R10.0', 'R10.10', 'R10.31', 'R10.32', 'R10.814', 'R10.84', 'R10.9', 'R19.00', 'R30.0', 'R31.0', 'R31.9', 'R35.0', 'R39.15', 'R50.82', 'R50.9', 'R53.81', 'R60.0', 'R60.9', 'R63.4', 'S02.5XX', 'Z3A.39', 'Z53.31', 'Z87.440', 'Z87.891', 'Z90.710']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 36.36%\n",
      "Saving best model... 0.01551 -> 0.01674\n",
      "F1 Validation | Micro: 0.11796 | Macro: 0.01674 | Best: 0.01674 | Epochs without improvement: 7\n",
      "Nuevos umbrales: Parent=0.327, Child=0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 603/603 [01:16<00:00,  7.89it/s, loss=0.0605, lr=2.97e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Loss: 0.0703 | LR: 2.97E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D49', 'I10', 'I86', 'L53', 'N18', 'N28', 'R10', 'R31', 'R50', 'R52', 'R60']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A15.9', 'B95.5', 'B95.61', 'B96.20', 'B96.3', 'B96.5', 'B99.9', 'C48.2', 'C62.92', 'C63.10', 'C64.9', 'C67.7', 'C67.9', 'D16.5', 'D23.11', 'D30.01', 'D30.3', 'D49.0', 'D49.2', 'D49.4', 'D49.511', 'D49.59', 'D72.0', 'D72.829', 'E11.42', 'E11.9', 'E66.3', 'E78.00', 'E78.5', 'F17.210', 'F17.290', 'G40.119', 'I12.9', 'I86.1', 'J98.51', 'K08.109', 'K11.1', 'K11.9', 'K12.2', 'K31.1', 'K44.9', 'K52.9', 'K59.8', 'K76.81', 'K83.3', 'K85.20', 'L53.9', 'L92.9', 'L98.8', 'M25.40', 'M25.50', 'M25.551', 'M26.601', 'M26.609', 'M32.9', 'M89.9', 'N13.30', 'N18.5', 'N18.9', 'N20.0', 'N20.1', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N30.90', 'N32.0', 'N32.89', 'N32.9', 'N39.0', 'N45.3', 'N48.6', 'N48.81', 'N48.89', 'N50.89', 'N60.01', 'N60.02', 'Q53.10', 'Q61.3', 'Q64.4', 'R10.0', 'R10.10', 'R10.13', 'R10.31', 'R10.32', 'R10.814', 'R10.84', 'R10.9', 'R19.00', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R35.0', 'R39.15', 'R40.4', 'R50.9', 'R53.81', 'R59.0', 'R60.0', 'R60.9', 'R63.4', 'S02.5XX', 'Z3A.39', 'Z53.31', 'Z87.440', 'Z87.891', 'Z90.710']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 45.45%\n",
      "Saving best model... 0.01674 -> 0.01798\n",
      "F1 Validation | Micro: 0.13478 | Macro: 0.01798 | Best: 0.01798 | Epochs without improvement: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 603/603 [01:18<00:00,  7.70it/s, loss=0.124, lr=2.97e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Loss: 0.0710 | LR: 2.97E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D49', 'D72', 'E11', 'I10', 'I86', 'I96', 'K52', 'K59', 'L53', 'L98', 'N18', 'N28', 'R10', 'R50', 'R52', 'R60', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A15.9', 'A41.9', 'B95.5', 'B95.61', 'B96.20', 'B96.3', 'B96.5', 'B99.9', 'C48.2', 'C67.9', 'D23.11', 'D30.01', 'D49.0', 'D49.4', 'D49.59', 'D72.0', 'D72.829', 'E11.9', 'E66.3', 'E78.00', 'E78.5', 'F17.210', 'F17.290', 'I12.9', 'I82.90', 'I86.4', 'J98.51', 'K08.109', 'K11.1', 'K11.9', 'K12.1', 'K31.1', 'K31.89', 'K40.90', 'K52.9', 'K57.32', 'K59.00', 'K59.8', 'K75.9', 'K76.81', 'K83.3', 'K85.20', 'L53.9', 'L92.9', 'L98.8', 'L98.9', 'M19.90', 'M25.40', 'M25.50', 'M25.551', 'M26.601', 'M26.609', 'M32.9', 'M85.8', 'M89.9', 'N18.2', 'N18.5', 'N18.9', 'N20.0', 'N20.1', 'N28.1', 'N28.82', 'N30.90', 'N32.0', 'N32.89', 'N32.9', 'N39.0', 'N45.3', 'N48.6', 'N48.81', 'N48.89', 'N60.01', 'Q53.10', 'Q61.3', 'Q64.4', 'R10.0', 'R10.10', 'R10.13', 'R10.814', 'R10.84', 'R10.9', 'R30.0', 'R31.0', 'R31.9', 'R35.0', 'R39.15', 'R40.4', 'R50.9', 'R53.81', 'R59.0', 'R60.0', 'R60.9', 'R63.4', 'Z53.31', 'Z87.891', 'Z90.710']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 36.36%\n",
      "F1 Validation | Micro: 0.12172 | Macro: 0.01718 | Best: 0.01798 | Epochs without improvement: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 603/603 [01:18<00:00,  7.71it/s, loss=0.0806, lr=2.96e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Loss: 0.0583 | LR: 2.96E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B19', 'B95', 'B96', 'B99', 'D72', 'E11', 'I10', 'I86', 'K59', 'L53', 'N18', 'N28', 'R10', 'R30', 'R31', 'R50', 'R52', 'R60', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A41.9', 'B95.4', 'B95.5', 'B95.61', 'B96.20', 'B96.5', 'B99.9', 'C48.2', 'C64.9', 'C67.7', 'C67.9', 'C78.6', 'C79.51', 'D49.0', 'D49.4', 'D72.0', 'D72.829', 'E11.9', 'E78.5', 'F10.21', 'F17.210', 'F17.290', 'I82.90', 'I85.00', 'I86.4', 'J98.51', 'K31.1', 'K31.89', 'K40.90', 'K52.9', 'K59.00', 'K59.8', 'K75.9', 'K76.7', 'K76.81', 'K83.3', 'K85.20', 'L53.9', 'L92.9', 'L98.9', 'M25.40', 'M25.50', 'M26.601', 'M26.609', 'M32.9', 'M89.9', 'N18.5', 'N18.9', 'N20.1', 'N28.1', 'N28.82', 'N28.9', 'N32.0', 'N32.89', 'N32.9', 'N39.0', 'N45.3', 'N48.6', 'N48.81', 'N48.89', 'N60.01', 'N92.1', 'Q53.10', 'Q61.3', 'Q64.4', 'R06.82', 'R10.10', 'R10.13', 'R10.31', 'R10.84', 'R10.9', 'R11.10', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R35.0', 'R39.15', 'R40.4', 'R50.9', 'R53.81', 'R60.0', 'R60.9', 'R63.0', 'R63.4', 'Z53.31', 'Z87.440', 'Z87.891', 'Z90.710']\n",
      "Parent Accuracy: 30.00% | Child Accuracy: 36.36%\n",
      "F1 Validation | Micro: 0.12803 | Macro: 0.01815 | Best: 0.01798 | Epochs without improvement: 9\n",
      "Nuevos umbrales: Parent=0.297, Child=0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 603/603 [01:17<00:00,  7.81it/s, loss=0.0331, lr=2.96e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Loss: 0.0372 | LR: 2.96E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D49', 'I10', 'I86', 'L53', 'N18', 'N28', 'R50', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'B96.5', 'B99.9', 'C67.9', 'C79.51', 'D49.0', 'D49.4', 'D49.59', 'D72.0', 'D72.829', 'E11.9', 'E78.5', 'F17.210', 'F17.290', 'J98.51', 'K31.1', 'K31.89', 'K59.8', 'K85.20', 'L53.9', 'M25.40', 'M25.50', 'M26.601', 'M26.609', 'N18.5', 'N18.9', 'N20.1', 'N28.1', 'N28.82', 'N28.89', 'N28.9', 'N32.0', 'N32.89', 'N32.9', 'N39.0', 'N48.89', 'N60.01', 'Q64.4', 'R10.13', 'R10.84', 'R30.0', 'R31.0', 'R31.9', 'R40.4', 'R50.9', 'R60.0', 'R63.4', 'Z53.31', 'Z87.891', 'Z90.710']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 36.36%\n",
      "Saving best model... 0.01798 -> 0.01859\n",
      "F1 Validation | Micro: 0.15287 | Macro: 0.01859 | Best: 0.01859 | Epochs without improvement: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 603/603 [01:18<00:00,  7.73it/s, loss=0.0471, lr=2.96e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Loss: 0.0388 | LR: 2.96E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'I10', 'L53', 'N18', 'N28', 'R50', 'R52', 'R60']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.5', 'B95.61', 'B96.20', 'B96.5', 'B99.9', 'D49.0', 'D49.4', 'D72.0', 'D72.829', 'E11.9', 'E78.5', 'F17.210', 'F17.290', 'J98.51', 'K11.9', 'K12.1', 'K52.9', 'K59.8', 'K85.20', 'L53.9', 'L92.9', 'M25.40', 'M26.601', 'M26.609', 'M32.9', 'M89.9', 'N18.5', 'N18.9', 'N20.1', 'N28.1', 'N28.82', 'N39.0', 'N48.6', 'N48.81', 'N48.89', 'N60.01', 'Q53.10', 'Q64.4', 'R30.0', 'R31.9', 'R40.4', 'R50.9', 'R60.0', 'R60.9', 'Z53.31', 'Z87.891', 'Z90.710']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 18.18%\n",
      "Saving best model... 0.01859 -> 0.01942\n",
      "F1 Validation | Micro: 0.14526 | Macro: 0.01942 | Best: 0.01942 | Epochs without improvement: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 603/603 [01:17<00:00,  7.75it/s, loss=0.0436, lr=2.95e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Loss: 0.0322 | LR: 2.95E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D49', 'I10', 'I86', 'L53', 'N18', 'N28', 'R50', 'R52', 'R60']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'B96.5', 'B99.9', 'D49.0', 'D49.4', 'D72.0', 'D72.829', 'E11.9', 'E78.5', 'F17.210', 'F17.290', 'J98.51', 'K52.9', 'K59.8', 'K83.3', 'L53.9', 'M25.40', 'M26.601', 'M26.609', 'M32.9', 'M89.9', 'N18.5', 'N18.9', 'N20.1', 'N28.1', 'N28.82', 'N32.89', 'N32.9', 'N39.0', 'N48.89', 'Q53.10', 'Q64.4', 'R30.0', 'R31.0', 'R31.9', 'R50.9', 'R60.0', 'R60.9', 'Z53.31', 'Z87.891']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.15456 | Macro: 0.01881 | Best: 0.01942 | Epochs without improvement: 10\n",
      "Nuevos umbrales: Parent=0.254, Child=0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 603/603 [01:14<00:00,  8.09it/s, loss=0.0297, lr=2.95e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Loss: 0.0199 | LR: 2.95E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'I10', 'I86', 'L53', 'N28', 'R50', 'R52']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'B99.9', 'D49.0', 'D49.4', 'D72.0', 'D72.829', 'E78.5', 'F17.210', 'F17.290', 'J98.51', 'K59.00', 'K59.8', 'K85.20', 'L53.9', 'M26.601', 'M26.609', 'M32.9', 'N18.5', 'N18.9', 'N28.1', 'N28.82', 'N32.9', 'N39.0', 'Q64.4', 'R30.0', 'R31.0', 'R31.9', 'R50.9', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 27.27%\n",
      "F1 Validation | Micro: 0.16789 | Macro: 0.01894 | Best: 0.01942 | Epochs without improvement: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 603/603 [01:16<00:00,  7.93it/s, loss=0.0225, lr=2.95e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Loss: 0.0218 | LR: 2.95E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'I10', 'I86', 'L53', 'N18', 'N28', 'N32', 'R30', 'R31', 'R52']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'B96.5', 'B99.9', 'C67.9', 'D49.0', 'D49.4', 'D72.0', 'E11.9', 'E78.5', 'F17.290', 'J98.51', 'K59.8', 'K85.20', 'L53.9', 'L92.9', 'M19.90', 'M25.40', 'M26.609', 'N18.5', 'N18.9', 'N20.1', 'N28.1', 'N28.82', 'N28.9', 'N32.89', 'N32.9', 'N39.0', 'Q53.10', 'Q61.3', 'Q64.4', 'R30.0', 'R31.0', 'R31.9', 'R50.9', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 27.27%\n",
      "F1 Validation | Micro: 0.15850 | Macro: 0.01795 | Best: 0.01942 | Epochs without improvement: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 603/603 [01:13<00:00,  8.16it/s, loss=0.0104, lr=2.95e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Loss: 0.0190 | LR: 2.95E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'I10', 'I86', 'K59', 'L53', 'N18', 'N28', 'N32', 'Q64', 'R50', 'R52', 'R60', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['A15.9', 'B95.61', 'B96.20', 'B96.5', 'B99.9', 'D49.4', 'D72.0', 'D72.829', 'E11.9', 'E78.5', 'F17.290', 'J98.51', 'K40.90', 'K44.9', 'K59.00', 'K59.8', 'K85.20', 'L53.9', 'M26.609', 'M32.9', 'N18.5', 'N18.9', 'N28.1', 'N28.82', 'N28.9', 'N32.89', 'N32.9', 'N39.0', 'Q61.3', 'Q64.4', 'R30.0', 'R31.9', 'R50.9', 'R60.0', 'R60.9', 'R63.4', 'Z87.891', 'Z90.710']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 36.36%\n",
      "F1 Validation | Micro: 0.15992 | Macro: 0.01935 | Best: 0.01942 | Epochs without improvement: 13\n",
      "Nuevos umbrales: Parent=0.241, Child=0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 603/603 [01:14<00:00,  8.14it/s, loss=0.00798, lr=2.94e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Loss: 0.0110 | LR: 2.94E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B99', 'I10', 'L53', 'N18', 'N28', 'R50', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'B99.9', 'D49.4', 'D72.0', 'D72.829', 'E78.5', 'F17.290', 'J98.51', 'K59.00', 'K59.8', 'L53.9', 'N18.9', 'N28.1', 'N28.82', 'N32.89', 'N32.9', 'N39.0', 'Q64.4', 'R30.0', 'R31.9', 'R50.9', 'R60.0', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 27.27%\n",
      "Saving best model... 0.01942 -> 0.02010\n",
      "F1 Validation | Micro: 0.18508 | Macro: 0.02010 | Best: 0.02010 | Epochs without improvement: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 603/603 [01:13<00:00,  8.22it/s, loss=0.00588, lr=2.94e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Loss: 0.0121 | LR: 2.94E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'I10', 'L53', 'N28', 'R50', 'R52', 'R63', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'B96.5', 'B99.9', 'D49.4', 'D72.0', 'D72.829', 'E78.5', 'F17.290', 'J98.51', 'K59.8', 'L53.9', 'N18.9', 'N28.1', 'N28.82', 'N32.9', 'N39.0', 'Q64.4', 'R31.9', 'R50.9', 'R60.0', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.16866 | Macro: 0.01954 | Best: 0.02010 | Epochs without improvement: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 603/603 [01:13<00:00,  8.22it/s, loss=0.0121, lr=2.94e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Loss: 0.0105 | LR: 2.94E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'I10', 'K59', 'L53', 'N18', 'N28', 'N32', 'R50', 'R52', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'B96.5', 'B99.9', 'D49.4', 'D72.0', 'D72.829', 'E78.5', 'F17.290', 'J98.51', 'K59.00', 'K59.8', 'L53.9', 'N18.9', 'N28.82', 'N32.9', 'N39.0', 'Q64.4', 'R30.0', 'R31.9', 'R50.9', 'R60.0', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 27.27%\n",
      "F1 Validation | Micro: 0.17639 | Macro: 0.01967 | Best: 0.02010 | Epochs without improvement: 15\n",
      "Nuevos umbrales: Parent=0.211, Child=0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 603/603 [01:12<00:00,  8.34it/s, loss=0.00324, lr=2.93e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Loss: 0.0060 | LR: 2.93E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B99', 'I10', 'K59', 'L53', 'N18', 'N28', 'R50', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'D49.4', 'D72.0', 'E78.5', 'F17.290', 'J98.51', 'K59.00', 'K59.8', 'L53.9', 'N18.9', 'N28.1', 'N28.82', 'N32.9', 'N39.0', 'Q64.4', 'R50.9', 'R60.0', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18938 | Macro: 0.01999 | Best: 0.02010 | Epochs without improvement: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 603/603 [01:13<00:00,  8.22it/s, loss=0.00945, lr=2.93e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Loss: 0.0071 | LR: 2.93E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'B99', 'D72', 'I10', 'K59', 'L53', 'N18', 'N28', 'N32', 'N39', 'Q64', 'R30', 'R31', 'R50', 'R52', 'R63', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.4', 'B95.61', 'B96.20', 'B96.5', 'B99.9', 'C67.9', 'C79.51', 'D49.4', 'D72.0', 'D72.829', 'E11.9', 'E78.5', 'F17.290', 'K44.9', 'K59.00', 'K59.8', 'K85.20', 'L53.9', 'L92.9', 'M32.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'N39.0', 'Q61.3', 'Q64.4', 'R18.8', 'R30.0', 'R31.0', 'R31.29', 'R31.9', 'R50.9', 'R63.0', 'R63.4', 'Z87.891', 'Z90.710']\n",
      "Parent Accuracy: 40.00% | Child Accuracy: 36.36%\n",
      "F1 Validation | Micro: 0.16880 | Macro: 0.01959 | Best: 0.02010 | Epochs without improvement: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 603/603 [01:13<00:00,  8.22it/s, loss=0.00608, lr=2.93e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Loss: 0.0072 | LR: 2.93E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B99', 'D11', 'D49', 'G83', 'I86', 'J98', 'K59', 'L53', 'N28', 'R52', 'R63', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.5', 'B95.61', 'B99.9', 'C78.7', 'C79.51', 'C80.0', 'D11.0', 'D49.0', 'E78.5', 'F17.290', 'G83.9', 'I85.00', 'I86.1', 'J98.51', 'K11.9', 'K59.00', 'K59.8', 'K76.9', 'K85.20', 'L53.9', 'L92.9', 'M32.9', 'M54.40', 'M89.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'Q61.3', 'Q64.4', 'R60.0', 'R63.0', 'R63.4', 'T85.41X', 'Z80.3', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.16182 | Macro: 0.01908 | Best: 0.02010 | Epochs without improvement: 18\n",
      "Nuevos umbrales: Parent=0.231, Child=0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 603/603 [01:12<00:00,  8.34it/s, loss=0.00303, lr=2.92e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Loss: 0.0044 | LR: 2.92E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B99', 'D49', 'I10', 'I86', 'K31', 'K59', 'L53', 'N18', 'N28', 'R50', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'C79.51', 'D11.0', 'D49.59', 'E78.5', 'F17.290', 'I85.00', 'I86.1', 'J98.51', 'K59.00', 'K59.8', 'L53.9', 'L92.9', 'M32.9', 'N13.30', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'N39.0', 'Q61.3', 'Q64.4', 'R19.00', 'R30.0', 'R31.9', 'R50.9', 'R63.0', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 36.36%\n",
      "F1 Validation | Micro: 0.18245 | Macro: 0.01984 | Best: 0.02010 | Epochs without improvement: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 603/603 [01:13<00:00,  8.22it/s, loss=0.00801, lr=2.92e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Loss: 0.0043 | LR: 2.92E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I10', 'I86', 'K59', 'L53', 'N18', 'N28', 'R50', 'R63', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'C79.51', 'D49.4', 'D72.0', 'E78.5', 'J98.51', 'K59.00', 'K59.8', 'L53.9', 'L92.9', 'M32.9', 'N18.9', 'N28.1', 'N28.89', 'N32.9', 'N39.0', 'Q64.4', 'R30.0', 'R50.9', 'R60.0', 'R63.0', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 27.27%\n",
      "F1 Validation | Micro: 0.18167 | Macro: 0.01970 | Best: 0.02010 | Epochs without improvement: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 603/603 [01:13<00:00,  8.22it/s, loss=0.00171, lr=2.92e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Loss: 0.0035 | LR: 2.92E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I10', 'I85', 'I86', 'K59', 'L53', 'N18', 'R63', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'E78.5', 'F17.290', 'I85.00', 'K59.00', 'K59.8', 'L53.9', 'M32.9', 'N18.9', 'N39.0', 'Q64.4', 'R30.0', 'R63.0', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18581 | Macro: 0.01950 | Best: 0.02010 | Epochs without improvement: 21\n",
      "Nuevos umbrales: Parent=0.201, Child=0.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 603/603 [01:12<00:00,  8.34it/s, loss=0.000538, lr=2.92e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Loss: 0.0019 | LR: 2.92E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I10', 'I86', 'K59', 'L53', 'N18', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'K59.00', 'K59.8', 'L53.9', 'N18.9', 'N28.1', 'R30.0', 'R50.9', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.19562 | Macro: 0.01978 | Best: 0.02010 | Epochs without improvement: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 603/603 [01:13<00:00,  8.22it/s, loss=0.00072, lr=2.91e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Loss: 0.0025 | LR: 2.91E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I10', 'I86', 'K59', 'L53', 'N28', 'R63', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B99.9', 'E78.5', 'I85.00', 'K31.89', 'K59.00', 'K59.8', 'L53.9', 'M32.9', 'N18.9', 'N28.82', 'N28.89', 'N32.9', 'Q64.4', 'R18.8', 'R30.0', 'R63.0', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18364 | Macro: 0.01965 | Best: 0.02010 | Epochs without improvement: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.00287, lr=2.91e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Loss: 0.0055 | LR: 2.91E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I86', 'K31', 'K59', 'L53', 'N28', 'R50', 'R52', 'R63', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'I86.1', 'J98.51', 'K59.8', 'L53.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'Q64.4', 'R11.10', 'R30.0', 'R31.9', 'R50.9', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.14879 | Macro: 0.01657 | Best: 0.02010 | Epochs without improvement: 24\n",
      "Nuevos umbrales: Parent=0.231, Child=0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 603/603 [01:12<00:00,  8.35it/s, loss=0.00202, lr=2.91e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Loss: 0.0026 | LR: 2.91E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I86', 'L53', 'N28', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'L53.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'Q64.4', 'R11.10', 'R63.4']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.18551 | Macro: 0.01792 | Best: 0.02010 | Epochs without improvement: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 603/603 [01:13<00:00,  8.24it/s, loss=0.00148, lr=2.9e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Loss: 0.0019 | LR: 2.90E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'I86', 'K59', 'L53', 'N28', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'E78.5', 'F17.290', 'K59.8', 'L53.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'Q64.4', 'R11.10', 'R63.4', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.18352 | Macro: 0.01839 | Best: 0.02010 | Epochs without improvement: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.00101, lr=2.9e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Loss: 0.0015 | LR: 2.90E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I86', 'K59', 'L53', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'K59.8', 'L53.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'Q64.4', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.18786 | Macro: 0.01910 | Best: 0.02010 | Epochs without improvement: 27\n",
      "Nuevos umbrales: Parent=0.198, Child=0.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 603/603 [01:12<00:00,  8.35it/s, loss=0.000924, lr=2.9e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Loss: 0.0008 | LR: 2.90E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'I86', 'L53', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'L53.9', 'N18.9', 'N28.89', 'Q64.4']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.19256 | Macro: 0.01890 | Best: 0.02010 | Epochs without improvement: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.000347, lr=2.89e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Loss: 0.0011 | LR: 2.89E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'I86', 'K59', 'L53', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B99.9', 'E78.5', 'K59.8', 'L53.9', 'N18.9', 'N28.1', 'N28.89', 'Q64.4', 'R11.10', 'R63.4']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.18844 | Macro: 0.01903 | Best: 0.02010 | Epochs without improvement: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.00067, lr=2.89e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Loss: 0.0009 | LR: 2.89E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'I86', 'K59', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'F17.290', 'I85.00', 'K59.8', 'N18.9', 'N28.89', 'N32.9', 'Q64.4', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.18767 | Macro: 0.01854 | Best: 0.02010 | Epochs without improvement: 30\n",
      "Nuevos umbrales: Parent=0.192, Child=0.123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 603/603 [01:12<00:00,  8.35it/s, loss=0.000549, lr=2.89e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Loss: 0.0005 | LR: 2.89E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['D49', 'I86', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['N18.9', 'N28.89', 'Q64.4']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.19397 | Macro: 0.01835 | Best: 0.02010 | Epochs without improvement: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.000393, lr=2.89e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Loss: 0.0007 | LR: 2.89E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['D49', 'I10', 'I86', 'K31', 'K59', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['D49.4', 'D49.59', 'F17.290', 'K59.8', 'N18.9', 'N28.89', 'N32.9', 'Q64.4', 'R63.4']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.18861 | Macro: 0.01865 | Best: 0.02010 | Epochs without improvement: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.00113, lr=2.88e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Loss: 0.0029 | LR: 2.88E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'E78', 'I10', 'L53', 'N18', 'N28', 'N32', 'Q64', 'R31', 'R50', 'R52', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.4', 'B95.61', 'B96.20', 'D49.4', 'D49.59', 'E11.9', 'E13.9', 'E78.5', 'F17.290', 'K59.8', 'L53.9', 'L92.9', 'N13.30', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'N39.0', 'Q61.3', 'Q64.4', 'R31.9', 'R50.9', 'R60.0', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 27.27%\n",
      "F1 Validation | Micro: 0.17254 | Macro: 0.01793 | Best: 0.02010 | Epochs without improvement: 33\n",
      "Nuevos umbrales: Parent=0.228, Child=0.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 603/603 [01:12<00:00,  8.35it/s, loss=0.000943, lr=2.88e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Loss: 0.0005 | LR: 2.88E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'E78', 'I86', 'L53', 'N18', 'N28', 'N32', 'Q64', 'R31', 'R50', 'R52', 'R63', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'D49.4', 'D49.59', 'E78.5', 'F17.290', 'L53.9', 'L92.9', 'N13.30', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'Q64.4', 'R31.9', 'R50.9', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18664 | Macro: 0.01864 | Best: 0.02010 | Epochs without improvement: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 603/603 [01:13<00:00,  8.26it/s, loss=0.000515, lr=2.88e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Loss: 0.0007 | LR: 2.88E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'L53', 'N18', 'N28', 'Q64', 'R50', 'R52', 'R63', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'D49.4', 'D49.59', 'E78.5', 'F17.290', 'K59.8', 'L53.9', 'L92.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N39.0', 'Q64.4', 'R31.9', 'R50.9', 'Z87.891']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 27.27%\n",
      "F1 Validation | Micro: 0.18488 | Macro: 0.01887 | Best: 0.02010 | Epochs without improvement: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.000233, lr=2.87e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Loss: 0.0005 | LR: 2.87E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'I86', 'L53', 'N18', 'N28', 'Q64', 'R50', 'R63', 'Z87']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'D49.4', 'D49.59', 'E78.5', 'F17.290', 'L53.9', 'L92.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'Q64.4', 'R19.00', 'R31.9', 'R50.9', 'Z87.891']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18778 | Macro: 0.01884 | Best: 0.02010 | Epochs without improvement: 36\n",
      "Nuevos umbrales: Parent=0.218, Child=0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 603/603 [01:12<00:00,  8.36it/s, loss=0.000599, lr=2.87e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Loss: 0.0003 | LR: 2.87E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'L53', 'N18', 'N28', 'Q64', 'R50', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'D49.59', 'E78.5', 'F17.290', 'L53.9', 'L92.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'Q64.4', 'R31.9', 'R50.9', 'Z87.891']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.19363 | Macro: 0.01870 | Best: 0.02010 | Epochs without improvement: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.00024, lr=2.87e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Loss: 0.0004 | LR: 2.87E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'L53', 'N18', 'N28', 'Q64', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'D49.59', 'E78.5', 'F17.290', 'L53.9', 'L92.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'Q64.4', 'R19.00', 'R50.9', 'Z87.891']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.19025 | Macro: 0.01891 | Best: 0.02010 | Epochs without improvement: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.000433, lr=2.86e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Loss: 0.0021 | LR: 2.86E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'I86', 'K31', 'K59', 'L53', 'N18', 'N28', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'D49.59', 'E78.5', 'I85.00', 'I86.1', 'L53.9', 'L92.9', 'N17.9', 'N18.9', 'N28.89', 'Q64.4', 'R19.00', 'R31.9', 'R63.4']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.16928 | Macro: 0.01836 | Best: 0.02010 | Epochs without improvement: 39\n",
      "Nuevos umbrales: Parent=0.235, Child=0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 603/603 [01:12<00:00,  8.35it/s, loss=0.000341, lr=2.86e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Loss: 0.0004 | LR: 2.86E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'D49', 'I86', 'L53', 'N18', 'N28', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['D49.59', 'E78.5', 'I85.00', 'I86.1', 'L53.9', 'N18.9', 'N28.89', 'R31.9', 'R63.0', 'R63.4']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.17813 | Macro: 0.01853 | Best: 0.02010 | Epochs without improvement: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.000171, lr=2.86e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Loss: 0.0005 | LR: 2.86E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I86', 'K59', 'L53', 'N18', 'N28', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['I86.1', 'L53.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'Q64.4', 'R19.00', 'R31.9', 'R63.0', 'R63.4']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.17754 | Macro: 0.01928 | Best: 0.02010 | Epochs without improvement: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 603/603 [01:13<00:00,  8.26it/s, loss=0.000515, lr=2.86e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Loss: 0.0004 | LR: 2.86E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I86', 'K59', 'L53', 'N18', 'N28', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['E78.5', 'F17.290', 'I86.1', 'L53.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'N32.9', 'R19.00', 'R31.9', 'R63.0', 'R63.4']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18005 | Macro: 0.01943 | Best: 0.02010 | Epochs without improvement: 42\n",
      "Nuevos umbrales: Parent=0.214, Child=0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 603/603 [01:12<00:00,  8.36it/s, loss=0.000101, lr=2.85e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Loss: 0.0002 | LR: 2.85E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['D49', 'I86', 'K59', 'L53', 'N18', 'N28', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['F17.290', 'I86.1', 'L53.9', 'N18.9', 'N28.1', 'N28.82', 'N28.89', 'R19.00', 'R31.9', 'R63.0', 'R63.4']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18589 | Macro: 0.01887 | Best: 0.02010 | Epochs without improvement: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.00037, lr=2.85e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Loss: 0.0003 | LR: 2.85E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['I86', 'K59', 'L53', 'N18', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['F17.290', 'L53.9', 'N18.9', 'N28.89', 'R31.9', 'R63.0', 'R63.4']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18306 | Macro: 0.01976 | Best: 0.02010 | Epochs without improvement: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.000358, lr=2.85e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Loss: 0.0002 | LR: 2.85E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['D49', 'I86', 'K59', 'L53', 'N18', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['F17.290', 'I86.1', 'L53.9', 'N18.9', 'N28.1', 'N28.89', 'R31.9', 'R63.0', 'R63.4']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18278 | Macro: 0.01944 | Best: 0.02010 | Epochs without improvement: 45\n",
      "Nuevos umbrales: Parent=0.212, Child=0.120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 603/603 [01:12<00:00,  8.35it/s, loss=0.000336, lr=2.84e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Loss: 0.0001 | LR: 2.84E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['D49', 'I86', 'L53', 'N18', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['F17.290', 'I86.1', 'L53.9', 'N18.9', 'N28.89', 'R31.9', 'R63.4']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18761 | Macro: 0.01869 | Best: 0.02010 | Epochs without improvement: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 603/603 [01:12<00:00,  8.26it/s, loss=0.00011, lr=2.84e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Loss: 0.0002 | LR: 2.84E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['D49', 'I86', 'K59', 'L53', 'N18', 'N28', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['F17.290', 'L53.9', 'N18.9', 'N28.89', 'N32.9', 'R31.9', 'R63.0', 'R63.4']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.18593 | Macro: 0.01996 | Best: 0.02010 | Epochs without improvement: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.000367, lr=2.84e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Loss: 0.0062 | LR: 2.84E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'B96', 'C64', 'D49', 'D72', 'E11', 'E78', 'E79', 'I10', 'I85', 'I86', 'K59', 'N18', 'N28', 'Q61', 'R52', 'R60', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'C64.1', 'C64.9', 'C79.51', 'D72.829', 'E11.9', 'E78.5', 'E79.0', 'F17.290', 'I50.9', 'I85.00', 'I86.1', 'K40.90', 'N17.9', 'N18.9', 'N28.1', 'N28.89', 'N32.9', 'N39.0', 'Q44.6', 'Q61.3', 'Q64.4', 'R10.10', 'R19.00', 'R53.1', 'R60.0', 'R60.9', 'R63.0', 'Z87.891']\n",
      "Parent Accuracy: 20.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.13555 | Macro: 0.01688 | Best: 0.02010 | Epochs without improvement: 48\n",
      "Nuevos umbrales: Parent=0.273, Child=0.160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 603/603 [01:12<00:00,  8.36it/s, loss=0.000244, lr=2.83e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Loss: 0.0005 | LR: 2.83E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I10', 'I86', 'K59', 'N18', 'N28', 'N32', 'Q64', 'R31', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'C79.51', 'D72.829', 'E11.9', 'E78.5', 'F17.290', 'L53.9', 'L92.9', 'N17.9', 'N18.9', 'N28.1', 'N28.89', 'N32.9', 'Q64.4', 'R18.8', 'R19.00', 'R31.9', 'R50.9', 'R63.0']\n",
      "Parent Accuracy: 30.00% | Child Accuracy: 18.18%\n",
      "F1 Validation | Micro: 0.15910 | Macro: 0.01729 | Best: 0.02010 | Epochs without improvement: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 603/603 [01:13<00:00,  8.25it/s, loss=0.000151, lr=2.83e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Loss: 0.0007 | LR: 2.83E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I10', 'I86', 'L53', 'N18', 'N28', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['B95.61', 'B96.20', 'B99.9', 'C79.51', 'E11.9', 'E78.5', 'F17.290', 'I86.1', 'L53.9', 'L92.9', 'N18.9', 'N28.1', 'N28.89', 'N32.9', 'Q64.4', 'R50.9', 'R63.0']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.17684 | Macro: 0.01816 | Best: 0.02010 | Epochs without improvement: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 603/603 [01:13<00:00,  8.24it/s, loss=9.78e-5, lr=2.83e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Loss: 0.0002 | LR: 2.83E-05\n",
      "\n",
      "Example Validation Results:\n",
      "Expected parent: ['D18', 'K26', 'K59', 'N13', 'N20', 'N23', 'N28', 'N39', 'Q62', 'R31']\n",
      "Predicted parent: ['B95', 'I10', 'I86', 'L53', 'N18', 'N28', 'R52', 'R63']\n",
      "Expected child: ['D18.09', 'K26.9', 'K59.00', 'N13.5', 'N20.0', 'N28.0', 'N28.89', 'N28.9', 'N39.0', 'Q62.11', 'R31.9']\n",
      "Predicted child: ['E78.5', 'F17.290', 'I86.1', 'L53.9', 'L92.9', 'N18.9', 'N28.1', 'N28.89', 'N32.9', 'Q64.4', 'R63.0', 'Z87.891']\n",
      "Parent Accuracy: 10.00% | Child Accuracy: 9.09%\n",
      "F1 Validation | Micro: 0.18129 | Macro: 0.01867 | Best: 0.02010 | Epochs without improvement: 51\n",
      "Early stopping at epoch 60\n",
      "Loaded saved MLBs\n",
      "Loaded saved tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default BERT model\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'exists'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 530\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing default tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    525\u001b[0m model \u001b[38;5;241m=\u001b[39m HierarchicalBERT(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mlen\u001b[39m(mlb_parent\u001b[38;5;241m.\u001b[39mclasses_),\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mlen\u001b[39m(mlb_child\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m    528\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mConfig\u001b[38;5;241m.\u001b[39mSAVE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_2\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    531\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mConfig\u001b[38;5;241m.\u001b[39mSAVE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_2\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded best model - 2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'exists'"
     ]
    }
   ],
   "source": [
    "# v3 (Sliding Window)\n",
    "# ====================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup, AutoConfig\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ====================\n",
    "#  Modelo v3\n",
    "# ====================\n",
    "class HierarchicalBERTv2(torch.nn.Module):\n",
    "    def __init__(self, num_parents, num_children):\n",
    "        super().__init__()\n",
    "        config = AutoConfig.from_pretrained(Config.MODEL_NAME, output_hidden_states=True)\n",
    "        self.bert = AutoModel.from_pretrained(Config.MODEL_NAME, config=config)\n",
    "\n",
    "        hidden_size = self.bert.config.hidden_size  # This will be 768 for base models\n",
    "\n",
    "        self.parent_classifier = torch.nn.Linear(hidden_size, num_parents)\n",
    "        self.child_classifier = torch.nn.Linear(hidden_size + num_parents, num_children)\n",
    "        self.dropout = torch.nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        if Config.USE_FEATURE_PYRAMID:\n",
    "            # Combine last 3 layers' [CLS] embeddings\n",
    "            hidden_states = outputs.hidden_states[-3:]  # Get last 3 layers\n",
    "            # Stack [CLS] embeddings (shape: [3, batch_size, hidden_size])\n",
    "            pooled = torch.stack([state[:, 0] for state in hidden_states])\n",
    "            # Weighted combination of layers (weights should sum to 1)\n",
    "            if sum(Config.FEATURE_LAYER_WEIGHTS) != 1:\n",
    "                raise ValueError(\"FEATURE_LAYER_WEIGHTS must sum to 1\")\n",
    "\n",
    "            # Apply weights to layers\n",
    "            pooled = torch.einsum('lbd,l->bd', pooled,\n",
    "                                torch.tensor(Config.FEATURE_LAYER_WEIGHTS).to(pooled.device))\n",
    "        else:\n",
    "            pooled = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        pooled = self.dropout(pooled)\n",
    "\n",
    "        # Jerarquía de clasificación\n",
    "        parent_logits = self.parent_classifier(pooled)\n",
    "        parent_probs = torch.sigmoid(parent_logits)\n",
    "        child_input = torch.cat([pooled, parent_probs], dim=1)\n",
    "        child_logits = self.child_classifier(child_input)\n",
    "\n",
    "        return parent_logits, child_logits, pooled\n",
    "\n",
    "# ====================\n",
    "#  FUNCIÓN DE PÉRDIDA MEJORADA\n",
    "# ====================\n",
    "def hierarchical_lossv2(parent_logits, child_logits,\n",
    "                     parent_labels, child_labels,\n",
    "                     parent_weights, child_weights):\n",
    "\n",
    "    loss_parent = F.binary_cross_entropy_with_logits(\n",
    "        parent_logits,\n",
    "        parent_labels,\n",
    "        pos_weight=parent_weights\n",
    "    )\n",
    "\n",
    "    loss_child = F.binary_cross_entropy_with_logits(\n",
    "        child_logits,\n",
    "        child_labels,\n",
    "        pos_weight=child_weights\n",
    "    )\n",
    "\n",
    "    return (Config.HIERARCHICAL_WEIGHTS['parent'] * loss_parent +\n",
    "            Config.HIERARCHICAL_WEIGHTS['child'] * loss_child)\n",
    "\n",
    "# ====================\n",
    "#  AJUSTE DINÁMICO DE UMBRALES\n",
    "# ====================\n",
    "def calculate_optimal_thresholds(y_true, y_probs):\n",
    "    thresholds = {}\n",
    "    for i in range(y_probs.shape[1]):\n",
    "        if np.sum(y_true[:, i]) > 0:  # Solo clases presentes\n",
    "            precision, recall, threshs = precision_recall_curve(y_true[:, i], y_probs[:, i])\n",
    "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "            best_idx = np.nanargmax(f1_scores)\n",
    "            thresholds[i] = threshs[best_idx]\n",
    "    return thresholds\n",
    "\n",
    "# ====================\n",
    "#  DATASET v3 (Sliding Window)\n",
    "# ====================\n",
    "class HierarchicalMedicalDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, mlb_parent, mlb_child):\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.examples = []\n",
    "\n",
    "        # Procesar etiquetas\n",
    "        self.parent_labels = []\n",
    "        self.child_labels = []\n",
    "\n",
    "        # Same label processing as before\n",
    "        for codes in df['labels'].apply(eval):\n",
    "            parents, children = set(), set()\n",
    "            for code in codes:\n",
    "                code = code.strip().upper()\n",
    "                levels = parse_code(code)\n",
    "                if len(levels) >= 1: parents.add(levels[0])\n",
    "                if len(levels) >= 2: children.add(levels[1])\n",
    "\n",
    "            self.parent_labels.append(mlb_parent.transform([parents])[0])\n",
    "            self.child_labels.append(mlb_child.transform([children])[0])\n",
    "\n",
    "        # Generate sliding windows for each text\n",
    "        for idx, text in enumerate(self.texts):\n",
    "            # Tokenize whole text\n",
    "            tokens = self.tokenizer(\n",
    "                text,\n",
    "                truncation=False,\n",
    "                return_offsets_mapping=True,\n",
    "                add_special_tokens=False\n",
    "            )\n",
    "\n",
    "            # Generate sliding windows\n",
    "            window_size = Config.MAX_LENGTH - 2  # Account for [CLS] and [SEP]\n",
    "            stride = Config.STRIDE\n",
    "\n",
    "            for i in range(0, len(tokens['input_ids']), stride):\n",
    "                # Extract window\n",
    "                window_start = i\n",
    "                window_end = min(i + window_size, len(tokens['input_ids']))\n",
    "\n",
    "                # Add special tokens\n",
    "                input_ids = (\n",
    "                    [self.tokenizer.cls_token_id] +\n",
    "                    tokens['input_ids'][window_start:window_end] +\n",
    "                    [self.tokenizer.sep_token_id]\n",
    "                )\n",
    "\n",
    "                attention_mask = [1] * len(input_ids)\n",
    "\n",
    "                # Pad if necessary\n",
    "                padding_length = Config.MAX_LENGTH - len(input_ids)\n",
    "                if padding_length > 0:\n",
    "                    input_ids += [self.tokenizer.pad_token_id] * padding_length\n",
    "                    attention_mask += [0] * padding_length\n",
    "\n",
    "                self.examples.append({\n",
    "                    'input_ids': torch.tensor(input_ids),\n",
    "                    'attention_mask': torch.tensor(attention_mask),\n",
    "                    'parent_labels': torch.FloatTensor(self.parent_labels[idx]),\n",
    "                    'child_labels': torch.FloatTensor(self.child_labels[idx]),\n",
    "                    'text_id': idx  # To group windows later\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "\n",
    "# ====================\n",
    "#  ENTRENAMIENTO con Sliding Window\n",
    "# ====================\n",
    "def train(best_thresholds=Config.THRESHOLDS):\n",
    "    epochs_without_improvement = 0\n",
    "    early_stop = False\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Cargar datos\n",
    "    train_df = pd.read_csv(Config.DATA_PATHS['train'])\n",
    "    val_df = pd.read_csv(Config.DATA_PATHS['val'])\n",
    "\n",
    "    # Construir binarizadores\n",
    "    mlb_parent, mlb_child = calculate_mlb_classes()\n",
    "\n",
    "    # Preparar datasets\n",
    "\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.SAVE_TOKENIZER_PATH)\n",
    "        print(\"Loaded saved tokenizer\")\n",
    "    except:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
    "        tokenizer.save_pretrained(Config.SAVE_TOKENIZER_PATH)\n",
    "        print(\"Created new tokenizer\")\n",
    "\n",
    "    train_dataset = HierarchicalMedicalDataset(train_df, tokenizer, mlb_parent, mlb_child)\n",
    "    val_dataset = HierarchicalMedicalDataset(val_df, tokenizer, mlb_parent, mlb_child)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=Config.TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=Config.VAL_BATCH_SIZE)\n",
    "\n",
    "    # Modelo y optimizador\n",
    "    model = HierarchicalBERTv2(\n",
    "        len(mlb_parent.classes_),\n",
    "        len(mlb_child.classes_)\n",
    "    ).to(device)\n",
    "\n",
    "    # Load best model if available\n",
    "    if not Config.FORCE_NEW_MODEL:\n",
    "        if os.path.exists(f\"{Config.SAVE_PATH}_2\"):\n",
    "            model.load_state_dict(torch.load(f\"{Config.SAVE_PATH}_2\"))\n",
    "            print(\"Loaded best model - 2\")\n",
    "        elif os.path.exists(Config.SAVE_PATH):\n",
    "            model.load_state_dict(torch.load(Config.SAVE_PATH))\n",
    "            print(\"Loaded best model\")\n",
    "        else:\n",
    "            print(\"Starting training from scratch\")\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps = Config.WARMUP_EPOCHS * len(train_loader),\n",
    "        num_training_steps = Config.EPOCHS * len(train_loader)\n",
    "    )\n",
    "\n",
    "    # Bucle de entrenamiento\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=Config.USE_FP16)\n",
    "\n",
    "    # Calcular pesos de clases\n",
    "    parent_counts = np.sum(train_dataset.parent_labels, axis=0)\n",
    "    parent_weights = (len(train_dataset) - parent_counts) / (parent_counts + Config.CLASS_WEIGHT_SMOOTHING)\n",
    "    parent_weights = torch.tensor(parent_weights).to(device)\n",
    "\n",
    "    child_counts = np.sum(train_dataset.child_labels, axis=0)\n",
    "    child_weights = (len(train_dataset) - child_counts) / (child_counts + Config.CLASS_WEIGHT_SMOOTHING)\n",
    "    child_weights = torch.tensor(child_weights).to(device)\n",
    "\n",
    "    for epoch in range(Config.EPOCHS):\n",
    "        if early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Ajuste periódico de umbrales\n",
    "        if (epoch + 1) % Config.THRESHOLD_TUNING_INTERVAL == 0:\n",
    "            val_probs, val_labels = get_validation_probabilities(model, val_loader, device)\n",
    "\n",
    "            # Calcular mejores umbrales por clase\n",
    "            parent_thresholds = calculate_optimal_thresholds(\n",
    "                val_labels['parent'], val_probs['parent']\n",
    "            )\n",
    "            child_thresholds = calculate_optimal_thresholds(\n",
    "                val_labels['child'], val_probs['child']\n",
    "            )\n",
    "\n",
    "            # Actualizar umbrales globales\n",
    "            best_thresholds['parent'] = np.mean(list(parent_thresholds.values()))\n",
    "            best_thresholds['child'] = np.mean(list(child_thresholds.values()))\n",
    "            print(f\"Nuevos umbrales: Parent={best_thresholds['parent']:.3f}, Child={best_thresholds['child']:.3f}\")\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        text_predictions = defaultdict(lambda: {'parent': [], 'child': []})\n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            with torch.amp.autocast('cuda', enabled=Config.USE_FP16):\n",
    "                parent_logits, child_logits, _ = model(\n",
    "                    input_ids=batch['input_ids'],\n",
    "                    attention_mask=batch['attention_mask']\n",
    "                )\n",
    "\n",
    "                # Store predictions by original text\n",
    "                for i, text_id in enumerate(batch['text_id'].cpu().numpy()):\n",
    "                    text_predictions[text_id]['parent'].append(parent_logits[i])\n",
    "                    text_predictions[text_id]['child'].append(child_logits[i])\n",
    "\n",
    "                # Immediate window-level loss\n",
    "                loss = hierarchical_lossv2(\n",
    "                    parent_logits,\n",
    "                    child_logits,\n",
    "                    batch['parent_labels'],  # Use batch labels directly\n",
    "                    batch['child_labels'],   # Not the dataset's labels\n",
    "                    parent_weights,\n",
    "                    child_weights\n",
    "                )\n",
    "\n",
    "            # Backpropagate\n",
    "            scaler.scale(loss).backward()\n",
    "            if (step + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item(), lr=scheduler.get_last_lr()[0])\n",
    "\n",
    "        # After epoch completes, calculate aggregated loss\n",
    "        agg_loss = 0\n",
    "        for text_id in text_predictions:\n",
    "            if text_id >= len(train_dataset.parent_labels):\n",
    "                continue  # Skip invalid text_ids\n",
    "\n",
    "            # Aggregate predictions\n",
    "            parent_agg = torch.stack(text_predictions[text_id]['parent']).max(dim=0)[0]\n",
    "            child_agg = torch.stack(text_predictions[text_id]['child']).max(dim=0)[0]\n",
    "\n",
    "            # Get true labels from dataset\n",
    "            parent_label = torch.FloatTensor(train_dataset.parent_labels[text_id]).to(device)\n",
    "            child_label = torch.FloatTensor(train_dataset.child_labels[text_id]).to(device)\n",
    "\n",
    "            # Calculate aggregated loss\n",
    "            agg_loss += hierarchical_lossv2(\n",
    "                parent_agg.unsqueeze(0),\n",
    "                child_agg.unsqueeze(0),\n",
    "                parent_label.unsqueeze(0),\n",
    "                child_label.unsqueeze(0),\n",
    "                parent_weights,\n",
    "                child_weights\n",
    "            )\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss += agg_loss.item() / len(text_predictions)\n",
    "        print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | LR: {scheduler.get_last_lr()[0]:.2E}\")\n",
    "\n",
    "        # Validación\n",
    "        val_metrics = evaluate(model, val_loader, device, mlb_parent, mlb_child, best_thresholds)\n",
    "\n",
    "        # Store metrics\n",
    "        loss_metric = val_metrics['f1_macro']\n",
    "        if epoch == 0:\n",
    "            best_f1 = loss_metric\n",
    "\n",
    "        if loss_metric > (best_f1 + Config.IMPROVEMENT_MARGIN):\n",
    "            print(f\"Saving best model... {best_f1:.5f} -> {loss_metric:.5f}\")\n",
    "            torch.save(model.state_dict(), f\"{Config.SAVE_PATH}_3\")\n",
    "            best_f1 = loss_metric\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= Config.EARLY_STOP_PATIENCE:\n",
    "                early_stop = True\n",
    "\n",
    "        metrics_data = {\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': total_loss/len(train_loader),\n",
    "            'f1_micro': val_metrics['f1_micro'],\n",
    "            'f1_macro': val_metrics['f1_macro'],\n",
    "            'f1_micro_parent': val_metrics['f1_micro_parent'],\n",
    "            'f1_macro_parent': val_metrics['f1_macro_parent'],\n",
    "            'f1_micro_child': val_metrics['f1_micro_child'],\n",
    "            'f1_macro_child': val_metrics['f1_macro_child'],\n",
    "            'lr': scheduler.get_last_lr()[0],\n",
    "            'epochs_without_improvement': epochs_without_improvement,\n",
    "            'parent_threshold': best_thresholds['parent'],\n",
    "            'child_threshold': best_thresholds['child']\n",
    "        }\n",
    "\n",
    "        # Write metrics to CSV\n",
    "        metrics_df = pd.DataFrame([metrics_data])\n",
    "        if epoch == 0:\n",
    "            metrics_df.to_csv('training_metrics.csv', mode='a', index=False)\n",
    "        else:\n",
    "            metrics_df.to_csv('training_metrics.csv', mode='a', header=False, index=False)\n",
    "\n",
    "        print(f\"F1 Validation | Micro: {val_metrics['f1_micro']:.5f} | Macro: {val_metrics['f1_macro']:.5f} | Best: {best_f1:.5f} | Epochs without improvement: {epochs_without_improvement + 1}\")\n",
    "\n",
    "# ====================\n",
    "#  FUNCIONES AUXILIARES (Con sliding windows)\n",
    "# ====================\n",
    "def get_validation_probabilities(model, dataloader, device):\n",
    "    model.eval()\n",
    "    text_predictions = defaultdict(lambda: {'parent': [], 'child': []})\n",
    "    parent_labels = {}\n",
    "    child_labels = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(device),\n",
    "                'attention_mask': batch['attention_mask'].to(device)\n",
    "            }\n",
    "            text_ids = batch['text_id'].numpy()\n",
    "\n",
    "            # Store labels by text_id\n",
    "            for i, text_id in enumerate(text_ids):\n",
    "                if text_id not in parent_labels:\n",
    "                    parent_labels[text_id] = batch['parent_labels'][i].numpy()\n",
    "                    child_labels[text_id] = batch['child_labels'][i].numpy()\n",
    "\n",
    "            # Get predictions\n",
    "            p_logits, c_logits, _ = model(**inputs)\n",
    "\n",
    "            # Store predictions by text_id\n",
    "            for i, text_id in enumerate(text_ids):\n",
    "                text_predictions[text_id]['parent'].append(p_logits[i].cpu())\n",
    "                text_predictions[text_id]['child'].append(c_logits[i].cpu())\n",
    "\n",
    "    # Aggregate predictions per text\n",
    "    parent_probs, child_probs = [], []\n",
    "    final_parent_labels, final_child_labels = [], []\n",
    "\n",
    "    for text_id in text_predictions:\n",
    "        # Aggregate using max pooling (same as training)\n",
    "        parent_agg = torch.stack(text_predictions[text_id]['parent']).max(dim=0)[0]\n",
    "        child_agg = torch.stack(text_predictions[text_id]['child']).max(dim=0)[0]\n",
    "\n",
    "        parent_probs.append(torch.sigmoid(parent_agg).numpy())\n",
    "        child_probs.append(torch.sigmoid(child_agg).numpy())\n",
    "\n",
    "        # Get original labels\n",
    "        final_parent_labels.append(parent_labels[text_id])\n",
    "        final_child_labels.append(child_labels[text_id])\n",
    "\n",
    "    return {\n",
    "        'parent': np.array(parent_probs),\n",
    "        'child': np.array(child_probs)\n",
    "    }, {\n",
    "        'parent': np.array(final_parent_labels),\n",
    "        'child': np.array(final_child_labels)\n",
    "    }\n",
    "\n",
    "# ====================\n",
    "#  EVALUACIÓN Con sliding windows\n",
    "# ====================\n",
    "def evaluate(model, dataloader, device, mlb_parent, mlb_child, thresholds):\n",
    "    val_probs, val_labels = get_validation_probabilities(model, dataloader, device)\n",
    "\n",
    "    # Convert probabilities to predictions\n",
    "    parent_preds = (val_probs['parent'] > thresholds['parent']).astype(int)\n",
    "    child_preds = (val_probs['child'] > thresholds['child']).astype(int)\n",
    "\n",
    "    # Print example comparison\n",
    "    if len(val_labels['parent']) > 0:\n",
    "        idx = 0  # First example\n",
    "        parent_true = np.array(mlb_parent.classes_)[val_labels['parent'][idx].astype(bool)]\n",
    "        parent_pred = np.array(mlb_parent.classes_)[parent_preds[idx].astype(bool)]\n",
    "\n",
    "        child_true = np.array(mlb_child.classes_)[val_labels['child'][idx].astype(bool)]\n",
    "        child_pred = np.array(mlb_child.classes_)[child_preds[idx].astype(bool)]\n",
    "\n",
    "        print(\"\\nExample Validation Results:\")\n",
    "        print(f\"Expected parent: {sorted(parent_true)}\")\n",
    "        print(f\"Predicted parent: {sorted(parent_pred)}\")\n",
    "        print(f\"Expected child: {sorted(child_true)}\")\n",
    "        print(f\"Predicted child: {sorted(child_pred)}\")\n",
    "\n",
    "        common_parent = len(set(parent_true) & set(parent_pred))\n",
    "        common_child = len(set(child_true) & set(child_pred))\n",
    "        print(f\"Parent Accuracy: {common_parent/len(parent_true):.2%} | Child Accuracy: {common_child/len(child_true):.2%}\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'f1_micro_parent': f1_score(val_labels['parent'], parent_preds, average='micro', zero_division=0),\n",
    "        'f1_macro_parent': f1_score(val_labels['parent'], parent_preds, average='macro', zero_division=0),\n",
    "        'f1_micro_child': f1_score(val_labels['child'], child_preds, average='micro', zero_division=0),\n",
    "        'f1_macro_child': f1_score(val_labels['child'], child_preds, average='macro', zero_division=0)\n",
    "    }\n",
    "\n",
    "    # Weighted averages\n",
    "    total_weight = sum(Config.HIERARCHICAL_WEIGHTS.values())\n",
    "    metrics['f1_micro'] = (Config.HIERARCHICAL_WEIGHTS['parent'] * metrics['f1_micro_parent'] +\n",
    "                          Config.HIERARCHICAL_WEIGHTS['child'] * metrics['f1_micro_child']) / total_weight\n",
    "\n",
    "    metrics['f1_macro'] = (Config.HIERARCHICAL_WEIGHTS['parent'] * metrics['f1_macro_parent'] +\n",
    "                          Config.HIERARCHICAL_WEIGHTS['child'] * metrics['f1_macro_child']) / total_weight\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ====================\n",
    "#  PREDICCIÓN\n",
    "# ====================\n",
    "def predict(text, model, tokenizer, mlb_parent, mlb_child, device, thresholds):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=Config.MAX_LENGTH,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        parent_logits, child_logits = model(**encoding)\n",
    "\n",
    "    # Obtener predicciones\n",
    "    parent_probs = torch.sigmoid(parent_logits).cpu().numpy()\n",
    "    child_probs = torch.sigmoid(child_logits).cpu().numpy()\n",
    "\n",
    "    # Decodificar etiquetas\n",
    "    parent_preds = mlb_parent.inverse_transform((parent_probs > thresholds['parent']).astype(int))\n",
    "    child_preds = mlb_child.inverse_transform((child_probs > thresholds['child']).astype(int))\n",
    "\n",
    "    # Combinar y asegurar jerarquía\n",
    "    final_codes = set()\n",
    "    for parent in parent_preds[0]:\n",
    "        final_codes.add(parent)\n",
    "        for child in child_preds[0]:\n",
    "            if child.startswith(parent):\n",
    "                final_codes.add(child)\n",
    "\n",
    "    return sorted(final_codes)\n",
    "\n",
    "# ====================\n",
    "#  EJECUCIÓN\n",
    "# ====================\n",
    "if __name__ == \"__main__\":\n",
    "    best_thresholds = Config.THRESHOLDS\n",
    "\n",
    "    train(best_thresholds)\n",
    "\n",
    "    # Cargar datos de test\n",
    "    test_df = pd.read_csv(Config.DATA_PATHS['test'])\n",
    "    mlb_parent, mlb_child = calculate_mlb_classes()\n",
    "\n",
    "    # Cargar modelo\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.SAVE_TOKENIZER_PATH)\n",
    "        print(\"Loaded saved tokenizer\")\n",
    "    except:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
    "        print(\"Using default tokenizer\")\n",
    "\n",
    "    model = HierarchicalBERT(\n",
    "        len(mlb_parent.classes_),\n",
    "        len(mlb_child.classes_)\n",
    "    ).to(device)\n",
    "\n",
    "    if os.path.exists(f\"{Config.SAVE_PATH}_2\"):\n",
    "        model.load_state_dict(torch.load(f\"{Config.SAVE_PATH}_2\"))\n",
    "        print(\"Loaded best model - 2\")\n",
    "    elif os.path.exists(Config.SAVE_PATH):\n",
    "        model.load_state_dict(torch.load(Config.SAVE_PATH))\n",
    "        print(\"Loaded best model\")\n",
    "\n",
    "    # Evaluar en test\n",
    "    test_dataset = HierarchicalMedicalDataset(test_df, tokenizer, mlb_parent, mlb_child)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=Config.TEST_BATCH_SIZE)\n",
    "\n",
    "    test_metrics = evaluate(model, test_loader, device, mlb_parent, mlb_child)\n",
    "    print(\"\\nResultados en Test:\")\n",
    "    print(f\"Micro F1: {test_metrics['f1_micro']:.4f}\")\n",
    "    print(f\"Macro F1: {test_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "    # Ejemplo de predicción\n",
    "    sample_text = \"Paciente con diabetes mellitus tipo 2 y complicaciones renales...\"\n",
    "    prediction = predict(sample_text, model, tokenizer, mlb_parent, mlb_child, device, best_thresholds)\n",
    "    print(\"\\nPredicción de ejemplo:\", prediction)\n",
    "\n",
    "    plot_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 modelo jerárquico\n",
    "# # ====================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup, AutoConfig\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ====================\n",
    "#  Modelo v2\n",
    "# ====================\n",
    "class HierarchicalBERTv2(torch.nn.Module):\n",
    "    def __init__(self, num_parents, num_children):\n",
    "        super().__init__()\n",
    "        config = AutoConfig.from_pretrained(Config.MODEL_NAME, output_hidden_states=True)\n",
    "        self.bert = AutoModel.from_pretrained(Config.MODEL_NAME, config=config)\n",
    "\n",
    "        hidden_size = self.bert.config.hidden_size  # This will be 768 for base models\n",
    "\n",
    "        self.parent_classifier = torch.nn.Linear(hidden_size, num_parents)\n",
    "        self.child_classifier = torch.nn.Linear(hidden_size + num_parents, num_children)\n",
    "        self.dropout = torch.nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        if Config.USE_FEATURE_PYRAMID:\n",
    "            # Combine last 3 layers' [CLS] embeddings\n",
    "            hidden_states = outputs.hidden_states[-3:]  # Get last 3 layers\n",
    "            # Stack [CLS] embeddings (shape: [3, batch_size, hidden_size])\n",
    "            pooled = torch.stack([state[:, 0] for state in hidden_states])\n",
    "            # Weighted combination of layers (weights should sum to 1)\n",
    "            pooled = torch.einsum('lbd,l->bd', pooled,\n",
    "                                torch.tensor(Config.FEATURE_LAYER_WEIGHTS).to(pooled.device))\n",
    "        else:\n",
    "            pooled = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        pooled = self.dropout(pooled)\n",
    "\n",
    "        # Jerarquía de clasificación\n",
    "        parent_logits = self.parent_classifier(pooled)\n",
    "        parent_probs = torch.sigmoid(parent_logits)\n",
    "        child_input = torch.cat([pooled, parent_probs], dim=1)\n",
    "        child_logits = self.child_classifier(child_input)\n",
    "\n",
    "        return parent_logits, child_logits, pooled\n",
    "\n",
    "# ====================\n",
    "#  FUNCIÓN DE PÉRDIDA MEJORADA\n",
    "# ====================\n",
    "def hierarchical_lossv2(parent_logits, child_logits,\n",
    "                     parent_labels, child_labels,\n",
    "                     parent_weights, child_weights):\n",
    "\n",
    "    loss_parent = F.binary_cross_entropy_with_logits(\n",
    "        parent_logits,\n",
    "        parent_labels,\n",
    "        pos_weight=parent_weights\n",
    "    )\n",
    "\n",
    "    loss_child = F.binary_cross_entropy_with_logits(\n",
    "        child_logits,\n",
    "        child_labels,\n",
    "        pos_weight=child_weights\n",
    "    )\n",
    "\n",
    "    return (Config.HIERARCHICAL_WEIGHTS['parent'] * loss_parent +\n",
    "            Config.HIERARCHICAL_WEIGHTS['child'] * loss_child)\n",
    "\n",
    "# ====================\n",
    "#  AJUSTE DINÁMICO DE UMBRALES\n",
    "# ====================\n",
    "def calculate_optimal_thresholds(y_true, y_probs):\n",
    "    thresholds = {}\n",
    "    for i in range(y_probs.shape[1]):\n",
    "        if np.sum(y_true[:, i]) > 0:  # Solo clases presentes\n",
    "            precision, recall, threshs = precision_recall_curve(y_true[:, i], y_probs[:, i])\n",
    "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "            best_idx = np.nanargmax(f1_scores)\n",
    "            thresholds[i] = threshs[best_idx]\n",
    "    return thresholds\n",
    "\n",
    "# ====================\n",
    "#  Dataset\n",
    "# ====================\n",
    "class HierarchicalMedicalDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, mlb_parent, mlb_child):\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.examples = []\n",
    "\n",
    "        # Procesar etiquetas\n",
    "        self.parent_labels = []\n",
    "        self.child_labels = []\n",
    "\n",
    "        for codes in df['labels'].apply(eval): # FIXME: Unsafe eval\n",
    "            parents, children = set(), set()\n",
    "            for code in codes:\n",
    "                code = code.strip().upper()\n",
    "                levels = parse_code(code)\n",
    "                if len(levels) >= 1: parents.add(levels[0])\n",
    "                if len(levels) >= 2: children.add(levels[1])\n",
    "\n",
    "            self.parent_labels.append(mlb_parent.transform([parents])[0])\n",
    "            self.child_labels.append(mlb_child.transform([children])[0])\n",
    "\n",
    "        for idx in range(len(self.texts)):\n",
    "            encoding = self.tokenizer(\n",
    "                self.texts[idx],\n",
    "                max_length=Config.MAX_LENGTH,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            self.examples.append({\n",
    "                'input_ids': encoding['input_ids'].squeeze(),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "                'parent_labels': torch.FloatTensor(self.parent_labels[idx]),\n",
    "                'child_labels': torch.FloatTensor(self.child_labels[idx]),\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "# ====================\n",
    "#  ENTRENAMIENTO\n",
    "# ====================\n",
    "def train(best_thresholds=Config.THRESHOLDS):\n",
    "    epochs_without_improvement = 0\n",
    "    early_stop = False\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Cargar datos\n",
    "    train_df = pd.read_csv(Config.DATA_PATHS['train'])\n",
    "    val_df = pd.read_csv(Config.DATA_PATHS['val'])\n",
    "\n",
    "    # Construir binarizadores\n",
    "    mlb_parent, mlb_child = calculate_mlb_classes()\n",
    "\n",
    "    # Preparar datasets\n",
    "\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.SAVE_TOKENIZER_PATH)\n",
    "        print(\"Loaded saved tokenizer\")\n",
    "    except:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
    "        tokenizer.save_pretrained(Config.SAVE_TOKENIZER_PATH)\n",
    "        print(\"Created new tokenizer\")\n",
    "\n",
    "    train_dataset = HierarchicalMedicalDataset(train_df, tokenizer, mlb_parent, mlb_child)\n",
    "    val_dataset = HierarchicalMedicalDataset(val_df, tokenizer, mlb_parent, mlb_child)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=Config.TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=Config.VAL_BATCH_SIZE)\n",
    "\n",
    "    # Modelo y optimizador\n",
    "    model = HierarchicalBERTv2(\n",
    "        len(mlb_parent.classes_),\n",
    "        len(mlb_child.classes_)\n",
    "    ).to(device)\n",
    "\n",
    "    # Load best model if available\n",
    "    if os.path.exists(f\"{Config.SAVE_PATH}_2\"):\n",
    "        model.load_state_dict(torch.load(f\"{Config.SAVE_PATH}_2\"))\n",
    "        print(\"Loaded best model - 2\")\n",
    "    elif os.path.exists(Config.SAVE_PATH):\n",
    "        model.load_state_dict(torch.load(Config.SAVE_PATH))\n",
    "        print(\"Loaded best model\")\n",
    "    else:\n",
    "        print(\"Starting training from scratch\")\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps = Config.WARMUP_EPOCHS * len(train_loader),\n",
    "        num_training_steps = Config.EPOCHS * len(train_loader)\n",
    "    )\n",
    "\n",
    "    # Bucle de entrenamiento\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=Config.USE_FP16)\n",
    "\n",
    "    # Calcular pesos de clases\n",
    "    parent_counts = np.sum(train_dataset.parent_labels, axis=0)\n",
    "    parent_weights = (len(train_dataset) - parent_counts) / (parent_counts + Config.CLASS_WEIGHT_SMOOTHING)\n",
    "    parent_weights = torch.tensor(parent_weights).to(device)\n",
    "\n",
    "    child_counts = np.sum(train_dataset.child_labels, axis=0)\n",
    "    child_weights = (len(train_dataset) - child_counts) / (child_counts + Config.CLASS_WEIGHT_SMOOTHING)\n",
    "    child_weights = torch.tensor(child_weights).to(device)\n",
    "\n",
    "    for epoch in range(Config.EPOCHS):\n",
    "        if early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Ajuste periódico de umbrales\n",
    "        if (epoch + 1) % Config.THRESHOLD_TUNING_INTERVAL == 0:\n",
    "            val_probs, val_labels = get_validation_probabilities(model, val_loader, device)\n",
    "\n",
    "            # Calcular mejores umbrales por clase\n",
    "            parent_thresholds = calculate_optimal_thresholds(\n",
    "                val_labels['parent'], val_probs['parent']\n",
    "            )\n",
    "            child_thresholds = calculate_optimal_thresholds(\n",
    "                val_labels['child'], val_probs['child']\n",
    "            )\n",
    "\n",
    "            # Actualizar umbrales globales\n",
    "            best_thresholds['parent'] = np.mean(list(parent_thresholds.values()))\n",
    "            best_thresholds['child'] = np.mean(list(child_thresholds.values()))\n",
    "            print(f\"Nuevos umbrales: Parent={best_thresholds['parent']:.3f}, Child={best_thresholds['child']:.3f}\")\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            inputs = {\n",
    "                k: v.to(device)\n",
    "                for k, v in batch.items()\n",
    "                if k in ['input_ids', 'attention_mask']\n",
    "            }\n",
    "\n",
    "            parent_labels = batch['parent_labels'].to(device)\n",
    "            child_labels = batch['child_labels'].to(device)\n",
    "\n",
    "            with torch.amp.autocast('cuda', enabled=Config.USE_FP16):\n",
    "                outputs = model(**inputs)\n",
    "\n",
    "                # Línea corregida\n",
    "                loss = hierarchical_loss(\n",
    "                    outputs[0],  # parent_logits\n",
    "                    outputs[1],  # child_logits\n",
    "                    parent_labels,\n",
    "                    child_labels\n",
    "                )\n",
    "\n",
    "                loss = loss / Config.GRADIENT_ACCUMULATION_STEPS\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                if (step + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    scaler.step(optimizer)\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    scaler.update()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                progress_bar.set_postfix(loss=loss.item(), lr=scheduler.get_last_lr()[0])\n",
    "\n",
    "        # Validación\n",
    "        val_metrics = evaluate(model, val_loader, device, mlb_parent, mlb_child, best_thresholds)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | LR: {scheduler.get_last_lr()[0]:.2E}\")\n",
    "        # Store metrics\n",
    "\n",
    "        loss_metric = val_metrics['f1_macro']\n",
    "        if epoch == 0:\n",
    "            best_f1 = loss_metric\n",
    "\n",
    "        if loss_metric > (best_f1 + Config.IMPROVEMENT_MARGIN):\n",
    "            print(f\"Saving best model... {best_f1:.5f} -> {loss_metric:.5f}\")\n",
    "            torch.save(model.state_dict(), f\"{Config.SAVE_PATH}_3\")\n",
    "            best_f1 = loss_metric\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= Config.EARLY_STOP_PATIENCE:\n",
    "                early_stop = True\n",
    "\n",
    "        metrics_data = {\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': total_loss/len(train_loader),\n",
    "            'f1_micro': val_metrics['f1_micro'],\n",
    "            'f1_macro': val_metrics['f1_macro'],\n",
    "            'f1_micro_parent': val_metrics['f1_micro_parent'],\n",
    "            'f1_macro_parent': val_metrics['f1_macro_parent'],\n",
    "            'f1_micro_child': val_metrics['f1_micro_child'],\n",
    "            'f1_macro_child': val_metrics['f1_macro_child'],\n",
    "            'lr': scheduler.get_last_lr()[0],\n",
    "            'epochs_without_improvement': epochs_without_improvement,\n",
    "            'parent_threshold': best_thresholds['parent'],\n",
    "            'child_threshold': best_thresholds['child']\n",
    "        }\n",
    "\n",
    "        # Write metrics to CSV\n",
    "        metrics_df = pd.DataFrame([metrics_data])\n",
    "        if epoch == 0:\n",
    "            metrics_df.to_csv('training_metrics.csv', mode='a', index=False)\n",
    "        else:\n",
    "            metrics_df.to_csv('training_metrics.csv', mode='a', header=False, index=False)\n",
    "\n",
    "        print(f\"F1 Validation | Micro: {val_metrics['f1_micro']:.5f} | Macro: {val_metrics['f1_macro']:.5f} | Best: {best_f1:.5f} | Epochs without improvement: {epochs_without_improvement + 1}\")\n",
    "\n",
    "# ====================\n",
    "#  FUNCIONES AUXILIARES\n",
    "# ====================\n",
    "def get_validation_probabilities(model, dataloader, device):\n",
    "    model.eval()\n",
    "    parent_probs, child_probs = [], []\n",
    "    parent_labels, child_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(device),\n",
    "                'attention_mask': batch['attention_mask'].to(device)\n",
    "            }\n",
    "            p_logits, c_logits, _ = model(**inputs)\n",
    "\n",
    "            parent_probs.append(torch.sigmoid(p_logits).cpu().numpy())\n",
    "            child_probs.append(torch.sigmoid(c_logits).cpu().numpy())\n",
    "\n",
    "            parent_labels.append(batch['parent_labels'].numpy())\n",
    "            child_labels.append(batch['child_labels'].numpy())\n",
    "\n",
    "    return {\n",
    "        'parent': np.concatenate(parent_probs),\n",
    "        'child': np.concatenate(child_probs)\n",
    "    }, {\n",
    "        'parent': np.concatenate(parent_labels),\n",
    "        'child': np.concatenate(child_labels)\n",
    "    }\n",
    "\n",
    "\n",
    "# ====================\n",
    "#  EVALUACIÓN\n",
    "# ====================\n",
    "def evaluate(model, dataloader, device, mlb_parent, mlb_child, thresholds):\n",
    "    model.eval()\n",
    "    parent_preds_all = []\n",
    "    child_preds_all = []\n",
    "    parent_labels_all = []\n",
    "    child_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {\n",
    "                k: v.to(device)\n",
    "                for k, v in batch.items()\n",
    "                if k in ['input_ids', 'attention_mask']\n",
    "            }\n",
    "\n",
    "            # Get labels\n",
    "            parent_labels = batch['parent_labels'].numpy()\n",
    "            child_labels = batch['child_labels'].numpy()\n",
    "\n",
    "            parent_logits, child_logits, pooled = model(**inputs)\n",
    "\n",
    "            # Convert to predictions\n",
    "            parent_preds = (torch.sigmoid(parent_logits).cpu().numpy() > thresholds['parent']).astype(int)\n",
    "            child_preds = (torch.sigmoid(child_logits).cpu().numpy() > thresholds['child']).astype(int)\n",
    "\n",
    "            # Append to lists\n",
    "            parent_preds_all.extend(parent_preds)\n",
    "            child_preds_all.extend(child_preds)\n",
    "            parent_labels_all.extend(parent_labels)\n",
    "            child_labels_all.extend(child_labels)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    parent_preds_all = np.array(parent_preds_all)\n",
    "    child_preds_all = np.array(child_preds_all)\n",
    "    parent_labels_all = np.array(parent_labels_all)\n",
    "    child_labels_all = np.array(child_labels_all)\n",
    "\n",
    "    # Print example comparison for parent level\n",
    "    if len(parent_labels_all) > 0:\n",
    "        parent_true = np.array(mlb_parent.classes_)[parent_labels_all[0].astype(bool)]\n",
    "        parent_pred = np.array(mlb_parent.classes_)[parent_preds_all[0].astype(bool)]\n",
    "        common_labels = len(set(parent_true) & set(parent_pred))\n",
    "        total_labels = len(set(parent_true))\n",
    "        accuracy_parent = common_labels / total_labels if total_labels > 0 else 0\n",
    "\n",
    "        child_true = np.array(mlb_child.classes_)[child_labels_all[0].astype(bool)]\n",
    "        child_pred = np.array(mlb_child.classes_)[child_preds_all[0].astype(bool)]\n",
    "        common_labels = len(set(child_true) & set(child_pred))\n",
    "        total_labels = len(set(child_true))\n",
    "        accuracy_child = common_labels / total_labels if total_labels > 0 else 0\n",
    "\n",
    "        print(\"Expected parent labels:\", sorted(parent_true))\n",
    "        print(\"Predicted parent labels:\", sorted(parent_pred))\n",
    "        print(\"Expected child labels:\", sorted(child_true))\n",
    "        print(\"Predicted child labels:\", sorted(child_pred))\n",
    "\n",
    "        print(f\"Percentage of correct parent labels: {accuracy_parent:.2%} | {accuracy_child:.2%}\")\n",
    "\n",
    "    # Calculate F1 scores for each level\n",
    "    metrics = {\n",
    "        'f1_micro_parent': f1_score(parent_labels_all, parent_preds_all, average='micro' , zero_division=0),\n",
    "        'f1_macro_parent': f1_score(parent_labels_all, parent_preds_all, average='macro', zero_division=0),\n",
    "        'f1_micro_child': f1_score(child_labels_all, child_preds_all, average='micro', zero_division=0),\n",
    "        'f1_macro_child': f1_score(child_labels_all, child_preds_all, average='macro', zero_division=0)\n",
    "    }\n",
    "\n",
    "    # Calculate weighted average F1 scores\n",
    "    metrics['f1_micro'] = (\n",
    "        Config.HIERARCHICAL_WEIGHTS['parent'] * metrics['f1_micro_parent'] +\n",
    "        Config.HIERARCHICAL_WEIGHTS['child'] * metrics['f1_micro_child']\n",
    "    ) / sum(Config.HIERARCHICAL_WEIGHTS.values())\n",
    "\n",
    "    metrics['f1_macro'] = (\n",
    "        Config.HIERARCHICAL_WEIGHTS['parent'] * metrics['f1_macro_parent'] +\n",
    "        Config.HIERARCHICAL_WEIGHTS['child'] * metrics['f1_macro_child']\n",
    "    ) / sum(Config.HIERARCHICAL_WEIGHTS.values())\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ====================\n",
    "#  PREDICCIÓN\n",
    "# ====================\n",
    "def predict(text, model, tokenizer, mlb_parent, mlb_child, device, thresholds):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=Config.MAX_LENGTH,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        parent_logits, child_logits = model(**encoding)\n",
    "\n",
    "    # Obtener predicciones\n",
    "    parent_probs = torch.sigmoid(parent_logits).cpu().numpy()\n",
    "    child_probs = torch.sigmoid(child_logits).cpu().numpy()\n",
    "\n",
    "    # Decodificar etiquetas\n",
    "    parent_preds = mlb_parent.inverse_transform((parent_probs > thresholds['parent']).astype(int))\n",
    "    child_preds = mlb_child.inverse_transform((child_probs > thresholds['child']).astype(int))\n",
    "\n",
    "    # Combinar y asegurar jerarquía\n",
    "    final_codes = set()\n",
    "    for parent in parent_preds[0]:\n",
    "        final_codes.add(parent)\n",
    "        for child in child_preds[0]:\n",
    "            if child.startswith(parent):\n",
    "                final_codes.add(child)\n",
    "\n",
    "    return sorted(final_codes)\n",
    "\n",
    "# ====================\n",
    "#  EJECUCIÓN\n",
    "# ====================\n",
    "if __name__ == \"__main__\":\n",
    "    best_thresholds = Config.THRESHOLDS\n",
    "\n",
    "    train(best_thresholds)\n",
    "\n",
    "    # Cargar datos de test\n",
    "    test_df = pd.read_csv(Config.DATA_PATHS['test'])\n",
    "    mlb_parent, mlb_child = calculate_mlb_classes()\n",
    "\n",
    "    # Cargar modelo\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.SAVE_TOKENIZER_PATH)\n",
    "        print(\"Loaded saved tokenizer\")\n",
    "    except:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
    "        print(\"Using default tokenizer\")\n",
    "\n",
    "    model = HierarchicalBERT(\n",
    "        len(mlb_parent.classes_),\n",
    "        len(mlb_child.classes_)\n",
    "    ).to(device)\n",
    "\n",
    "    if os.path.exists(f\"{Config.SAVE_PATH}_2\"):\n",
    "        model.load_state_dict(torch.load(f\"{Config.SAVE_PATH}_2\"))\n",
    "        print(\"Loaded best model - 2\")\n",
    "    elif os.path.exists(Config.SAVE_PATH):\n",
    "        model.load_state_dict(torch.load(Config.SAVE_PATH))\n",
    "        print(\"Loaded best model\")\n",
    "\n",
    "    # Evaluar en test\n",
    "    test_dataset = HierarchicalMedicalDataset(test_df, tokenizer, mlb_parent, mlb_child)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=Config.TEST_BATCH_SIZE)\n",
    "\n",
    "    test_metrics = evaluate(model, test_loader, device, mlb_parent, mlb_child)\n",
    "    print(\"\\nResultados en Test:\")\n",
    "    print(f\"Micro F1: {test_metrics['f1_micro']:.4f}\")\n",
    "    print(f\"Macro F1: {test_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "    # Ejemplo de predicción\n",
    "    sample_text = \"Paciente con diabetes mellitus tipo 2 y complicaciones renales...\"\n",
    "    prediction = predict(sample_text, model, tokenizer, mlb_parent, mlb_child, device, best_thresholds)\n",
    "    print(\"\\nPredicción de ejemplo:\", prediction)\n",
    "\n",
    "    plot_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical - V1\n",
    "# ====================\n",
    "\n",
    "import os\n",
    "\n",
    "class HierarchicalMedicalDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, mlb_parent, mlb_child):\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.examples = []\n",
    "\n",
    "        # Procesar etiquetas\n",
    "        self.parent_labels = []\n",
    "        self.child_labels = []\n",
    "\n",
    "        for codes in df['labels'].apply(eval): # FIXME: Unsafe eval\n",
    "            parents, children = set(), set()\n",
    "            for code in codes:\n",
    "                code = code.strip().upper()\n",
    "                levels = parse_code(code)\n",
    "                if len(levels) >= 1: parents.add(levels[0])\n",
    "                if len(levels) >= 2: children.add(levels[1])\n",
    "\n",
    "            self.parent_labels.append(mlb_parent.transform([parents])[0])\n",
    "            self.child_labels.append(mlb_child.transform([children])[0])\n",
    "\n",
    "        for idx in range(len(self.texts)):\n",
    "            encoding = self.tokenizer(\n",
    "                self.texts[idx],\n",
    "                max_length=Config.MAX_LENGTH,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            self.examples.append({\n",
    "                'input_ids': encoding['input_ids'].squeeze(),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "                'parent_labels': torch.FloatTensor(self.parent_labels[idx]),\n",
    "                'child_labels': torch.FloatTensor(self.child_labels[idx]),\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "# ====================\n",
    "#  ENTRENAMIENTO\n",
    "# ====================\n",
    "def train():\n",
    "    epochs_without_improvement = 0\n",
    "    early_stop = False\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Cargar datos\n",
    "    train_df = pd.read_csv(Config.DATA_PATHS['train'])\n",
    "    val_df = pd.read_csv(Config.DATA_PATHS['val'])\n",
    "\n",
    "    # Construir binarizadores\n",
    "    mlb_parent, mlb_child = calculate_mlb_classes()\n",
    "\n",
    "    # Preparar datasets\n",
    "\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.SAVE_TOKENIZER_PATH)\n",
    "        print(\"Loaded saved tokenizer\")\n",
    "    except:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
    "        tokenizer.save_pretrained(Config.SAVE_TOKENIZER_PATH)\n",
    "        print(\"Created new tokenizer\")\n",
    "\n",
    "    train_dataset = HierarchicalMedicalDataset(train_df, tokenizer, mlb_parent, mlb_child)\n",
    "    val_dataset = HierarchicalMedicalDataset(val_df, tokenizer, mlb_parent, mlb_child)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=Config.TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=Config.VAL_BATCH_SIZE)\n",
    "\n",
    "    # Modelo y optimizador\n",
    "    model = HierarchicalBERT(\n",
    "        len(mlb_parent.classes_),\n",
    "        len(mlb_child.classes_)\n",
    "    ).to(device)\n",
    "\n",
    "    # Load best model if available\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(Config.SAVE_STATE_PATH))\n",
    "        print(\"Loaded previously saved best model\")\n",
    "    except:\n",
    "        print(\"Starting training from scratch\")\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps = Config.WARMUP_EPOCHS * len(train_loader),\n",
    "        num_training_steps = Config.EPOCHS * len(train_loader)\n",
    "    )\n",
    "\n",
    "    # Bucle de entrenamiento\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=Config.USE_FP16)\n",
    "    for epoch in range(Config.EPOCHS):\n",
    "        if early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            inputs = {\n",
    "                k: v.to(device)\n",
    "                for k, v in batch.items()\n",
    "                if k in ['input_ids', 'attention_mask']\n",
    "            }\n",
    "\n",
    "            parent_labels = batch['parent_labels'].to(device)\n",
    "            child_labels = batch['child_labels'].to(device)\n",
    "\n",
    "            with torch.amp.autocast('cuda', enabled=Config.USE_FP16):\n",
    "                outputs = model(**inputs)\n",
    "\n",
    "                # Línea corregida\n",
    "                loss = hierarchical_loss(\n",
    "                    outputs[0],  # parent_logits\n",
    "                    outputs[1],  # child_logits\n",
    "                    parent_labels,\n",
    "                    child_labels\n",
    "                )\n",
    "\n",
    "                loss = loss / Config.GRADIENT_ACCUMULATION_STEPS\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                if (step + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    scaler.step(optimizer)\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    scaler.update()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                progress_bar.set_postfix(loss=loss.item(), lr=scheduler.get_last_lr()[0])\n",
    "\n",
    "        # Validación\n",
    "        val_metrics = evaluate(model, val_loader, device,\n",
    "                              mlb_parent, mlb_child)\n",
    "        print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | LR: {scheduler.get_last_lr()[0]:.2E}\")\n",
    "        # Store metrics\n",
    "\n",
    "        loss_metric = val_metrics['f1_macro']\n",
    "        if loss_metric > (best_f1 + Config.IMPROVEMENT_MARGIN) and epoch > 0:\n",
    "            print(f\"Saving best model... {best_f1:.5f} -> {loss_metric:.5f}\")\n",
    "            torch.save(model.state_dict(), f\"{Config.SAVE_PATH}_2\")\n",
    "            best_f1 = loss_metric\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= Config.EARLY_STOP_PATIENCE:\n",
    "                early_stop = True\n",
    "\n",
    "        metrics_data = {\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': total_loss/len(train_loader),\n",
    "            'f1_micro': val_metrics['f1_micro'],\n",
    "            'f1_macro': val_metrics['f1_macro'],\n",
    "            'f1_micro_parent': val_metrics['f1_micro_parent'],\n",
    "            'f1_macro_parent': val_metrics['f1_macro_parent'],\n",
    "            'f1_micro_child': val_metrics['f1_micro_child'],\n",
    "            'f1_macro_child': val_metrics['f1_macro_child'],\n",
    "            'lr': scheduler.get_last_lr()[0],\n",
    "            'epochs_without_improvement': epochs_without_improvement\n",
    "        }\n",
    "\n",
    "        # Write metrics to CSV\n",
    "        metrics_df = pd.DataFrame([metrics_data])\n",
    "        if epoch == 0:\n",
    "            metrics_df.to_csv('training_metrics.csv', mode='a', index=False)\n",
    "        else:\n",
    "            metrics_df.to_csv('training_metrics.csv', mode='a', header=False, index=False)\n",
    "\n",
    "        print(f\"F1 Validation | Micro: {val_metrics['f1_micro']:.5f} | Macro: {val_metrics['f1_macro']:.5f} | Best: {best_f1:.5f} | Epochs without improvement: {epochs_without_improvement + 1}\")\n",
    "\n",
    "\n",
    "# ====================\n",
    "#  EVALUACIÓN\n",
    "# ====================\n",
    "def evaluate(model, dataloader, device, mlb_parent, mlb_child):\n",
    "    model.eval()\n",
    "    parent_preds_all = []\n",
    "    child_preds_all = []\n",
    "    parent_labels_all = []\n",
    "    child_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {\n",
    "                k: v.to(device)\n",
    "                for k, v in batch.items()\n",
    "                if k in ['input_ids', 'attention_mask']\n",
    "            }\n",
    "\n",
    "            # Get labels\n",
    "            parent_labels = batch['parent_labels'].numpy()\n",
    "            child_labels = batch['child_labels'].numpy()\n",
    "\n",
    "            parent_logits, child_logits = model(**inputs)\n",
    "\n",
    "            # Convert to predictions\n",
    "            parent_preds = (torch.sigmoid(parent_logits).cpu().numpy() > Config.THRESHOLDS['parent']).astype(int)\n",
    "            child_preds = (torch.sigmoid(child_logits).cpu().numpy() > Config.THRESHOLDS['child']).astype(int)\n",
    "\n",
    "            # Append to lists\n",
    "            parent_preds_all.extend(parent_preds)\n",
    "            child_preds_all.extend(child_preds)\n",
    "            parent_labels_all.extend(parent_labels)\n",
    "            child_labels_all.extend(child_labels)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    parent_preds_all = np.array(parent_preds_all)\n",
    "    child_preds_all = np.array(child_preds_all)\n",
    "    parent_labels_all = np.array(parent_labels_all)\n",
    "    child_labels_all = np.array(child_labels_all)\n",
    "\n",
    "    # Print example comparison for parent level\n",
    "    if len(parent_labels_all) > 0:\n",
    "        parent_true = np.array(mlb_parent.classes_)[parent_labels_all[0].astype(bool)]\n",
    "        parent_pred = np.array(mlb_parent.classes_)[parent_preds_all[0].astype(bool)]\n",
    "        common_labels = len(set(parent_true) & set(parent_pred))\n",
    "        total_labels = len(set(parent_true))\n",
    "        accuracy_parent = common_labels / total_labels if total_labels > 0 else 0\n",
    "\n",
    "        child_true = np.array(mlb_child.classes_)[child_labels_all[0].astype(bool)]\n",
    "        child_pred = np.array(mlb_child.classes_)[child_preds_all[0].astype(bool)]\n",
    "        common_labels = len(set(child_true) & set(child_pred))\n",
    "        total_labels = len(set(child_true))\n",
    "        accuracy_child = common_labels / total_labels if total_labels > 0 else 0\n",
    "\n",
    "        print(\"Expected parent labels:\", sorted(parent_true))\n",
    "        print(\"Predicted parent labels:\", sorted(parent_pred))\n",
    "        print(\"Expected child labels:\", sorted(child_true))\n",
    "        print(\"Predicted child labels:\", sorted(child_pred))\n",
    "\n",
    "        print(f\"Percentage of correct parent labels: {accuracy_parent:.2%} | {accuracy_child:.2%}\")\n",
    "\n",
    "    # Calculate F1 scores for each level\n",
    "    metrics = {\n",
    "        'f1_micro_parent': f1_score(parent_labels_all, parent_preds_all, average='micro' , zero_division=0),\n",
    "        'f1_macro_parent': f1_score(parent_labels_all, parent_preds_all, average='macro', zero_division=0),\n",
    "        'f1_micro_child': f1_score(child_labels_all, child_preds_all, average='micro', zero_division=0),\n",
    "        'f1_macro_child': f1_score(child_labels_all, child_preds_all, average='macro', zero_division=0)\n",
    "    }\n",
    "\n",
    "    # Calculate weighted average F1 scores\n",
    "    metrics['f1_micro'] = (\n",
    "        Config.HIERARCHICAL_WEIGHTS['parent'] * metrics['f1_micro_parent'] +\n",
    "        Config.HIERARCHICAL_WEIGHTS['child'] * metrics['f1_micro_child']\n",
    "    ) / sum(Config.HIERARCHICAL_WEIGHTS.values())\n",
    "\n",
    "    metrics['f1_macro'] = (\n",
    "        Config.HIERARCHICAL_WEIGHTS['parent'] * metrics['f1_macro_parent'] +\n",
    "        Config.HIERARCHICAL_WEIGHTS['child'] * metrics['f1_macro_child']\n",
    "    ) / sum(Config.HIERARCHICAL_WEIGHTS.values())\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ====================\n",
    "#  PREDICCIÓN\n",
    "# ====================\n",
    "def predict(text, model, tokenizer, mlb_parent, mlb_child, device):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=Config.MAX_LENGTH,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        parent_logits, child_logits = model(**encoding)\n",
    "\n",
    "    # Obtener predicciones\n",
    "    parent_probs = torch.sigmoid(parent_logits).cpu().numpy()\n",
    "    child_probs = torch.sigmoid(child_logits).cpu().numpy()\n",
    "\n",
    "    # Decodificar etiquetas\n",
    "    parent_preds = mlb_parent.inverse_transform((parent_probs > Config.THRESHOLDS['parent']).astype(int))\n",
    "    child_preds = mlb_child.inverse_transform((child_probs > Config.THRESHOLDS['child']).astype(int))\n",
    "\n",
    "    # Combinar y asegurar jerarquía\n",
    "    final_codes = set()\n",
    "    for parent in parent_preds[0]:\n",
    "        final_codes.add(parent)\n",
    "        for child in child_preds[0]:\n",
    "            if child.startswith(parent):\n",
    "                final_codes.add(child)\n",
    "\n",
    "    return sorted(final_codes)\n",
    "\n",
    "# ====================\n",
    "#  EJECUCIÓN\n",
    "# ====================\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "\n",
    "    # Cargar datos de test\n",
    "    test_df = pd.read_csv(Config.DATA_PATHS['test'])\n",
    "    mlb_parent, mlb_child = calculate_mlb_classes()\n",
    "\n",
    "    # Cargar modelo\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.SAVE_TOKENIZER_PATH)\n",
    "        print(\"Loaded saved tokenizer\")\n",
    "    except:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
    "        print(\"Using default tokenizer\")\n",
    "\n",
    "    model = HierarchicalBERT(\n",
    "        len(mlb_parent.classes_),\n",
    "        len(mlb_child.classes_)\n",
    "    ).to(device)\n",
    "\n",
    "    if os.exists(f\"{Config.SAVE_PATH}2\"):\n",
    "        model.load_state_dict(torch.load(f\"{Config.SAVE_PATH}_2\"))\n",
    "        print(\"Loaded best model - 2\")\n",
    "    elif os.exists(Config.SAVE_PATH\"):\n",
    "        model.load_state_dict(torch.load(Config.SAVE_PATH))\n",
    "        print(\"Loaded best model\")\n",
    "\n",
    "    # Evaluar en test\n",
    "    test_dataset = HierarchicalMedicalDataset(test_df, tokenizer, mlb_parent, mlb_child)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=Config.TEST_BATCH_SIZE)\n",
    "\n",
    "    test_metrics = evaluate(model, test_loader, device, mlb_parent, mlb_child)\n",
    "    print(\"\\nResultados en Test:\")\n",
    "    print(f\"Micro F1: {test_metrics['f1_micro']:.4f}\")\n",
    "    print(f\"Macro F1: {test_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "    # Ejemplo de predicción\n",
    "    sample_text = \"Paciente con diabetes mellitus tipo 2 y complicaciones renales...\"\n",
    "    prediction = predict(sample_text, model, tokenizer, mlb_parent, mlb_child, device)\n",
    "    print(\"\\nPredicción de ejemplo:\", prediction)\n",
    "\n",
    "    plot_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  V0 Entrenamiento con cie10 dataset\n",
    "# ====================\n",
    "\n",
    "# Dataset especializado para pre-entrenamiento\n",
    "class PretrainDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, mlb_parent, mlb_child):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.examples = []\n",
    "        self.mlb_parent = mlb_parent\n",
    "        self.mlb_child = mlb_child\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            code = row['code'].strip()\n",
    "            desc = row['description'].strip()\n",
    "            levels = parse_code(code)\n",
    "\n",
    "            # Generar múltiples variantes textuales\n",
    "            # Base variant is the description itself\n",
    "            variants = []\n",
    "\n",
    "            # Extract text inside parentheses and brackets\n",
    "            parentheses_matches = re.findall(r'\\((.*?)\\)', desc)\n",
    "            bracket_matches = re.findall(r'\\[(.*?)\\]', desc)\n",
    "\n",
    "            # Get text outside parentheses and brackets\n",
    "            clean_text = re.sub(r'\\([^)]*\\)|\\[[^\\]]*\\]', '', desc).strip()\n",
    "            if clean_text != desc:\n",
    "                variants.append(clean_text)\n",
    "\n",
    "            # Add matches from parentheses and brackets\n",
    "            variants.extend(parentheses_matches)\n",
    "            variants.extend(bracket_matches)\n",
    "\n",
    "            for variant in variants:\n",
    "                if len(variant) > 5:\n",
    "                    self.examples.append({\n",
    "                        'text': variant,\n",
    "                        'levels': levels\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Skipping short variant: {variant}\")\n",
    "\n",
    "        tokenized_examples = []\n",
    "        for example in self.examples:\n",
    "            encoding = self.tokenizer(\n",
    "                example['text'],\n",
    "                max_length=Config.MAX_LENGTH,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            levels = example['levels']\n",
    "\n",
    "            tokenized_examples.append({\n",
    "                'input_ids': encoding['input_ids'].squeeze(),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "                'parent_labels': torch.FloatTensor(self.mlb_parent.transform([[levels[0]]] if levels else [[]])[0]),\n",
    "                'child_labels': torch.FloatTensor(self.mlb_child.transform([[levels[1]]] if len(levels)>1 else [[]])[0])\n",
    "            })\n",
    "        self.examples = tokenized_examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "def pretrain():\n",
    "    # Cargar datos de códigos CIE10\n",
    "    df = pd.read_csv(Config.PRETRAIN_DATA_PATH)\n",
    "\n",
    "    mlb_parent, mlb_child = calculate_mlb_classes()\n",
    "\n",
    "    # Inicializar componentes\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
    "    dataset = PretrainDataset(df, tokenizer, mlb_parent, mlb_child)\n",
    "    dataloader = DataLoader(dataset, batch_size=Config.PRETRAIN_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    model = HierarchicalBERT(\n",
    "        len(mlb_parent.classes_),\n",
    "        len(mlb_child.classes_)\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "\n",
    "    # Bucle de pre-entrenamiento (similar al entrenamiento normal)\n",
    "    for epoch in range(Config.PRETRAIN_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Pre-train Epoch {epoch+1}\")\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(device),\n",
    "                'attention_mask': batch['attention_mask'].to(device)\n",
    "            }\n",
    "\n",
    "            parent_labels = batch['parent_labels'].to(device)\n",
    "            child_labels = batch['child_labels'].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            loss = hierarchical_loss(\n",
    "                outputs[0], outputs[1],\n",
    "                parent_labels, child_labels\n",
    "            )\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        print(f\"Pre-train Epoch {epoch+1} | Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "    # Guardar modelo pre-entrenado\n",
    "    torch.save(model.state_dict(), Config.SAVE_PATH)\n",
    "    tokenizer.save_pretrained(Config.SAVE_TOKENIZER_PATH)\n",
    "    print(f\"Modelo pre-entrenado guardado en {Config.SAVE_PATH}\")\n",
    "\n",
    "pretrain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
